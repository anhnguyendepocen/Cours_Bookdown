# Projections Methods {#Projections}

Consider the infinite MA representation of $y_t$ (Eq. \@ref(eq:InfMA)):
$$
y_t = \mu + \sum_{h=0}^\infty {\color{blue}\Psi_{h}} \eta_{t-h}.
$$

As seen in Section XXXX, the entries $(i,j)$ of the sequence of the $\Psi_h$ matrices define the IRF of $\eta_{j,t}$ on $y_{i,t}$.

Assume that you observe $\eta_{j,t}$, then a consistent estimate of $\Psi_{i,j,h}$ is simply obtained by the OLS regression of $y_{i,t+h}$ on $\eta_{j,t}$:
\begin{equation}
y_{i,t+h} = \mu_i + \Psi_{i,j,h}\eta_{j,t} + u_{i,j,t+h}.(\#eq:OLS1)
\end{equation}
Because the residuals $u_{i,j,t+h}$ are autocorrelated (for $h>0$), estimates of the covariance of the OLS estimators of the $\Psi_{i,j,h}$ then have to be based on robust estimators (e.g. Newey-West).

This is the core idea of the **local projection approach** [Jorda, 2005](https://www.aeaweb.org/articles?id=10.1257/0002828053828518).

Now, how to proceed in the (usual) case where $\eta_{j,t}$ is not observed? We consider two situations.

**Situation A: Without IV**

This corresponds to the original Jord\`a (2005)}'s approach. 

Assume that the structural shock of interest ($\eta_{1,t}$, say) can be consistently obtained as the residual of a regression of a variable $x_t$ on a set of control variables $w_t$ independent from $\eta_{1,t}$:
\begin{equation}
\eta_{1,t} = x_t - \mathbb{E}(x_t|w_t),(\#eq:xetaw)
\end{equation}
where $\mathbb{E}(x_t|w_t)$ is affine in $w_t$ and where $w_t$ is an affine transformation of $\eta_{2:n,t}$ and of past shocks $\eta_{t-1},\eta_{t-2},\dots$.

Eq. \@ref(eq:xetaw) implies that, conditional on $w_t$, the additional knowledge of $x_t$ is useful only when it comes to forecast something that depends on $\eta_{1,t}$.

Hence, given that $u_{i,1,t+h}$ (see Eq. \@ref(eq:OLS1)) is independent from $\eta_{1,t}$ (it depends on  $\eta_{t+h},\dots,\eta_{t+1},{\color{blue}\eta_{2:n,t}},\eta_{t-1},\eta_{t-2},\dots$), it comes that
$$
\mathbb{E}(u_{i,1,t+h}|x_t,w_t)= \mathbb{E}(u_{i,1,t+h}|w_t).
$$
This is the **conditional mean independence** case.

Let's rewrite Eq. \@ref(eq:OLS1) as follows:
\begin{eqnarray*}
y_{i,t+h} &=& \mu_i + \Psi_{i,1,h}\eta_{1,t} + u_{i,1,t+h}\\
&=&  \mu_i + \Psi_{i,1,h}x_t  {\color{blue}-\Psi_{i,1,h}\mathbb{E}(x_t|w_t) + u_{i,1,t+h}},
\end{eqnarray*}

What precedes implies that the expectation of the blue term, conditional on $x_t$ and $w_t$, is linear in $w_t$.

Standard results in the conditional mean independence case imply that the regression of $y_{i,t+h}$ on $x_t$, controlling for $w_t$, provides a consistent estimate of $\Psi_{i,1,h}$:
\begin{equation}
y_{i,t+h} = \alpha_i + \Psi_{i,1,h}x_t + \beta'w_t + v_{i,t+h}.
\end{equation}

Example: $[\Delta GDP_t, \pi_t,i_t]'$ follows a VAR(1) and the monetary-policy shock do not contemporaneously affect $\Delta GDP_t$ and $\pi_t$.

The IRFs can be estimated by LP, taking $x_t = i_t$ and $w_t = [\Delta GDP_t,\pi_t,\Delta GDP_{t-1}, \pi_{t-1},i_{t-1}]'$.

This approach closely relates to the SVAR Cholesky-based identification approach. Specifically, if $w_t = [{\color{blue}y_{1,t},\dots,y_{k-1,t}}, y_{t-1}',\dots,y_{t-p}']'$, with $k\le n$, and $x_t = y_{k,t}$, then this approach corresponds, for $h=0$, to the SVAR($p$) Cholesky-based IRF (focusing on the responses to the $k^{th}$ structural shock).

However, the two approaches differ for $h>0$, because the LP methodology does not necessarily reckons that the true dynamics of $y_t$ is a VAR.

Analogy with direct forecasting --based on regressions of $y_{t+h}$ on $\{y_t,y_{t-1},\dots\}$-- and iterated forecasting --based on a recursive model where $y_{t+1} = g(y_t,y_{t-1},\dots)+\varepsilon_{t+1}$ [Marcellino et al., 2006](https://www.princeton.edu/~mwatson/papers/Marcellino_Stock_Watson_JoE_2006.pdf). 



**Situation B: IV approach**

Consider now that we have a valid instrument $z_t$ for $\eta_{1,t}$ (with $\mathbb{E}(z_t)=0$). That is:
\begin{equation}
\left\{
\begin{array}{llll}
(IV.i) & \mathbb{E}(z_t \eta_{1,t}) &\ne 0 & \mbox{(relevance condition)} \\
(IV.ii) & \mathbb{E}(z_t \eta_{j,t}) &= 0 \quad \mbox{for } j>1 & \mbox{(exogeneity condition)}
\end{array}\right.(\#eq:IV1)
\end{equation}

The instrument $z_t$ can be used to identify the structural shock.

Eq. \@ref(eq:IV1) implies that there exist $\rho \ne 0$ and a mean-zero variable $\xi_t$ such that:
$$
\eta_{1,t} = \rho z_t + \xi_t,
$$
where $\xi_t$ is correlated neither to $z_t$, nor to $\eta_{j,t}$, $j\ge2$.

:::{.proof}
Define $\rho = \frac{\mathbb{E}(\eta_{1,t}z_t)}{\mathbb{V}ar(z_t)}$ and $\xi_t = \eta_{1,t} - \rho z_t$. It is easily seen that $\xi_t$ satisfies the moment restrictions given above.
:::

**Example: Identification of Monetary-Policy Shocks Based on High-Frequency Data**

Instruments for monetary-policy shocks can be extracted from high-frequency market data associated with interest-rate products.

The quotes of all interest-rate-related financial products are sensitive to monetary-policy announcements. That is because these quotes mainly depends on investors' expectations regarding future short-term rates: $\mathbb{E}_t(i_{t+s})$.

Typically, if agents were risk-neutral, the maturity-$h$ interest rate would approximatively be given by:
$$
i_{t,h} \approx \mathbb{E}_t\left(\frac{1}{h}\int_{0}^{h} i_{t+s} ds\right) = \frac{1}{h}\int_{0}^{h} \mathbb{E}_t\left(i_{t+s}\right) ds.
$$
In general, changes in $\mathbb{E}_t(i_{t+s})$, for $s>0$, can be affected by all types of shocks that may trigger a reaction by the central bank.

However, if a MP announcement takes place between $t$ and $t+\epsilon$, then most of $\mathbb{E}_{t+\epsilon}(i_{t+s})-\mathbb{E}_t(i_{t+s})$ is to be attributed to the MP shock. Hence, a monthly time series of MP shocks can be obtained by summing, over each month, the changes $i_{t+ \epsilon,h} - i_{t,h}$ associated with a given interest rate (T-bills, futures, swaps) and a given maturity $h$.

See among others: [Kuttner (2001)](https://www.sciencedirect.com/science/article/pii/S0304393201000551), 
[Cochrane and Piazzesi (2003)](https://web.stanford.edu/~piazzesi/cp2002.pdf), [Gurkaynak, Sack and Swanson (2005)](https://www.ijcb.org/journal/ijcb05q2a2.htm), [Piazzesi and Swanson (2008)](https://web.stanford.edu/~piazzesi/fff.pdf), [Gertler and Karadi (2015)](https://www.jstor.org/stable/43189950?seq=1\#metadata_info_tab_contents)

[Source of paper](https://www.ijcb.org/journal/ijcb05q2a2.htm)


```{r HighFreq, fig.align = 'center', out.width = "95%", fig.cap = "Source: Gurkaynak, Sack and Swanson (2005). Transaction rates of Federal funds futures on June 25, 2003, day on which a regularly scheduled FOMC meeting was scheduled. At 2:15 p.m., the FOMC announced that it was lowering its target for the federal funds rate from 1.25\\% to 1\\%, while many market participants were expecting a 50 bp cut. This shows that (i) financial markets seem to fully adjust to the policy action within just a few minutes and (ii) the federal funds rate surprise is not necessarily in the same direction as the federal funds rate action itself.", echo=FALSE}
knitr::include_graphics("images/GSS2005_HFI.png")
```

**Identification of Monetary-Policy Shocks Based on the Narrative Approach**

[Romer and Romer (2004)](https://eml.berkeley.edu/~dromer/papers/AER_September04.pdf) propose a two-step approach:

a. derive a series for Federal Reserve intentions for the  federal  funds  rate (the explicit target of the Fed)  around  FOMC  meetings,
b. control for Federal Reserve forecasts.

This gives a measure of intended monetary policy actions not driven by information about future economic developments.
a. "intentions" are measured as a combination of narrative and quantitative evidence. Sources: (among others) Minutes of FOMC and "Blue Books".
b. Controls = variables spanning the information the Federal Reserve has about future developments. Data: Federal Reserve's internal forecasts (inflation, real output and unemployment), "Greenbook's forecasts" -- usually issued 6 days before the FOMC meeting.

The shock measure is the residual series in the linear regression of (a) on (b).

**Situation B.1: IV approach**

There are two main IV approaches to estimate IRFs see [Stock and Watson, 2018](https://onlinelibrary.wiley.com/doi/abs/10.1111/ecoj.12593):

a. The LP-IV approach, where $y_t$'s DGP is left unspecified,
b. The SVAR-IV approach.

(again, analogy with direct and iterative forecasting, see above)

LP-IV is based on a set of IV regressions (for each variable of interest, one for each forecast horizon).

SVAR-IV is based on IV regressions of VAR innovations only (one for each series of VAR innovations).

If the VAR adequately captures the DGP, then the IV-SVAR is optimal for all horizons. If the VAR is misspecified, then specification errors are compounded at each horizon and a local projection method would lead to better results.

Assume you have consistent estimates of $\varepsilon_t = B\eta_t$, these estimates ($\hat\varepsilon_{t}$) coming e.g. from the estimation of a VAR model.

You have, for $i \in \{1,\dots,n\}$:
\begin{eqnarray}
\varepsilon_{i,t} &=& b_{i,1} \eta_{1,t} + u_{i,t} (\#eq:eps_rho)\\
&=& b_{i,1} \rho z_t + \underbrace{b_{i,1}\xi_t + u_{i,t}}_{\perp z_t}. \nonumber
\end{eqnarray}
($u_{i,t}$ is a linear combination of the $\eta_{j,t}$'s, $j\ge2$).

Hence, up to a multiplicative factor ($\rho$), the (OLS) regressions of the $\hat\varepsilon_{i,t}$'s on $z_t$ provide consistent estimates of the $b_{i,1}$'s.

Combined with the estimated VAR (the $\Phi_k$ matrices), this provides consistent estimates of the IRFs of $\eta_{1,t}$ on $y_t$, though up to a multiplicative factor.

How to resolve the scale ambiguity?

By rescaling of the structural shock ("unit-effect normalisation", see [Stock and Watson, 2018](https://onlinelibrary.wiley.com/doi/abs/10.1111/ecoj.12593)

Let us consider $\tilde\eta_{1,t}=b_{1,1}\eta_{1,t}$; by construction, $\tilde\eta_{1,t}$ has a one-unit contemporaneous effect on $y_{1,t}$.

Denoting by $\tilde{B}_{i,1}$ the contemporaneous impact of $\tilde\eta_{1,t}$, we get:
$$
\tilde{B}_{1} = \frac{1}{b_{1,1}} {B}_{1},
$$
where $B_{1}$ denotes the $1^{st}$ column of $B$ and $\tilde{B}_{1}=[1,\tilde{B}_{2,1},\dots,\tilde{B}_{n,1}]'$.

Eq. \@ref(eq:eps_rho) gives:
\begin{eqnarray*}
\varepsilon_{1,t} &=& \tilde\eta_{1,t} + u_{1,t}\\
\varepsilon_{i,t} &=& \tilde{B}_{i,1} \tilde\eta_{1,t} + u_{i,t}.
\end{eqnarray*}

This suggests that $\tilde{B}_{i,1}$ can be estimated by regressing $\varepsilon_{i,t}$ on $\varepsilon_{1,t}$, using $z_t$ as an instrument.

What about inference? Once cannot use the usual TSLS standard deviations because the $\varepsilon_{i,t}$'s are not directly observed. Bootstrap procedures can be resorted to.


Gaussian Parametric Bootstrap ([Stock and Watson, 2018, A.2](https://onlinelibrary.wiley.com/doi/abs/10.1111/ecoj.12593))

Assume you have estimated $\{\widehat{\Phi}_1,\dots,\widehat{\Phi}_p,\widehat{B}_1\}$ using the SVAR-IV approach based on a size-$T$ sample.

Generate $N$ (where $N$ is large) size-$T$ samples from the following VAR:
$$
\left[
\begin{array}{cc}
\widehat{\Phi}(L) & 0 \\
0 & \widehat{\rho}(L)
\end{array}
\right]
\left[
\begin{array}{c}
y_t \\
z_t
\end{array}
\right] =
\left[
\begin{array}{c}
\varepsilon_t \\
e_t
\end{array}
\right],
$$
$$
\mbox{where} \quad \left[
\begin{array}{c}
\varepsilon_t \\
e_t
\end{array}
\right]\sim \, i.i.d.\,\mathcal{N}\left(\left[\begin{array}{c}0\\0\end{array}\right],
\left[\begin{array}{cc}
\Omega & S'_{\varepsilon,e}\\
S_{\varepsilon,e}& \sigma^2_{e}
\end{array}\right]
\right),
$$
where $\widehat{\rho}(L)$ and $\sigma^2_{e}$ result from the estimation of an AR process for $z_t$, and where $\Omega$ and $S_{\varepsilon,e}$ are sample covariances for the VAR/AR residuals.

For each simulated sample (of $\tilde{y}_t$ and $\tilde{z}_t$, say), estimate $\{\widetilde{\widehat{\Phi}}_1,\dots,\widetilde{\widehat{\Phi}}_p,\widetilde{\widehat{B}}_1\}$ and associated $\widetilde{\Psi}_{i,1,h}$. This provides e.g. a sequence of $N$ estimates of $\Psi_{i,1,h}$, from which quantiles and conf. intervals can be deduced.



**Situation B.2: LP-IV**

If you do not want to posit a VAR-type dynamics for $y_t$ --e.g. because you suspect that the true generating model may be a non-invertible VARMA model-- you can directly proceed by IV-projection methods to obtain the $\tilde\Psi_{i,1,h}\equiv \Psi_{i,1,h}/b_{1,1}$ (that are the IRFs of $\tilde\eta_{1,t}$ on $y_{i,t}$).

However, Assumptions (IV.i) and (IV.ii) (Eq. \@ref(eq:IV1)) have to be complemented with (IV.iii):
\begin{equation*}
\begin{array}{llll}
(IV.iii) & \mathbb{E}(z_t \eta_{j,t+h}) &= 0 \, \mbox{ for } h \ne 0 & \mbox{(lead-lag exogeneity)}
\end{array}
\end{equation*}

When (IV.i), (IV.ii) and (IV.iii) are satisfied, $\tilde\Psi_{i,1,h}$ can be estimated by regressing $y_{i,t+h}$ on $y_{1,t}$, using $z_t$ as an instrument, i.e. by considering the TSLS estimation of:
\begin{equation}
y_{i,t+h} = \alpha_i + \tilde\Psi_{i,1,h}y_{1,t} + \nu_{i,t+h},(\#eq:regIV1)
\end{equation}
where $\nu_{i,t+h}$ is correlated to $y_{1,t}$, but not to $z_t$.

We have indeed:
\begin{eqnarray*}
y_{1,t} &=& \alpha_1 + \tilde\eta_{1,t} + v_{1,t}\\
y_{i,t+h} &=& \alpha_i + \tilde\Psi_{i,1,h}\tilde\eta_{1,t} + v_{i,t+h},
\end{eqnarray*}
where the $v_{i,t+h}$'s are uncorrelated to $z_t$ under (IV.i), (IV.ii) and (IV.iii).
\item Note again that, for $h>0$, the $v_{i,t+h}$ (and $\nu_{i,t+h}$) are auto-correlated. Newey-West corrections therefore have to be used to compute std errors of the $\tilde\Psi_{i,1,h}$'s estimates. 

Consider the linear regression:
$$
\bv{Y} = \bv{X}\boldsymbol\beta + \boldsymbol\varepsilon,
$$
where $\mathbb{E}(\boldsymbol\varepsilon)=0$, but where the explicative variables $\bv{X}$ are supposed to be correlated to the residuals $\boldsymbol\varepsilon$. 

Moreover, the $\boldsymbol\varepsilon$ are supposed to be possibly heteroskedastic and auto-correlated.

We consider the instruments $\bv{Z}$, with $\mathbb{E}(\bv{X}'\bv{Z}) \ne 0$ but $\mathbb{E}(\boldsymbol\varepsilon'\bv{Z}) = 0$.

The IV estimator of $\boldsymbol\beta$ is obtained by regressing $\hat{\bv{Y}}$ on $\hat{\bv{X}}$, where $\hat{\bv{Y}}$ and $\hat{\bv{X}}$ are the respective residuals of the regressions of $\bv{Y}$ and $\bv{X}$ on $\bv{Z}$.
\begin{eqnarray*}
\bv{b}_{iv} &=& [\bv{X}'\bv{Z}(\bv{Z}'\bv{Z})^{-1}\bv{Z}'\bv{X}]^{-1}\bv{X}'\bv{Z}(\bv{Z}'\bv{Z})^{-1}\bv{Z}'\bv{Y}\\
\bv{b}_{iv} &=& \boldsymbol\beta + \frac{1}{\sqrt{T}}\underbrace{T[\bv{X}'\bv{Z}(\bv{Z}'\bv{Z})^{-1}\bv{Z}'\bv{X}]^{-1}\bv{X}'\bv{Z}(\bv{Z}'\bv{Z})^{-1}}_{=Q(\bv{X},\bv{Z}) \overset{p}{\rightarrow} \bv{Q}_{xz}}\underbrace{\sqrt{T}\left(\frac{1}{T}\bv{Z}'\boldsymbol\varepsilon\right)}_{\overset{d}{\rightarrow} \mathcal{N}(0,S)},
\end{eqnarray*}
where $\bv{S}$ is the long-run variance of $\bv{z}_t\varepsilon_t$ (see next slide).

The asymptotic covariance matrix of $\sqrt{T}\bv{b}_{iv}$ is $\bv{Q}_{xz} \bv{S} \bv{Q}_{xz}'$.

The covariance matrix of $\bv{b}_{iv}$ can be approximated by $\frac{1}{T}Q(\bv{X},\bv{Z})\hat{\bv{S}}Q(\bv{X},\bv{Z})'$ where $\hat{\bv{S}}$ is the Newey-West estimator of $\bv{S}$ (see XXXXXX)


(IV.iii) is usually not restrictive for $h>0$ ($z_t$ is usually not affected by future shocks). By contrast, it may be restrictive for $h<0$.

This can be solved by adding controls in Regression \@ref(eq:regIV1).

These controls should span the space of $\{\eta_{t-1},\eta_{t-2},\dots\}$.

If $z_t$ is  suspected to be correlated to past values of $\eta_{1,t}$ but not to the $\eta_{j,t}$'s, $j>1$, then one can add lags of $z_t$ as controls (method e.g. advocated by Ramey, 2016, p.108, considering the instrument by Gertler and Karadi, 2015).

In the general case, one can use lags of $y_t$ as controls. Note that, even if (IV.iii) holds, adding controls may reduce the variance of the regression error.

As noted by [Stock and Watson (2018)](https://onlinelibrary.wiley.com/doi/abs/10.1111/ecoj.12593), the relevant variance is the long-run variance of the instrument-times-error term. They also recommend (p.926) using leads and lags of $z_t$ to improve efficiency.




