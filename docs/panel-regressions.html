<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Panel regressions | Advanced Econometrics</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.27 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Panel regressions | Advanced Econometrics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Panel regressions | Advanced Econometrics" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Jean-Paul Renne" />


<meta name="date" content="2022-08-11" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="linear-regressions.html"/>
<link rel="next" href="estimation-methods.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Advanced Econometrics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prerequisites</a></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a></li>
<li class="chapter" data-level="3" data-path="linear-regressions.html"><a href="linear-regressions.html"><i class="fa fa-check"></i><b>3</b> Linear Regressions</a>
<ul>
<li class="chapter" data-level="3.1" data-path="linear-regressions.html"><a href="linear-regressions.html#specification"><i class="fa fa-check"></i><b>3.1</b> Specification</a></li>
<li class="chapter" data-level="3.2" data-path="linear-regressions.html"><a href="linear-regressions.html#least-square-estimation"><i class="fa fa-check"></i><b>3.2</b> Least square estimation</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="linear-regressions.html"><a href="linear-regressions.html#bivariate-case"><i class="fa fa-check"></i><b>3.2.1</b> Bivariate case</a></li>
<li class="chapter" data-level="3.2.2" data-path="linear-regressions.html"><a href="linear-regressions.html#gauss-markow-theorem"><i class="fa fa-check"></i><b>3.2.2</b> Gauss Markow Theorem</a></li>
<li class="chapter" data-level="3.2.3" data-path="linear-regressions.html"><a href="linear-regressions.html#frish-waugh"><i class="fa fa-check"></i><b>3.2.3</b> Frish-Waugh</a></li>
<li class="chapter" data-level="3.2.4" data-path="linear-regressions.html"><a href="linear-regressions.html#goodness-of-fit"><i class="fa fa-check"></i><b>3.2.4</b> Goodness of fit</a></li>
<li class="chapter" data-level="3.2.5" data-path="linear-regressions.html"><a href="linear-regressions.html#inference-and-prediction"><i class="fa fa-check"></i><b>3.2.5</b> Inference and Prediction</a></li>
<li class="chapter" data-level="3.2.6" data-path="linear-regressions.html"><a href="linear-regressions.html#confidence-interval-of-beta_k"><i class="fa fa-check"></i><b>3.2.6</b> Confidence interval of <span class="math inline">\(\beta_k\)</span></a></li>
<li class="chapter" data-level="3.2.7" data-path="linear-regressions.html"><a href="linear-regressions.html#example"><i class="fa fa-check"></i><b>3.2.7</b> Example</a></li>
<li class="chapter" data-level="3.2.8" data-path="linear-regressions.html"><a href="linear-regressions.html#set-of-linear-restrictions"><i class="fa fa-check"></i><b>3.2.8</b> Set of linear restrictions</a></li>
<li class="chapter" data-level="3.2.9" data-path="linear-regressions.html"><a href="linear-regressions.html#common-pitfalls"><i class="fa fa-check"></i><b>3.2.9</b> Common pitfalls</a></li>
<li class="chapter" data-level="3.2.10" data-path="linear-regressions.html"><a href="linear-regressions.html#multicollinearity"><i class="fa fa-check"></i><b>3.2.10</b> Multicollinearity</a></li>
<li class="chapter" data-level="3.2.11" data-path="linear-regressions.html"><a href="linear-regressions.html#omitted-variables"><i class="fa fa-check"></i><b>3.2.11</b> Omitted variables</a></li>
<li class="chapter" data-level="3.2.12" data-path="linear-regressions.html"><a href="linear-regressions.html#irrelevant-variable"><i class="fa fa-check"></i><b>3.2.12</b> Irrelevant variable</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="linear-regressions.html"><a href="linear-regressions.html#large-sample-properties"><i class="fa fa-check"></i><b>3.3</b> Large Sample Properties</a></li>
<li class="chapter" data-level="3.4" data-path="linear-regressions.html"><a href="linear-regressions.html#instrumental-variables"><i class="fa fa-check"></i><b>3.4</b> Instrumental Variables</a></li>
<li class="chapter" data-level="3.5" data-path="linear-regressions.html"><a href="linear-regressions.html#general-regression-model"><i class="fa fa-check"></i><b>3.5</b> General Regression Model</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="linear-regressions.html"><a href="linear-regressions.html#generalized-least-squares"><i class="fa fa-check"></i><b>3.5.1</b> Generalized Least Squares</a></li>
<li class="chapter" data-level="3.5.2" data-path="linear-regressions.html"><a href="linear-regressions.html#heteroskedasticity-and-autocorrelation-hac"><i class="fa fa-check"></i><b>3.5.2</b> Heteroskedasticity and Autocorrelation (HAC)</a></li>
<li class="chapter" data-level="3.5.3" data-path="linear-regressions.html"><a href="linear-regressions.html#how-to-detect-autocorrelation-in-residuals"><i class="fa fa-check"></i><b>3.5.3</b> How to detect autocorrelation in residuals?</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="linear-regressions.html"><a href="linear-regressions.html#summary"><i class="fa fa-check"></i><b>3.6</b> Summary</a></li>
<li class="chapter" data-level="3.7" data-path="linear-regressions.html"><a href="linear-regressions.html#clusters"><i class="fa fa-check"></i><b>3.7</b> Clusters</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="panel-regressions.html"><a href="panel-regressions.html"><i class="fa fa-check"></i><b>4</b> Panel regressions</a>
<ul>
<li class="chapter" data-level="4.0.1" data-path="panel-regressions.html"><a href="panel-regressions.html#three-standard-cases"><i class="fa fa-check"></i><b>4.0.1</b> Three standard cases</a></li>
<li class="chapter" data-level="4.1" data-path="panel-regressions.html"><a href="panel-regressions.html#estimation-of-fixed-effects-models"><i class="fa fa-check"></i><b>4.1</b> Estimation of Fixed Effects Models</a></li>
<li class="chapter" data-level="4.2" data-path="panel-regressions.html"><a href="panel-regressions.html#estimation-of-random-effects-models"><i class="fa fa-check"></i><b>4.2</b> Estimation of random effects models</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="estimation-methods.html"><a href="estimation-methods.html"><i class="fa fa-check"></i><b>5</b> Estimation Methods</a>
<ul>
<li class="chapter" data-level="5.1" data-path="estimation-methods.html"><a href="estimation-methods.html#generalized-method-of-moments"><i class="fa fa-check"></i><b>5.1</b> Generalized Method of Moments</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="estimation-methods.html"><a href="estimation-methods.html#framework"><i class="fa fa-check"></i><b>5.1.1</b> Framework</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="estimation-methods.html"><a href="estimation-methods.html#maximum-likelihood-estimation"><i class="fa fa-check"></i><b>5.2</b> Maximum Likelihood Estimation</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="estimation-methods.html"><a href="estimation-methods.html#notations"><i class="fa fa-check"></i><b>5.2.1</b> Notations</a></li>
<li class="chapter" data-level="5.2.2" data-path="estimation-methods.html"><a href="estimation-methods.html#to-sum-up-mle-in-practice"><i class="fa fa-check"></i><b>5.2.2</b> To sum up – MLE in practice</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="microeconometrics.html"><a href="microeconometrics.html"><i class="fa fa-check"></i><b>6</b> Microeconometrics</a></li>
<li class="chapter" data-level="7" data-path="time-series.html"><a href="time-series.html"><i class="fa fa-check"></i><b>7</b> Time Series</a></li>
<li class="chapter" data-level="8" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>8</b> Appendix</a>
<ul>
<li class="chapter" data-level="8.1" data-path="appendix.html"><a href="appendix.html#statitical-tables"><i class="fa fa-check"></i><b>8.1</b> Statitical Tables</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Advanced Econometrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="panel-regressions" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">Chapter 4</span> Panel regressions<a href="panel-regressions.html#panel-regressions" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>The standard panel situation is the following: we have a lot of entities (<span class="math inline">\(i \in \{1,\dots,n\}\)</span>) and, for each entity, we observe different variables over a small number of periods (<span class="math inline">\(t \in \{1,\dots,T\}\)</span>). This is a <em>longitudinal dataset</em>.</p>
<p>The regression then reads:
<span class="math display">\[
y_{i,t} = \mathbf{x}&#39;_{i,t}\underbrace{\boldsymbol\beta}_{K \times 1} + \underbrace{\mathbf{z}&#39;_{i}\boldsymbol\alpha}_{\mbox{Individual effects}} + \varepsilon_{i,t}
\]</span>
Our objective is to estimate the previous equation.</p>
<!-- \includegraphics[width=.95\linewidth]{../../figures/Figure_Panel_simul0.pdf} -->
<p>Figure <a href="panel-regressions.html#fig:simulPanel">4.1</a>. The model is <span class="math inline">\(y_i = \alpha_i + \beta x_{i,t} + \varepsilon_{i,t}\)</span>, <span class="math inline">\(t \in \{1,2\}\)</span>. On Panel (b), blue dots are for <span class="math inline">\(t=1\)</span>, red dots are for <span class="math inline">\(t=2\)</span>. The lines relate the dots associated to the same entity <span class="math inline">\(i\)</span>.</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="panel-regressions.html#cb48-1" aria-hidden="true" tabindex="-1"></a>T <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="co"># 2 periods</span></span>
<span id="cb48-2"><a href="panel-regressions.html#cb48-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">12</span> <span class="co"># 12 entities</span></span>
<span id="cb48-3"><a href="panel-regressions.html#cb48-3" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="dv">5</span><span class="sc">*</span><span class="fu">rnorm</span>(n) <span class="co"># draw fixed effects</span></span>
<span id="cb48-4"><a href="panel-regressions.html#cb48-4" aria-hidden="true" tabindex="-1"></a>x<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n) <span class="sc">-</span> .<span class="dv">5</span><span class="sc">*</span>alpha <span class="co"># note: x_i&#39;s correlate to alpha_i&#39;s</span></span>
<span id="cb48-5"><a href="panel-regressions.html#cb48-5" aria-hidden="true" tabindex="-1"></a>x<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n) <span class="sc">-</span> .<span class="dv">5</span><span class="sc">*</span>alpha</span>
<span id="cb48-6"><a href="panel-regressions.html#cb48-6" aria-hidden="true" tabindex="-1"></a>beta <span class="ot">&lt;-</span> <span class="dv">5</span>; sigma <span class="ot">&lt;-</span> .<span class="dv">3</span></span>
<span id="cb48-7"><a href="panel-regressions.html#cb48-7" aria-hidden="true" tabindex="-1"></a>y<span class="fl">.1</span> <span class="ot">&lt;-</span> alpha <span class="sc">+</span> x<span class="fl">.1</span> <span class="sc">+</span> sigma<span class="sc">*</span><span class="fu">rnorm</span>(n)</span>
<span id="cb48-8"><a href="panel-regressions.html#cb48-8" aria-hidden="true" tabindex="-1"></a>y<span class="fl">.2</span> <span class="ot">&lt;-</span> alpha <span class="sc">+</span> x<span class="fl">.2</span> <span class="sc">+</span> sigma<span class="sc">*</span><span class="fu">rnorm</span>(n)</span>
<span id="cb48-9"><a href="panel-regressions.html#cb48-9" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(x<span class="fl">.1</span>,x<span class="fl">.2</span>) <span class="co"># pooled x</span></span>
<span id="cb48-10"><a href="panel-regressions.html#cb48-10" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">c</span>(y<span class="fl">.1</span>,y<span class="fl">.2</span>) <span class="co"># pooled y</span></span>
<span id="cb48-11"><a href="panel-regressions.html#cb48-11" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb48-12"><a href="panel-regressions.html#cb48-12" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x,y,<span class="at">col=</span><span class="st">&quot;black&quot;</span>,<span class="at">pch=</span><span class="dv">19</span>,<span class="at">xlab=</span><span class="st">&quot;x&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;y&quot;</span>,<span class="at">main=</span><span class="st">&quot;(a)&quot;</span>)</span>
<span id="cb48-13"><a href="panel-regressions.html#cb48-13" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x,y,<span class="at">col=</span><span class="st">&quot;black&quot;</span>,<span class="at">pch=</span><span class="dv">19</span>,<span class="at">xlab=</span><span class="st">&quot;x&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;y&quot;</span>,<span class="at">main=</span><span class="st">&quot;(b)&quot;</span>)</span>
<span id="cb48-14"><a href="panel-regressions.html#cb48-14" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x<span class="fl">.1</span>,y<span class="fl">.1</span>,<span class="at">col=</span><span class="st">&quot;blue&quot;</span>,<span class="at">pch=</span><span class="dv">19</span>)</span>
<span id="cb48-15"><a href="panel-regressions.html#cb48-15" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x<span class="fl">.2</span>,y<span class="fl">.2</span>,<span class="at">col=</span><span class="st">&quot;red&quot;</span>,<span class="at">pch=</span><span class="dv">19</span>)</span>
<span id="cb48-16"><a href="panel-regressions.html#cb48-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n){</span>
<span id="cb48-17"><a href="panel-regressions.html#cb48-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(<span class="fu">c</span>(x<span class="fl">.1</span>[i],x<span class="fl">.2</span>[i]),<span class="fu">c</span>(y<span class="fl">.1</span>[i],y<span class="fl">.2</span>[i]))</span>
<span id="cb48-18"><a href="panel-regressions.html#cb48-18" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:simulPanel"></span>
<img src="AdvECTS_files/figure-html/simulPanel-1.png" alt="The data are the same for both panels. On Panel (b), blue dots are for $t=1$, red dots are for $t=2$. The lines relate the dots associated to the same entity $i$." width="90%" />
<p class="caption">
Figure 4.1: The data are the same for both panels. On Panel (b), blue dots are for <span class="math inline">\(t=1\)</span>, red dots are for <span class="math inline">\(t=2\)</span>. The lines relate the dots associated to the same entity <span class="math inline">\(i\)</span>.
</p>
</div>
<p>Let us know use the <a href="https://rdrr.io/cran/AER/man/CigarettesSW.html">Cigarette Consumption Panel dataset</a> of <a href="https://www.pearson.com/en-gb/subject-catalog/p/Stock-Introduction-to-Econometrics-Global-Edition-4th-Edition/P200000005500/9781292264523">Stock and Watson (2007)</a></p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="panel-regressions.html#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;CigarettesSW&quot;</span>, <span class="at">package =</span> <span class="st">&quot;AER&quot;</span>)</span>
<span id="cb49-2"><a href="panel-regressions.html#cb49-2" aria-hidden="true" tabindex="-1"></a>CigarettesSW<span class="sc">$</span>rprice  <span class="ot">&lt;-</span> <span class="fu">with</span>(CigarettesSW, price<span class="sc">/</span>cpi)</span>
<span id="cb49-3"><a href="panel-regressions.html#cb49-3" aria-hidden="true" tabindex="-1"></a>CigarettesSW<span class="sc">$</span>rincome <span class="ot">&lt;-</span> <span class="fu">with</span>(CigarettesSW, income<span class="sc">/</span>population<span class="sc">/</span>cpi)</span>
<span id="cb49-4"><a href="panel-regressions.html#cb49-4" aria-hidden="true" tabindex="-1"></a>T <span class="ot">&lt;-</span> <span class="fu">length</span>(<span class="fu">levels</span>(CigarettesSW<span class="sc">$</span>year))</span>
<span id="cb49-5"><a href="panel-regressions.html#cb49-5" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(<span class="fu">levels</span>(CigarettesSW<span class="sc">$</span>state))</span>
<span id="cb49-6"><a href="panel-regressions.html#cb49-6" aria-hidden="true" tabindex="-1"></a>eq.pooled <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="fu">log</span>(packs)<span class="sc">~</span><span class="fu">log</span>(rprice)<span class="sc">+</span><span class="fu">log</span>(rincome),<span class="at">data=</span>CigarettesSW)</span>
<span id="cb49-7"><a href="panel-regressions.html#cb49-7" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">summary</span>(eq.pooled)<span class="sc">$</span>coefficients)</span></code></pre></div>
<pre><code>##                Estimate Std. Error   t value     Pr(&gt;|t|)
## (Intercept)  10.0671678  0.5156035 19.525020 1.158630e-34
## log(rprice)  -1.3341612  0.1353614 -9.856288 4.120472e-16
## log(rincome)  0.3181371  0.1361194  2.337191 2.157508e-02</code></pre>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="panel-regressions.html#cb51-1" aria-hidden="true" tabindex="-1"></a>eq.LSDV <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="fu">log</span>(packs)<span class="sc">~</span><span class="fu">log</span>(rprice)<span class="sc">+</span><span class="fu">log</span>(rincome)<span class="sc">+</span>state,</span>
<span id="cb51-2"><a href="panel-regressions.html#cb51-2" aria-hidden="true" tabindex="-1"></a>              <span class="at">data=</span>CigarettesSW)</span>
<span id="cb51-3"><a href="panel-regressions.html#cb51-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">summary</span>(eq.LSDV)<span class="sc">$</span>coefficients[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>,])</span></code></pre></div>
<pre><code>##                Estimate Std. Error   t value     Pr(&gt;|t|)
## (Intercept)   9.9543751  0.2641889  37.67901 3.156258e-36
## log(rprice)  -1.2103380  0.1138384 -10.63207 5.590562e-14
## log(rincome)  0.1209004  0.1901069   0.63596 5.279541e-01</code></pre>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="panel-regressions.html#cb53-1" aria-hidden="true" tabindex="-1"></a>CigarettesSW<span class="sc">$</span>year <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(CigarettesSW<span class="sc">$</span>year)</span>
<span id="cb53-2"><a href="panel-regressions.html#cb53-2" aria-hidden="true" tabindex="-1"></a>eq.LSDV2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="fu">log</span>(packs)<span class="sc">~</span><span class="fu">log</span>(rprice)<span class="sc">+</span><span class="fu">log</span>(rincome)<span class="sc">+</span>state<span class="sc">+</span>year,</span>
<span id="cb53-3"><a href="panel-regressions.html#cb53-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">data=</span>CigarettesSW)</span>
<span id="cb53-4"><a href="panel-regressions.html#cb53-4" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">summary</span>(eq.LSDV2)<span class="sc">$</span>coefficients[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>,])</span></code></pre></div>
<pre><code>##                Estimate Std. Error   t value     Pr(&gt;|t|)
## (Intercept)   8.3597463  1.0485390  7.972757 3.776672e-10
## log(rprice)  -1.0559739  0.1490905 -7.082770 7.682380e-09
## log(rincome)  0.4974424  0.3042306  1.635084 1.090085e-01</code></pre>
<!-- \includegraphics[width=.95\linewidth]{../../figures/Figure_Panel_cigarettes0.pdf} -->
<p>Cigarettes data from <a href="https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Cigarette.html">Stock and Watson (2003)</a>. Data for U.S. states, 2 years: 1985 and 1995. Each colour corresponds to a given State.</p>
<p>Airlines: cost versus fuel price</p>
<!-- \includegraphics[width=.95\linewidth]{../../figures/Figure_Panel_airline1.pdf} -->
<p>Airlines data from <a href="https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Airline.html">Greene (2003)</a>. Each colour corresponds to a given airline.</p>
<p>Notations:
<span class="math display">\[
\mathbf{y}_i =
\underbrace{\left[
\begin{array}{c}
y_{i,1}\\
\vdots\\
y_{i,T}
\end{array}\right]}_{T \times 1}, \quad
\boldsymbol\varepsilon_i =
\underbrace{\left[
\begin{array}{c}
\varepsilon_{i,1}\\
\vdots\\
\varepsilon_{i,T}
\end{array}\right]}_{T \times 1}, \quad
\mathbf{x}_i =
\underbrace{\left[
\begin{array}{c}
\mathbf{x}_{i,1}&#39;\\
\vdots\\
\mathbf{x}_{i,T}&#39;
\end{array}\right]}_{T \times K}, \quad
\mathbf{X} =
\underbrace{\left[
\begin{array}{c}
\mathbf{x}_{1}\\
\vdots\\
\mathbf{x}_{n}
\end{array}\right]}_{(nT) \times K}.
\]</span>
<span class="math display">\[
\tilde{\mathbf{y}}_i =
\left[
\begin{array}{c}
y_{i,1} - \bar{y}_i\\
\vdots\\
y_{i,T} - \bar{y}_i
\end{array}\right], \quad
\tilde{\boldsymbol\varepsilon}_i =
\left[
\begin{array}{c}
\varepsilon_{i,1} - \bar{\varepsilon}_i\\
\vdots\\
\varepsilon_{i,T} - \bar{\varepsilon}_i
\end{array}\right],
\]</span>
<span class="math display">\[
\tilde{\mathbf{x}}_i =
\left[
\begin{array}{c}
\mathbf{x}_{i,1}&#39; - \bar{\mathbf{x}}_i&#39;\\
\vdots\\
\mathbf{x}_{i,T}&#39; - \bar{\mathbf{x}}_i&#39;
\end{array}\right], \quad
\tilde{\mathbf{X}} =
\left[
\begin{array}{c}
\tilde{\mathbf{x}}_{1}\\
\vdots\\
\tilde{\mathbf{x}}_{n}
\end{array}\right], \quad
\tilde{\mathbf{Y}} =
\left[
\begin{array}{c}
\tilde{\mathbf{y}}_{1}\\
\vdots\\
\tilde{\mathbf{y}}_{n}
\end{array}\right],
\]</span>
where
<span class="math display">\[
\bar{y}_i = \frac{1}{T} \sum_{t=1}^T y_{i,t}, \quad \bar{\varepsilon}_i = \frac{1}{T}\sum_{t=1}^T \varepsilon_{i,t} \quad \mbox{and} \quad \bar{\mathbf{x}}_i = \frac{1}{T}\sum_{t=1}^T \mathbf{x}_{i,t}.
\]</span></p>
<div id="three-standard-cases" class="section level3 hasAnchor" number="4.0.1">
<h3><span class="header-section-number">4.0.1</span> Three standard cases<a href="panel-regressions.html#three-standard-cases" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><strong>Pooled regression</strong>: <span class="math inline">\(\mathbf{z}_i \equiv 1\)</span>.</li>
<li><strong>Fixed Effects</strong>: <span class="math inline">\(\mathbf{z}_i\)</span> is unobserved, but correlates with <span class="math inline">\(\mathbf{x}_i\)</span> <span class="math inline">\(\Rightarrow\)</span> <span class="math inline">\(\mathbf{b}\)</span> is biased and inconsistent in the OLS regression of <span class="math inline">\(\mathbf{y}\)</span> on <span class="math inline">\(\mathbf{X}\)</span> (omitted variable, see XXX).</li>
<li><strong>Random Effects</strong>: <span class="math inline">\(\mathbf{z}_i\)</span> is unobserved, but uncorrelated with <span class="math inline">\(\mathbf{x}_i\)</span>. The model writes:
<span class="math display">\[
y_{i,t} = \mathbf{x}&#39;_{i,t}\boldsymbol\beta + \alpha +  \underbrace{{\color{blue}u_i + \varepsilon_{i,t}}}_{\mbox{compound disturbance}},
\]</span>
where <span class="math inline">\(\alpha = \mathbb{E}(\mathbf{z}&#39;_{i}\boldsymbol\alpha)\)</span> and <span class="math inline">\(u_i = \mathbf{z}&#39;_{i}\boldsymbol\alpha - \mathbb{E}(\mathbf{z}&#39;_{i}\boldsymbol\alpha) \perp \mathbf{x}_i\)</span>.</li>
</ul>
<p>Least squares are consistent (but inefficient, see GLS XXXX).</p>
</div>
<div id="estimation-of-fixed-effects-models" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> Estimation of Fixed Effects Models<a href="panel-regressions.html#estimation-of-fixed-effects-models" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<hr />
<div class="hypothesis">
<p><span id="hyp:FE" class="hypothesis"><strong>Hypothesis 4.1  (Fixed-effect model) </strong></span>We assume that:</p>
<ol style="list-style-type: lower-roman">
<li>There is no perfect multicollinearity among the regressors.</li>
<li><span class="math inline">\(\mathbb{E}(\varepsilon_{i,t}|\mathbf{X})=0\)</span>, for all <span class="math inline">\(i,t\)</span>.</li>
<li>We have:
<span class="math display">\[
\mathbb{E}(\varepsilon_{i,t}\varepsilon_{j,s}|\mathbf{X}) =
\left\{
\begin{array}{cl}
\sigma^2 &amp; \mbox{if $i=j$ and $s=t$},\\
0 &amp; \mbox{otherwise.}
\end{array}\right.
\]</span></li>
</ol>
</div>
<hr />
<p>These assumptions are analogous to those introduced in the standard linear regression:</p>
<ol style="list-style-type: lower-roman">
<li><span class="math inline">\(\leftrightarrow\)</span> <a href="linear-regressions.html#hyp:fullrank">3.1</a>, (ii) <span class="math inline">\(\leftrightarrow\)</span> <a href="linear-regressions.html#hyp:exogeneity">3.2</a>, (iii) <span class="math inline">\(\leftrightarrow\)</span> <a href="linear-regressions.html#hyp:homoskedasticity">3.3</a> + <a href="linear-regressions.html#hyp:noncorrelResid">3.4</a>.</li>
</ol>
<p>In matrix form, for a given <span class="math inline">\(i\)</span>, the model writes:
<span class="math display">\[
\mathbf{y}_i = \mathbf{X}_i \boldsymbol\beta + \mathbf{1}\alpha_i + \boldsymbol\varepsilon_i,
\]</span>
where <span class="math inline">\(\mathbf{1}\)</span> is a <span class="math inline">\(T\)</span>-dimensional vector of ones.</p>
<p>This is the <strong>Least Square Dummy Variable (LSDV)</strong> model:
<span class="math display" id="eq:LSDV">\[\begin{equation}
\boxed{\mathbf{y} = [\mathbf{X} \quad \mathbf{D}]
\left[
\begin{array}{c}
\boldsymbol\beta\\
\boldsymbol\alpha
\end{array}
\right]
+ \boldsymbol\varepsilon,} \tag{4.1}
\end{equation}\]</span>
with:
<span class="math display">\[
\mathbf{D} = \underbrace{ \left[\begin{array}{cccc}
\mathbf{1}&amp;\mathbf{0}&amp;\dots&amp;\mathbf{0}\\
\mathbf{0}&amp;\mathbf{1}&amp;\dots&amp;\mathbf{0}\\
&amp;&amp;\vdots&amp;\\
\mathbf{0}&amp;\mathbf{0}&amp;\dots&amp;\mathbf{1}\\
\end{array}\right]}_{(nT \times n)}.
\]</span></p>
<p>The linear regression (Eq. <a href="panel-regressions.html#eq:LSDV">(4.1)</a>) –with the dummy variables– satisfies the Gauss-Markov conditions (Theorem <a href="linear-regressions.html#thm:GaussMarkov">3.1</a>). Hence, in this context, the OLS estimator is the <strong>best linear unbiased estimator</strong>.</p>
<p>Denoting by <span class="math inline">\(\mathbf{Z}\)</span> the matrix <span class="math inline">\([\mathbf{X} \quad \mathbf{D}]\)</span>, and by <span class="math inline">\(\mathbf{b}\)</span> and <span class="math inline">\(\mathbf{a}\)</span> the respective OLS estimates of <span class="math inline">\(\boldsymbol\beta\)</span> and of <span class="math inline">\(\boldsymbol\alpha\)</span>, we have:
<span class="math display" id="eq:bfixedeffects11">\[\begin{equation}
\boxed{
\left[
\begin{array}{c}
\mathbf{b}\\
\mathbf{a}
\end{array}
\right]
= [\mathbf{Z}&#39;\mathbf{Z}]^{-1}\mathbf{Z}&#39;\mathbf{y}.} \tag{4.2}
\end{equation}\]</span></p>
<p>The asymptotical distribution of <span class="math inline">\([\mathbf{b}&#39;,\mathbf{a}&#39;]&#39;\)</span> derives from the standard OLS context: Prop. <a href="linear-regressions.html#prp:asymptOLS">3.11</a> can be used after having replaced <span class="math inline">\(\mathbf{X}\)</span> by <span class="math inline">\(\mathbf{Z}=[\mathbf{X} \quad \mathbf{D}]\)</span>.</p>
<p>We have:
<span class="math display">\[\begin{equation}
\boxed{\left[
\begin{array}{c}
\mathbf{b}\\
\mathbf{a}
\end{array}
\right] \overset{d}{\rightarrow}
\mathcal{N}\left(
\left[
\begin{array}{c}
\boldsymbol\beta\\
\boldsymbol\alpha
\end{array}
\right],
\sigma^2 \frac{Q^{-1}}{nT}
\right)}
\end{equation}\]</span>
where
<span class="math display">\[
Q = \mbox{plim}_{nT \rightarrow \infty} \frac{1}{nT} \mathbf{Z}&#39;\mathbf{Z}.
\]</span></p>
<p>In practice, an estimator of the covariance matrix of <span class="math inline">\([\mathbf{b}&#39;,\mathbf{a}&#39;]&#39;\)</span> is:
<span class="math display">\[
s^2 \left( \mathbf{Z}&#39;\mathbf{Z}\right)^{-1} \quad with \quad s^2 = \frac{\mathbf{e}&#39;\mathbf{e}}{nT - K - n},
\]</span>
where <span class="math inline">\(\mathbf{e}\)</span> is the <span class="math inline">\((nT) \times 1\)</span> vector of OLS residuals.</p>
<p>There is an alternative way of expressing the LSDV estimators.</p>
<p>It is based on matrix <span class="math inline">\(\mathbf{M_D}=\mathbf{I} - \mathbf{D}(\mathbf{D}&#39;\mathbf{D})^{-1}\mathbf{D}&#39;\)</span>, which acts as an operator that removes entity-specific means, i.e.:
<span class="math display">\[
\tilde{\mathbf{Y}} = \mathbf{M_D}\mathbf{Y}, \quad \tilde{\mathbf{X}} = \mathbf{M_D}\mathbf{X} \quad and \quad \tilde{\boldsymbol\varepsilon} = \mathbf{M_D}\boldsymbol\varepsilon.
\]</span></p>
<p>With these notations, using Theorem <a href="linear-regressions.html#thm:FW">3.2</a>, we get:
<span class="math display" id="eq:bfixedeffects">\[\begin{equation}
\boxed{\mathbf{b} = [\mathbf{X}&#39;\mathbf{M_D}\mathbf{X}]^{-1}\mathbf{X}&#39;\mathbf{M_D}\mathbf{y}.}\tag{4.3}
\end{equation}\]</span></p>
<p>This amounts to regressing the <span class="math inline">\(\tilde{y}_{i,t}\)</span>s (<span class="math inline">\(= y_{i,t} - \bar{y}_i\)</span>) on the <span class="math inline">\(\tilde{\mathbf{x}}_{i,t}\)</span>s (<span class="math inline">\(=\mathbf{x}_{i,t} - \bar{\mathbf{x}}_i\)</span>).</p>
<p>The estimates of <span class="math inline">\(\boldsymbol\alpha\)</span> are given by:
<span class="math display" id="eq:a">\[\begin{equation}
\boxed{\mathbf{a} = (\mathbf{D}&#39;\mathbf{D})^{-1}\mathbf{D}&#39;(\mathbf{y} - \mathbf{X}\mathbf{b}),} \tag{4.4}
\end{equation}\]</span>
which is obtained by developing the second row of
<span class="math display">\[
\left[
\begin{array}{cc}
\mathbf{X}&#39;\mathbf{X} &amp; \mathbf{X}&#39;\mathbf{D}\\
\mathbf{D}&#39;\mathbf{X} &amp; \mathbf{D}&#39;\mathbf{D}
\end{array}\right]
\left[
\begin{array}{c}
\mathbf{b}\\
\mathbf{a}
\end{array}\right] =
\left[
\begin{array}{c}
\mathbf{X}&#39;\mathbf{Y}\\
\mathbf{D}&#39;\mathbf{Y}
\end{array}\right],
\]</span>
which are the first-order conditions resulting from the least squares problem (see Eq. <a href="linear-regressions.html#eq:OLSFOC">(3.1)</a>).</p>
<p>XXXX Regression of the log of airline costs on log(output), log(fuel price) and capacity utilization of the fleet (Data from , see Fig. <a href="#fig:airline"><strong>??</strong></a>.</p>
<p>XXXX Regression of the number of cigarette packs (log) on real income (log) and real price of cigarettes (log)</p>
<!-- %\begin{frame}{} -->
<!-- %\begin{scriptsize} -->
<!-- %Look at: -->
<!-- %http://www.princeton.edu/~otorres/Panel101R.pdf -->
<!-- % -->
<!-- %Nice chart with OLS versus LSDV. -->
<!-- % -->
<!-- %Use also Grunfeld data: -->
<!-- % -->
<!-- %https://vincentarelbundock.github.io/Rdatasets/doc/plm/Grunfeld.html -->
<!-- % -->
<!-- %===> Use Applied Econometrics with R 3.6: If $u_i$ exogen, then random effects more efficient. Hausman test. -->
<!-- % -->
<!-- %\end{scriptsize} -->
<!-- %\end{frame} -->
<p>Extension: Fixed time and group effects</p>
<p>Time effects are easily introduced:
<span class="math display">\[
y_{i,t} = \mathbf{x}_i&#39;\boldsymbol\beta + \alpha_i + \gamma_t + \varepsilon_{i,t}.
\]</span></p>
<p>The LSDV (Eq. <a href="panel-regressions.html#eq:LSDV">(4.1)</a>) can be extended:
<span class="math display" id="eq:LSDV2">\[\begin{equation}
\mathbf{y} = [\mathbf{X} \quad \mathbf{D} \quad \mathbf{C}]
\left[
\begin{array}{c}
\boldsymbol\beta\\
\boldsymbol\alpha\\
\boldsymbol\gamma
\end{array}
\right]
+ \boldsymbol\varepsilon, \tag{4.5}
\end{equation}\]</span>
with:
<span class="math display">\[
\mathbf{C} = \left[\begin{array}{cccc}
\boldsymbol{\delta}_1&amp;\boldsymbol{\delta}_2&amp;\dots&amp;\boldsymbol{\delta}_{T-1}\\
\vdots&amp;\vdots&amp;&amp;\vdots\\
\boldsymbol{\delta}_1&amp;\boldsymbol{\delta}_2&amp;\dots&amp;\boldsymbol{\delta}_{T-1}\\
\end{array}\right],
\]</span>
where the <span class="math inline">\(T\)</span>-dimensional vector <span class="math inline">\(\boldsymbol\delta_t\)</span> is
<span class="math display">\[
[0,\dots,0,\underbrace{1}_{\mbox{t$^{th}$ entry}},0,\dots,0]&#39;.
\]</span></p>
<p>XXXX Geo-located data from Airbnb, Z"urich</p>
<p>Source: <a href="http://tomslee.net/airbnb-data-collection-get-the-data">Airbnb, date 22 June 2017</a>. Regression of price for Entire home/apt on number of bedrooms, number of people that can be accommodated.</p>
</div>
<div id="estimation-of-random-effects-models" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">4.2</span> Estimation of random effects models<a href="panel-regressions.html#estimation-of-random-effects-models" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Here, the individual effects are assumed not to be correlated to other variables (the <span class="math inline">\(\mathbf{x}_i\)</span>s).</p>
<p><strong>Random-effect models</strong> write:
<span class="math display">\[
y_{i,t}=\mathbf{x}&#39;_{it}\boldsymbol\beta + (\alpha + \underbrace{u_i}_{\substack{\text{Random}\\\text{heterogeneity}}}) + \varepsilon_{i,t}
\]</span>
with
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}(\varepsilon_{i,t}|\mathbf{X})&amp;=&amp;\mathbb{E}(u_{i}|\mathbf{X}) =0,\\
\mathbb{E}(\varepsilon_{i,t}\varepsilon_{j,s}|\mathbf{X}) &amp;=&amp;
\left\{
\begin{array}{cl}
\sigma_\varepsilon^2 &amp; \mbox{ if $i=j$ and $s=t$},\\
0 &amp; \mbox{ otherwise.}
\end{array}
\right.\\
\mathbb{E}(u_{i}u_{j}|\mathbf{X}) &amp;=&amp;
\left\{
\begin{array}{cl}
\sigma_u^2 &amp; \mbox{ if $i=j$},\\
0 &amp; \mbox{otherwise.}
\end{array}
\right.\\
\mathbb{E}(\varepsilon_{i,t}u_{j}|\mathbf{X})&amp;=&amp;0 \quad \text{for all $i$, $j$ and $t$}.
\end{eqnarray*}\]</span></p>
<p>Notation: <span class="math inline">\(\eta_{i,t} = u_i + \varepsilon_{i,t}\)</span> and <span class="math inline">\(\boldsymbol\eta_i = [\eta_{i,1},\eta_{i,2},\dots,\eta_{i,T}]&#39;\)</span>.</p>
<p>We have <span class="math inline">\(\mathbb{E}(\boldsymbol\eta_i |\mathbf{X}) = \mathbf{0}\)</span> and <span class="math inline">\(\mathbb{V}ar(\boldsymbol\eta_i | \mathbf{X}) = \boldsymbol\Gamma\)</span> where
<span class="math display">\[
\boldsymbol\Gamma = \left[  \begin{array}{ccccc}
\sigma_\varepsilon^2+\sigma_u^2 &amp; \sigma_u^2 &amp; \sigma_u^2 &amp; \dots &amp; \sigma_u^2\\
\sigma_u^2 &amp; \sigma_\varepsilon^2+\sigma_u^2 &amp; \sigma_u^2 &amp; \dots &amp; \sigma_u^2\\
\vdots &amp;&amp; \ddots &amp;&amp; \vdots \\
\sigma_u^2 &amp; \sigma_u^2 &amp; \sigma_u^2 &amp; \dots &amp; \sigma_\varepsilon^2+\sigma_u^2\\
\end{array}
\right] = \sigma_\varepsilon^2\mathbf{I} + \sigma_u^2\mathbf{1}\mathbf{1}&#39;.
\]</span></p>
<p>Denoting by <span class="math inline">\(\boldsymbol\Sigma\)</span> the covariance matrix of <span class="math inline">\(\boldsymbol\eta = [\boldsymbol\eta_1&#39;,\dots,\boldsymbol\eta_n&#39;]&#39;\)</span>, we have:
<span class="math display">\[
\boldsymbol\Sigma = \mathbf{I} \otimes \boldsymbol\Gamma.
\]</span></p>
<p>If we knew <span class="math inline">\(\boldsymbol\Sigma\)</span>, we would apply (feasible) GLS (Eq. <a href="linear-regressions.html#eq:betaGLS">(3.28)</a>):
<span class="math display">\[
\boldsymbol\beta = (\mathbf{X}&#39;\boldsymbol\Sigma^{-1}\mathbf{X})^{-1}\mathbf{X}&#39;\boldsymbol\Sigma^{-1}\mathbf{y}
\]</span>
(recall that this amounts to regressing <span class="math inline">\({\boldsymbol\Sigma^{-1/2}}&#39;\mathbf{y}\)</span> on <span class="math inline">\({\boldsymbol\Sigma^{-1/2}}&#39;\mathbf{X}\)</span>).</p>
<p>It can be checked that <span class="math inline">\(\boldsymbol\Sigma^{-1/2} = \mathbf{I} \otimes (\boldsymbol\Gamma^{-1/2})\)</span> where
<span class="math display">\[
\boldsymbol\Gamma^{-1/2} = \frac{1}{\sigma_\varepsilon}\left( \mathbf{I} - \frac{\theta}{T}\mathbf{1}\mathbf{1}&#39;\right)
\]</span>
with
<span class="math display">\[
\theta = 1 - \frac{\sigma_\varepsilon}{\sqrt{\sigma_\varepsilon^2+T\sigma_u^2}}.
\]</span></p>
<p>Hence, if we knew <span class="math inline">\(\boldsymbol\Sigma\)</span>, we would transform the data as follows:
<span class="math display">\[
\boldsymbol\Gamma^{-1/2}\mathbf{y}_i = \frac{1}{\sigma_\varepsilon}\left[\begin{array}{c}y_{i,1} - \theta\bar{y}_i\\y_{i,2} - \theta\bar{y}_i\\\vdots\\y_{i,T} - \theta\bar{y}_i\\\end{array}\right].
\]</span></p>
<p>What about when <span class="math inline">\(\boldsymbol\Sigma\)</span> is unknown?</p>
<p>Idea: taking deviations from group means removes heterogeneity:
<span class="math display">\[
y_{i,t} - \bar{y}_i = [\mathbf{x}_{i,t} - \bar{\mathbf{x}}_i]&#39;\boldsymbol\beta + (\varepsilon_{i,t} - \bar{\varepsilon}_i).
\]</span></p>
<p>The previous equation can be consistently estimated by OLS</p>
<p>(the residuals are correlated across <span class="math inline">\(t\)</span> within an entity but the OLS remain consistent though, see Prop. @ref{prp:XXX)).</p>
<p>We have <span class="math inline">\(\mathbb{E}\left[\sum_{i=1}^{T}(\varepsilon_{i,t}-\bar{\varepsilon}_i)^2\right] = (T-1)\sigma_{\varepsilon}^2\)</span>.</p>
<p>The <span class="math inline">\(\varepsilon_{i,t}\)</span>s are not observed but <span class="math inline">\(\mathbf{b}\)</span> is a consistent estimator of <span class="math inline">\(\boldsymbol\beta\)</span>; adjustment for the degrees of freedom:
<span class="math display">\[
\hat{\sigma}_e^2 = \frac{1}{nT-n-K}\sum_{i=1}^{n}\sum_{t=1}^{T}(e_{i,t} - \bar{e}_i)^2.
\]</span></p>
<p>And for <span class="math inline">\(\sigma_u^2\)</span>? We can exploit the fact that OLS are consistent in the pooled regression:
<span class="math display">\[
\mbox{plim }s^2_{pooled} = \mbox{plim }\frac{\mathbf{e}&#39;\mathbf{e}}{nT-K-1} = \sigma_u^2 + \sigma_\varepsilon^2,
\]</span>
and therefore use <span class="math inline">\(s^2_{pooled} - \hat{\sigma}_e^2\)</span> as an approximation to <span class="math inline">\(\sigma_u^2\)</span>.</p>
<!-- %\begin{frame}{} -->
<!-- %\begin{scriptsize} -->
<!-- %\begin{itemize} -->
<!-- %  \item Breusch and Pagan LM test of $H_0: \quad \sigma_u^2=0$ (13.4.3 in Greene) -->
<!-- %  \item Hausman's specification test 13.4.4. -->
<!-- %  \item Cluster-robust standard errors (\href{http://cameron.econ.ucdavis.edu/research/Cameron_Miller_Cluster_Robust_October152013.pdf}{nice paper}) + \href{http://www.cemfi.es/~arellano/obes_1987.pdf}{Arellano (1987)} -->
<!-- %  \item Random versus Fixed effects: uncorrelated errors / LSDV: lose a lot of degrees of freedom. -->
<!-- %  \item \href{http://econweb.tamu.edu/keli/Hausman\%201978.pdf}{Hausman (1978)} test: $H_0:$ no correlation of random effects and regressors. -->
<!-- %\end{itemize} -->
<!-- %\end{scriptsize} -->
<!-- %\end{frame} -->
<!-- %\begin{frame}{} -->
<!-- %Instrumental Variable estimation of the random effect model -->
<!-- %\begin{scriptsize} -->
<!-- %\begin{itemize} -->
<!-- %  \item Objective: have a specification where the model can contain time-invariant characteristics. Specification: -->
<!-- %  $$ -->
<!-- %  y_{i,t} =   \underbrace{\bv{x}'_{1,i,t} \boldsymbol\beta_1}_{\perp u_i} + -->
<!-- %          \underbrace{\bv{x}'_{2,i,t} \boldsymbol\beta_2}_{\not\perp u_i} + -->
<!-- %          \underbrace{\bv{z}'_{1,i} \boldsymbol\alpha_1}_{\perp u_i} + -->
<!-- %          \underbrace{\bv{z}'_{2,i} \boldsymbol\alpha_2}_{\not\perp u_i} + \varepsilon_{i,t}. -->
<!-- %  $$ -->
<!-- %  \item Assumptions: -->
<!-- %  \begin{eqnarray*} -->
<!-- %  E(u_i) = E(u_i|\bv{x}_{1,i,t},\bv{z}_{1,i,t}) &=& 0\\ -->
<!-- %  E(u_i|\bv{x}_{2,i,t},\bv{z}_{2,i,t}) &\ne& 0\\ -->
<!-- %  \mbox{Var}(u_i|\bv{x}_{1,i,t},\bv{z}_{1,i,t},\bv{x}_{2,i,t},\bv{z}_{2,i,t})&=& \sigma_u^2\\ -->
<!-- %  \mbox{Cov}(u_i,\varepsilon_{i,t}|\bv{x}_{1,i,t},\bv{z}_{1,i,t},\bv{x}_{2,i,t},\bv{z}_{2,i,t})&=& 0\\ -->
<!-- %  \mbox{Var}(u_i + \varepsilon_{i,t}|\bv{x}_{1,i,t},\bv{z}_{1,i,t},\bv{x}_{2,i,t},\bv{z}_{2,i,t})&=& \sigma^2 = \sigma_u^2 + \sigma_\varepsilon^2\\ -->
<!-- %  \mbox{Corr}(u_i + \varepsilon_{i,t},u_i + \varepsilon_{i,s}|\bv{x}_{1,i,t},\bv{z}_{1,i,t},\bv{x}_{2,i,t},\bv{z}_{2,i,t})&=& \rho = \sigma_u^2/\sigma^2 -->
<!-- %  \end{eqnarray*}  -->
<!-- %\end{itemize} -->
<!-- %\end{scriptsize} -->
<!-- %\end{frame} -->
<!-- % -->
<!-- %\begin{frame}{} -->
<!-- %\begin{scriptsize} -->
<!-- %\begin{itemize} -->
<!-- %  \item OLS and GLS inconsistent. -->
<!-- %  \item \href{http://web.mit.edu/14.33/www/hausman.pdf}{Hausman and Taylor, 1981}. Example cited in the plm package by Baltagi (2001) (with data in the plm package). -->
<!-- %  \item First: -->
<!-- %  \begin{equation}\label{eq:13.36} -->
<!-- %  y_{i,t} - \bar{y}_i = [\bv{x}_{1,i,t} - \bar{\bv{x}}_{1,i}]'\boldsymbol\beta_1 + [\bv{x}_{2,i,t} - \bar{\bv{x}}_{2,i}]'\boldsymbol\beta_2 + (\varepsilon_{i,t} - \bar{\varepsilon}_i) -->
<!-- %  \end{equation} -->
<!-- %  \item[$\Rightarrow$] $\boldsymbol\beta$ can consistently be estimated by LS. -->
<!-- %  \item[Step 1] LSDV of $\boldsymbol\beta$ (Eq. \ref{eq:13.36})  -->
<!-- %  \item[Step 2] residuals of step 1: $e_{i,t}$. Regress $e_{i}$ on $(\bv{z}_1',\bv{z}_2')'$ with IV $\bv{z}_1$ and $\bv{x}_1$ (assuming $K_1\ge L_2$). NB: time-invariant data are repeated $T$ times. $\Rightarrow$ consistent estimate of $\boldsymbol\alpha$. -->
<!-- %  \item[Step 3] The residual variance in Step 2 = consistent estimator of $\sigma_u^2 + \sigma^2_\varepsilon/T$. From and from the estimator of $\sigma^2_\varepsilon$ from Step 1, estimator of $\sigma^2_u$. This leads to an estimate $\hat{\theta}$ of: -->
<!-- %  $$ -->
<!-- %  \theta = \sqrt{\frac{\sigma^2_\varepsilon}{\sigma^2_\varepsilon + T\sigma^2_u}} -->
<!-- %  $$ -->
<!-- %  that can  be used in Feasible GLS. -->
<!-- %\end{itemize} -->
<!-- %\end{scriptsize} -->
<!-- %\end{frame} -->
<!-- % -->
<!-- %\begin{frame}{} -->
<!-- %\begin{scriptsize} -->
<!-- %\begin{itemize} -->
<!-- %  \item[Step 4] Define $\bv{w}_{i,t} = [\bv{x}_{1,i,t}',\bv{x}_{2,i,t}',\bv{z}_{1,i,t}',\bv{z}_{2,i,t}']$, -->
<!-- %  $$ -->
<!-- %  \bv{w}_{i,t}^* = \bv{w}_{i,t} - (1 - \hat{\theta})\bv{w}_i \quad \mbox{and} \quad y_{i,t}^* = y_{i,t} - (1 - \hat\theta) y_i. -->
<!-- %  $$ -->
<!-- %  The IVs are: -->
<!-- %  $$ -->
<!-- %  \bv{v}_{i,t} = [(\bv{x}_{1,i,t}-\bv{x}_{1,i})',(\bv{x}_{2,i,t}-\bv{x}_{2,i})',\bv{z}_{1,i}',\bv{x}_{1,i}']. -->
<!-- %  $$ -->
<!-- %  Finally: -->
<!-- %  \begin{equation} -->
<!-- %  (\bv{b}_{iv}',\bv{a}_{iv}')' = [({\bv{W}^*}'\bv{V})(\bv{V}'\bv{V})^{-1}(\bv{V}'{\bv{W}^*})][({\bv{W}^*}'\bv{V})(\bv{V}'\bv{V})^{-1}(\bv{V}'{\bv{y}^*})] -->
<!-- %  \end{equation} -->
<!-- %  \item No Asymp Var??? -->
<!-- %\end{itemize} -->
<!-- %\end{scriptsize} -->
<!-- %\end{frame} -->
<!-- % -->
<!-- %\begin{frame}{} -->
<!-- %\begin{scriptsize} -->
<!-- %\begin{itemize} -->
<!-- %  \item GMM estimation \href{http://people.stern.nyu.edu/wgreene/Econometrics/Arellano-Bond.pdf}{Arellano and Bond (1991)}. plm package does it; see Greene 13.6. -->
<!-- %\end{itemize} -->
<!-- %\end{scriptsize} -->
<!-- %\end{frame} -->
<!-- % -->
<!-- %\begin{frame}{} -->
<!-- %\begin{scriptsize} -->
<!-- %\begin{itemize} -->
<!-- %  \item XXX -->
<!-- %\end{itemize} -->
<!-- %\end{scriptsize} -->
<!-- %\end{frame} -->

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="linear-regressions.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="estimation-methods.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/03-PanelRegressions.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["AdvECTS.pdf", "AdvECTS.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
