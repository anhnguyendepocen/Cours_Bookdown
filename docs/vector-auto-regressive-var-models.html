<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 3 Vector Auto-Regressive (VAR) models | Advanced Econometrics</title>
<meta name="author" content="Jean-Paul Renne">
<meta name="description" content="Kilian (1998) See this page Sign restrictions: package, Danne (2015). Pfaff (2008) Hlavac (2022) library(VAR.etp) library(vars) #standard VAR models data(dat) # part of VAR.etp package a &lt;-...">
<meta name="generator" content="bookdown 0.27 with bs4_book()">
<meta property="og:title" content="Chapter 3 Vector Auto-Regressive (VAR) models | Advanced Econometrics">
<meta property="og:type" content="book">
<meta property="og:description" content="Kilian (1998) See this page Sign restrictions: package, Danne (2015). Pfaff (2008) Hlavac (2022) library(VAR.etp) library(vars) #standard VAR models data(dat) # part of VAR.etp package a &lt;-...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 3 Vector Auto-Regressive (VAR) models | Advanced Econometrics">
<meta name="twitter:description" content="Kilian (1998) See this page Sign restrictions: package, Danne (2015). Pfaff (2008) Hlavac (2022) library(VAR.etp) library(vars) #standard VAR models data(dat) # part of VAR.etp package a &lt;-...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.0/transition.js"></script><script src="libs/bs3compat-0.4.0/tabs.js"></script><script src="libs/bs3compat-0.4.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="my-style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Advanced Econometrics</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Prerequisites</a></li>
<li><a class="" href="intro.html"><span class="header-section-number">2</span> Introduction</a></li>
<li><a class="active" href="vector-auto-regressive-var-models.html"><span class="header-section-number">3</span> Vector Auto-Regressive (VAR) models</a></li>
<li><a class="" href="appendix.html"><span class="header-section-number">4</span> Appendix</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="vector-auto-regressive-var-models" class="section level1" number="3">
<h1>
<span class="header-section-number">3</span> Vector Auto-Regressive (VAR) models<a class="anchor" aria-label="anchor" href="#vector-auto-regressive-var-models"><i class="fas fa-link"></i></a>
</h1>
<p><span class="citation">Kilian (<a href="references.html#ref-Kilian_1998" role="doc-biblioref">1998</a>)</span> See <a href="https://rdrr.io/cran/VAR.etp/man/VAR.Boot.html">this page</a></p>
<p>Sign restrictions: <a href="https://github.com/chrstdanne/VARsignR">package</a>, <span class="citation">Danne (<a href="references.html#ref-Danne_2015" role="doc-biblioref">2015</a>)</span>.</p>
<p><span class="citation">Pfaff (<a href="references.html#ref-vars" role="doc-biblioref">2008</a>)</span>
<!-- toBibtex(citation("vars")) --></p>
<p><span class="citation">Hlavac (<a href="references.html#ref-Stargazer" role="doc-biblioref">2022</a>)</span></p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">VAR.etp</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://www.pfaffikus.de">vars</a></span><span class="op">)</span> <span class="co">#standard VAR models</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">dat</span><span class="op">)</span> <span class="co"># part of VAR.etp package</span></span>
<span><span class="va">a</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/VAR.etp/man/VAR.Boot.html">VAR.Boot</a></span><span class="op">(</span><span class="va">dat</span>,p<span class="op">=</span><span class="fl">2</span>,nb<span class="op">=</span><span class="fl">200</span>,type<span class="op">=</span><span class="st">"const"</span><span class="op">)</span></span>
<span><span class="va">b</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/vars/man/VAR.html">VAR</a></span><span class="op">(</span><span class="va">dat</span>,p<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="va">a</span><span class="op">$</span><span class="va">coef</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span>,<span class="op">(</span><span class="va">a</span><span class="op">$</span><span class="va">coef</span><span class="op">+</span><span class="va">a</span><span class="op">$</span><span class="va">Bias</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span>,<span class="va">b</span><span class="op">$</span><span class="va">varresult</span><span class="op">$</span><span class="va">inv</span><span class="op">$</span><span class="va">coefficients</span><span class="op">)</span></span></code></pre></div>
<pre><code>##         inv(-1)   inc(-1)   con(-1)    inv(-2)   inc(-2)   con(-2)       const
## [1,] -0.2906628 0.2102173 0.9305823 -0.1342837 0.1558196 0.8813534 -0.01783941
## [2,] -0.3196310 0.1459888 0.9612190 -0.1605511 0.1146050 0.9343938 -0.01672199
## [3,] -0.3196310 0.1459888 0.9612190 -0.1605511 0.1146050 0.9343938 -0.01672199</code></pre>
<div id="vars-ans-svarma-models" class="section level3" number="3.0.1">
<h3>
<span class="header-section-number">3.0.1</span> VARs (ans SVARMA) models<a class="anchor" aria-label="anchor" href="#vars-ans-svarma-models"><i class="fas fa-link"></i></a>
</h3>
<p>VARs are widely used in macroeconomic analysis. While simple and easy to estimate, they make it possible to conveniently capture the dynamics of complex multivariate systems. VAR popularity is notably due to <span class="citation">Sims (<a href="references.html#ref-Sims_1980" role="doc-biblioref">1980</a>)</span>’s influential work. In economics, VAR models are often employed in order to identify <em>structural</em> shocks. First, we will present VAR models. Second, we will study its <em>structural</em> extension (SVAR models).</p>
<div class="definition">
<p><span id="def:SVAR" class="definition"><strong>Definition 3.1  ((S)VAR model) </strong></span>Let <span class="math inline">\(y_{t}\)</span> denote a <span class="math inline">\(n \times1\)</span> vector of random variables. Process <span class="math inline">\(y_{t}\)</span> follows a <span class="math inline">\(p^{th}\)</span>-order VAR if, for all <span class="math inline">\(t\)</span>, we have
<span class="math display" id="eq:yVAR">\[\begin{eqnarray}
\begin{array}{rllll}
VAR:&amp; y_t &amp;=&amp; c + \Phi_1 y_{t-1} + \dots + \Phi_p y_{t-p} + \varepsilon_t,&amp; \varepsilon_t:\mbox{ (correlated) innovation}\\
SVAR:&amp; y_t &amp;=&amp; c + \Phi_1 y_{t-1} + \dots + \Phi_p y_{t-p} + B \eta_t,&amp; \eta_t:\mbox{ ($\bot$) structural shock},
\end{array}\tag{3.1}
\end{eqnarray}\]</span>
with <span class="math inline">\(\varepsilon_t = B\eta_t\)</span>. We assume that <span class="math inline">\(\{\eta_{t}\}\)</span> is a white noise sequence whose components are are mutually and serially independent.</p>
</div>
<p>The first line of Eq. <a href="vector-auto-regressive-var-models.html#eq:yVAR">(3.1)</a> corresponds to the <strong>reduced-form</strong> of the VAR model (<strong>structural form</strong> for the second line).</p>
<p>Eq. <a href="vector-auto-regressive-var-models.html#eq:yVAR">(3.1)</a> can also be written:
<span class="math display">\[
y_{t}=c+\Phi(L)y_{t-1}+\varepsilon_{t},
\]</span>
with <span class="math inline">\(\Phi(L) = \Phi_1 + \Phi_2 L + \dots + \Phi_p L^{p-1}\)</span>.</p>
<p>Consequently:
<span class="math display">\[
y_{t}\mid y_{t-1},y_{t-2},\ldots,y_{-p+1}\sim \mathcal{N}(c+\Phi_{1}y_{t-1}+\ldots\Phi_{p}y_{t-p},\Omega).
\]</span></p>
<p>Using <span class="citation">Hamilton (<a href="references.html#ref-Hamilton_1994" role="doc-biblioref">1994</a>)</span>’s notations, denote with <span class="math inline">\(\Pi\)</span> the matrix <span class="math inline">\(\left[\begin{array}{ccccc} c &amp; \Phi_{1} &amp; \Phi_{2} &amp; \ldots &amp; \Phi_{p}\end{array}\right]'\)</span> and with <span class="math inline">\(x_{t}\)</span> the vector <span class="math inline">\(\left[\begin{array}{ccccc} 1 &amp; y'_{t-1} &amp; y'_{t-2} &amp; \ldots &amp; y'_{t-p}\end{array}\right]'\)</span>, we have:
<span class="math display" id="eq:PIVAR">\[\begin{equation}
y_{t}= \Pi'x_{t} + \varepsilon_{t}. \tag{3.2}
\end{equation}\]</span>
The previous representation is convenient to discuss the estimation of the VAR model, as parameters are gathered in two matrices only: <span class="math inline">\(\Pi\)</span> and <span class="math inline">\(\Omega\)</span>.</p>
<p>As was the case for univariate models, VARs can be extended with MA terms in <span class="math inline">\(\eta_t\)</span>:</p>
<div class="definition">
<p><span id="def:SVARMA" class="definition"><strong>Definition 3.2  ((S)VARMA model) </strong></span>Let <span class="math inline">\(y_{t}\)</span> denote a <span class="math inline">\(n \times1\)</span> vector of random variables. Process <span class="math inline">\(y_{t}\)</span> follows a VARMA model of order (p,q) if, for all <span class="math inline">\(t\)</span>, we have
<span class="math display" id="eq:yVARMA">\[\begin{eqnarray}
\begin{array}{rllll}
VARMA:&amp; y_t &amp;=&amp; c + \Phi_1 y_{t-1} + \dots + \Phi_p y_{t-p} + \varepsilon_t + \Theta_1\varepsilon_{t-1} + \dots + \Theta_q ,\\
SVARMA:&amp; y_t &amp;=&amp; c + \Phi_1 y_{t-1} + \dots + \Phi_p y_{t-p} + B_0 \eta_t+ B_1 \eta_{t-1} + \dots +  B_q \eta_{t-q},
\end{array}\tag{3.3}
\end{eqnarray}\]</span>
with <span class="math inline">\(\varepsilon_t = B_0\eta_t\)</span> (and <span class="math inline">\(B_j = \Theta_j B_0\)</span>, for <span class="math inline">\(j \ge 0\)</span>). We assume that <span class="math inline">\(\{\eta_{t}\}\)</span> is a white noise sequence whose components are are mutually and serially independent.</p>
</div>
</div>
<div id="irfs-svarma" class="section level3" number="3.0.2">
<h3>
<span class="header-section-number">3.0.2</span> IRFs SVARMA<a class="anchor" aria-label="anchor" href="#irfs-svarma"><i class="fas fa-link"></i></a>
</h3>
<!-- ```{r NgramIRF, echo=FALSE,fig.cap="Source: Google Ngram. Fraction of books containing the blue and red keywords."} -->
<!-- library(ngramr) -->
<!-- keyw <- c("impulse response function","macroeconomic analysis") -->
<!-- res1 <- ngram(keyw[1],year_start = 1900);res2 <- ngram(keyw[2],year_start = 1900) -->
<!-- plot(res1$Year,res1$Frequency,type="l",lwd=2,xlab="",ylab="",col="blue",las=1) -->
<!-- lines(res2$Year,res2$Frequency,type="l",lwd=2,col="red") -->
<!-- legend("topleft", -->
<!--        keyw,lty=c(1),lwd=c(2), -->
<!--        col=c("blue","red")) -->
<!-- ``` -->
<p>One of the main objectives of macro-econometrics: derivation of IRFs</p>
<p>IRFs = Dynamic effect of structural shocks (<span class="math inline">\(\eta_t\)</span>) on endogenous variables (<span class="math inline">\(y_t\)</span>)</p>
<p>What are structural shocks? (e.g.</p>
<p><a href="https://www.sciencedirect.com/science/article/pii/0167223186900370">Bernanke, 1986</a>
<a href="https://www.nber.org/papers/w21978">Ramey, 2016</a></p>
<p>Independent primitive exogenous forces that drive economic variables.</p>
<p>Standard assumptions:</p>
<ul>
<li>
<span class="math inline">\(\eta_t\)</span> and <span class="math inline">\(y_t\)</span> are <span class="math inline">\(n\)</span>-dimensional vectors;</li>
<li>the components of <span class="math inline">\(\eta_t\)</span> (i.e. <span class="math inline">\(\eta_{1,t},\dots,\eta_{n,t}\)</span>) are serially and mutually independent [consistent with {(<span class="math inline">\(\ast\)</span>)}], zero mean, unit variance;</li>
<li>
<span class="math inline">\(y_t\)</span> is a stationary process driven by <span class="math inline">\(\eta_t\)</span>.</li>
</ul>
<p>IRFs = Conditional expectations:
<span class="math display">\[
\boxed{\color{blue}{\Psi_{i,j,h}} = \mathbb{E}(y_{i,t+h}|\color{blue}{\eta_{j,t}=1}) - \mathbb{E}(y_{i,t+h})}
\]</span>
(effect on <span class="math inline">\(y_{i,t+h}\)</span> of a one-unit shock on <span class="math inline">\(\eta_{j,t}\)</span>).</p>
<p>If the structural shocks linearly affect <span class="math inline">\(y_t\)</span>, then <span class="math inline">\(y_t\)</span> admits the following infinite MA representation (MA(<span class="math inline">\(\infty\)</span>)):
<span class="math display" id="eq:InfMA">\[\begin{equation}
y_t = \mu + \sum_{h=0}^\infty \color{blue}{\Psi_{h}} \eta_{t-h}.\tag{3.4}
\end{equation}\]</span></p>
<p>Estimating IRFs amounts to estimating the <span class="math inline">\(\Psi_{h}\)</span>’s.</p>
<p>Three main approaches:</p>
<ul>
<li><p>Calibrate and solve a (purely structural) DSGE model at the first order (linearization). The solution takes the form of Eq. <a href="vector-auto-regressive-var-models.html#eq:InfMA">(3.4)</a>.</p></li>
<li><p>Directly estimate the <span class="math inline">\(\Psi_{h}\)</span> based on <strong>projection approaches</strong> (see Section <a href="#LP"><strong>??</strong></a>).</p></li>
<li><p>Approximate the infinite MA representation by estimating a parsimonious type of model, e.g. <strong>VAR(MA) models</strong> (see Section <a href="#XXX"><strong>??</strong></a>). Once a (Structural) VARMA representation is obtained, Eq. <a href="vector-auto-regressive-var-models.html#eq:InfMA">(3.4)</a> is easily deduced.</p></li>
</ul>
<p>Eq. <a href="vector-auto-regressive-var-models.html#eq:InfMA">(3.4)</a> involves an infinite number of parameters, which need to be estimated. MA(<span class="math inline">\(\infty\)</span>) are often approximated by VARMA processes. VARMA = Linear dynamic model with an auto-regressive (AR) component and a moving average (MA) component:</p>
<ul>
<li><p>AR process – <span class="math inline">\(y_t\)</span> depends on its own lagged values and one <span class="math inline">\(\eta_t\)</span>:
<span class="math display">\[
AR(2): \quad y_t = \Phi_1 y_{t-1} + \Phi_2 y_{t-2} + B \eta_t
\]</span></p></li>
<li><p>MA process – <span class="math inline">\(y_t\)</span> depends on a finite number of past <span class="math inline">\(\eta_t\)</span>’s:
<span class="math display">\[
MA(2): \quad y_{t} = B \eta_t+ \Theta_1 B \eta_{t-1}+ \Theta_2 B \eta_{t-2}.
\]</span></p></li>
</ul>
<p><span class="math display" id="eq:VARMAstd">\[\begin{equation}
\Rightarrow \mbox{VARMA($p$,$q$): } y_t = \underbrace{\Phi_1 y_{t-1} + \dots +\Phi_p y_{t-p}}_{\color{blue}{\mbox{AR component}}} + \underbrace{B \eta_t+ \Theta_1 B \eta_{t-1}+ \dots+ \Theta_q B \eta_{t-q}}_{\color{red}{\mbox{MA component}}}. \tag{3.5}
\end{equation}\]</span></p>
<p><span class="math inline">\(\Psi_k\)</span>’s (which define IRFs, see Eq. <a href="vector-auto-regressive-var-models.html#eq:InfMA">(3.4)</a>) are easily deduced from <span class="math inline">\(\Phi_k\)</span>’s and <span class="math inline">\(\Theta_k\)</span>’s:</p>
<p>Trivial to go from MA(q) to MA(<span class="math inline">\(\infty\)</span>)
<span class="math display">\[
MA(2): \quad y_{t} = \underbrace{C}_{=\Psi_0} \eta_t+ \underbrace{\Theta_1 C}_{=\Psi_1} \eta_{t-1}+ \underbrace{\Theta_2 C}_{=\Psi_2} \eta_{t-2},
\]</span>
and <span class="math inline">\(\Psi_k = 0\)</span> for <span class="math inline">\(k&gt;2\)</span>.</p>
<p>AR(p) case: MA(<span class="math inline">\(\infty\)</span>) representation obtained recursively. Example: AR(2)
<span class="math display">\[\begin{eqnarray*}
y_t &amp;=&amp; \Phi_1 {\color{blue}y_{t-1}} + \Phi_2 y_{t-2} + C \eta_t  \\
&amp;=&amp; \Phi_1 {\color{blue}(\Phi_1 y_{t-2} + \Phi_2 y_{t-3} + C \eta_{t-1})} + \Phi_2 y_{t-2} + C \eta_t  \\
&amp;=&amp; C \eta_t + \Phi_1 C \eta_{t-1} + (\Phi_2 + \Phi_1^2) \color{red}{y_{t-2}} + \Phi_1\Phi_2 y_{t-3}  \\
&amp;=&amp; C \eta_t + \Phi_1 C \eta_{t-1} + (\Phi_2 + \Phi_1^2) \color{red}{(\Phi_1 y_{t-3} + \Phi_2 y_{t-4} + C \eta_{t-2})} + \Phi_1\Phi_2 y_{t-3} \\
&amp;=&amp; \underbrace{C}_{=\Psi_0} \eta_t + \underbrace{\Phi_1 C}_{=\Psi_1} \eta_{t-1} + \underbrace{(\Phi_2 + \Phi_1^2)C}_{=\Psi_2} \eta_{t-2} + f(y_{t-3},y_{t-4}).
\end{eqnarray*}\]</span></p>
<p>VARMA(<span class="math inline">\(p\)</span>,<span class="math inline">\(q\)</span>) case: same type of recursive approach to get the <span class="math inline">\(\Psi_k\)</span>’s. Very similar to the univariate case: Proposition <a href="#prp:computPsi"><strong>??</strong></a>.</p>
<p>In particular, <span class="math inline">\(B = \Psi_0\)</span> : contemporaneous impact of <span class="math inline">\(\eta_t\)</span> on <span class="math inline">\(y_t\)</span>.</p>
<p>Example of IRFs in the context of a VARMA(1,1) model:
<span class="math display" id="eq:VARMA111">\[\begin{eqnarray}
\quad y_t &amp;=&amp;
\underbrace{\left[\begin{array}{cc}
0.5 &amp; 0.3 \\
-0.4 &amp; 0.7
\end{array}\right]}_{\Phi_1}
y_{t-1} +  
\underbrace{\left[\begin{array}{cc}
1 &amp; 2 \\
-1 &amp; 1
\end{array}\right]}_{B}\eta_t + \underbrace{\left[\begin{array}{cc}
2 &amp; 0 \\
1 &amp; 0.5
\end{array}\right]}_{\Theta_1} \underbrace{\left[\begin{array}{cc}
1 &amp; 2 \\
-1 &amp; 1
\end{array}\right]}_{B}\eta_{t-1}.\tag{3.6}
\end{eqnarray}\]</span></p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">AEC</span><span class="op">)</span></span>
<span><span class="va">distri</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>type<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"gaussian"</span>,<span class="st">"gaussian"</span><span class="op">)</span>,df<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">4</span>,<span class="fl">4</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">distri</span><span class="op">$</span><span class="va">type</span><span class="op">)</span></span>
<span><span class="va">nb.sim</span> <span class="op">&lt;-</span> <span class="fl">30</span></span>
<span><span class="va">eps</span> <span class="op">&lt;-</span> <span class="fu">simul.distri</span><span class="op">(</span><span class="va">distri</span>,<span class="va">nb.sim</span><span class="op">)</span></span>
<span><span class="va">Phi</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/array.html">array</a></span><span class="op">(</span><span class="cn">NaN</span>,<span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">n</span>,<span class="va">n</span>,<span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">Phi</span><span class="op">[</span>,,<span class="fl">1</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">.5</span>,<span class="op">-</span><span class="fl">.4</span>,<span class="fl">.3</span>,<span class="fl">.7</span><span class="op">)</span>,<span class="fl">2</span>,<span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">Phi</span><span class="op">)</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span></span>
<span><span class="va">Theta</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/array.html">array</a></span><span class="op">(</span><span class="cn">NaN</span>,<span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">n</span>,<span class="va">n</span>,<span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">Theta</span><span class="op">[</span>,,<span class="fl">1</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">1</span>,<span class="fl">0</span>,<span class="fl">.5</span><span class="op">)</span>,<span class="fl">2</span>,<span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">q</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">Theta</span><span class="op">)</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span></span>
<span><span class="va">Mu</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">0</span>,<span class="va">n</span><span class="op">)</span></span>
<span><span class="va">C</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="op">-</span><span class="fl">1</span>,<span class="fl">2</span>,<span class="fl">1</span><span class="op">)</span>,<span class="fl">2</span>,<span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">Model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>  Mu <span class="op">=</span> <span class="va">Mu</span>,</span>
<span>  Phi <span class="op">=</span> <span class="va">Phi</span>,</span>
<span>  Theta <span class="op">=</span> <span class="va">Theta</span>,</span>
<span>  C <span class="op">=</span> <span class="va">C</span>,</span>
<span>  distri <span class="op">=</span> <span class="va">distri</span></span>
<span><span class="op">)</span></span>
<span><span class="va">Y0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">0</span>,<span class="va">n</span><span class="op">)</span></span>
<span><span class="va">eta0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">0</span><span class="op">)</span></span>
<span><span class="va">res.sim.1</span> <span class="op">&lt;-</span> <span class="fu">simul.VARMA</span><span class="op">(</span><span class="va">Model</span>,<span class="va">nb.sim</span>,<span class="va">Y0</span>,<span class="va">eta0</span>,indic.IRF<span class="op">=</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">eta0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">res.sim.2</span> <span class="op">&lt;-</span> <span class="fu">simul.VARMA</span><span class="op">(</span><span class="va">Model</span>,<span class="va">nb.sim</span>,<span class="va">Y0</span>,<span class="va">eta0</span>,indic.IRF<span class="op">=</span><span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>plt<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">.1</span>,<span class="fl">.95</span>,<span class="fl">.25</span>,<span class="fl">.8</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/plot.html">plot</a></span><span class="op">(</span><span class="va">res.sim.1</span><span class="op">$</span><span class="va">Y</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span>,las<span class="op">=</span><span class="fl">1</span>,</span>
<span>     type<span class="op">=</span><span class="st">"l"</span>,lwd<span class="op">=</span><span class="fl">3</span>,xlab<span class="op">=</span><span class="st">""</span>,ylab<span class="op">=</span><span class="st">""</span>,</span>
<span>     main<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"Response of "</span>,<span class="va">y</span><span class="op">[</span><span class="fl">1</span>,<span class="st">"*,*"</span>,<span class="va">t</span><span class="op">]</span>,<span class="st">" to a one-unit increase in "</span>,<span class="va">eta</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>,sep<span class="op">=</span><span class="st">""</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>h<span class="op">=</span><span class="fl">0</span>,col<span class="op">=</span><span class="st">"grey"</span>,lty<span class="op">=</span><span class="fl">3</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/plot.html">plot</a></span><span class="op">(</span><span class="va">res.sim.2</span><span class="op">$</span><span class="va">Y</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span>,las<span class="op">=</span><span class="fl">1</span>,</span>
<span>     type<span class="op">=</span><span class="st">"l"</span>,lwd<span class="op">=</span><span class="fl">3</span>,xlab<span class="op">=</span><span class="st">""</span>,ylab<span class="op">=</span><span class="st">""</span>,</span>
<span>     main<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"Response of "</span>,<span class="va">y</span><span class="op">[</span><span class="fl">1</span>,<span class="st">"*,*"</span>,<span class="va">t</span><span class="op">]</span>,<span class="st">" to a one-unit increase in "</span>,<span class="va">eta</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>,sep<span class="op">=</span><span class="st">""</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>h<span class="op">=</span><span class="fl">0</span>,col<span class="op">=</span><span class="st">"grey"</span>,lty<span class="op">=</span><span class="fl">3</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/plot.html">plot</a></span><span class="op">(</span><span class="va">res.sim.1</span><span class="op">$</span><span class="va">Y</span><span class="op">[</span><span class="fl">2</span>,<span class="op">]</span>,las<span class="op">=</span><span class="fl">1</span>,</span>
<span>     type<span class="op">=</span><span class="st">"l"</span>,lwd<span class="op">=</span><span class="fl">3</span>,xlab<span class="op">=</span><span class="st">""</span>,ylab<span class="op">=</span><span class="st">""</span>,</span>
<span>     main<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"Response of "</span>,<span class="va">y</span><span class="op">[</span><span class="fl">2</span>,<span class="st">"*,*"</span>,<span class="va">t</span><span class="op">]</span>,<span class="st">" to a one-unit increase in "</span>,<span class="va">eta</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>,sep<span class="op">=</span><span class="st">""</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>h<span class="op">=</span><span class="fl">0</span>,col<span class="op">=</span><span class="st">"grey"</span>,lty<span class="op">=</span><span class="fl">3</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/plot.html">plot</a></span><span class="op">(</span><span class="va">res.sim.2</span><span class="op">$</span><span class="va">Y</span><span class="op">[</span><span class="fl">2</span>,<span class="op">]</span>,las<span class="op">=</span><span class="fl">1</span>,</span>
<span>     type<span class="op">=</span><span class="st">"l"</span>,lwd<span class="op">=</span><span class="fl">3</span>,xlab<span class="op">=</span><span class="st">""</span>,ylab<span class="op">=</span><span class="st">""</span>,</span>
<span>     main<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"Response of "</span>,<span class="va">y</span><span class="op">[</span><span class="fl">2</span>,<span class="st">"*,*"</span>,<span class="va">t</span><span class="op">]</span>,<span class="st">" to a one-unit increase in "</span>,<span class="va">eta</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>,sep<span class="op">=</span><span class="st">""</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>h<span class="op">=</span><span class="fl">0</span>,col<span class="op">=</span><span class="st">"grey"</span>,lty<span class="op">=</span><span class="fl">3</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="AdvECTS_files/figure-html/simVAR-1.png" width="672"></div>
<!-- \includegraphics[width=.9\linewidth]{figures/RcodesFigure_illustrIRF.pdf} -->
<!-- \begin{defn}[Autocovariance of order $j$] -->
<!-- The autocovariance of order $j$ of $y_t$ is $\mathbb{C}ov(y_t,y_{t-j})$. -->
<!-- \end{defn} -->
<!-- \begin{defn}[Covariance-stationary process] -->
<!-- Process $y_t$ is covariance-stationary if $\mathbb{E}(y_t)$ and all autocovariances of $y_t$ are finite and do not depend on $t$. -->
<!-- \end{defn} -->
<p>Let’s come back to the infinite MA case (Eq. <a href="vector-auto-regressive-var-models.html#eq:InfMA">(3.4)</a>):
<span class="math display">\[
y_t = \mu + \sum_{h=0}^\infty {\color{blue}\Psi_{h}} \eta_{t-h}.
\]</span>
For <span class="math inline">\(y_t\)</span> to be covariance-stationary (and ergodic for the mean), it has to be the case that</p>
<p><span class="math display" id="eq:condiInfiniteMA">\[\begin{equation}
\sum_{i=0}^\infty \|\Psi_i\| &lt; \infty,\tag{3.7}
\end{equation}\]</span>
where <span class="math inline">\(\|A\|\)</span> denotes a norm of the matrix <span class="math inline">\(A\)</span> (e.g. <span class="math inline">\(\|A\|=\sqrt{tr(AA')}\)</span>).</p>
<p>This notably implies that if <span class="math inline">\(y_t\)</span> is stationary, then <span class="math inline">\(\|\Psi_h\|\rightarrow 0\)</span> when <span class="math inline">\(h\)</span> gets large.</p>
<p>A finite-order MA process is always covariance-stationary.</p>
<p>What should be satisfied by <span class="math inline">\(\Phi_k\)</span>’s and <span class="math inline">\(\Theta_k\)</span>’s for a VARMA-based process (Eq. @ref{eq:VARMAstd)) to be stationary?
<span class="math display" id="eq:VARMA2">\[\begin{eqnarray}
y_t &amp;=&amp; c+ \underbrace{\Phi_1 y_{t-1} + \dots +\Phi_p y_{t-p}}_{{\color{blue}\mbox{AR component}}} +  \tag{3.8}\\
&amp;&amp;\underbrace{B \eta_t+ \Theta_1 B \eta_{t-1}+ \dots+ \Theta_q B \eta_{t-q}}_{{\color{red}\mbox{MA component}}} \nonumber\\
&amp;\Leftrightarrow&amp; \underbrace{(I - \Phi_1 L - \dots - \Phi_p L^p)}_{= \Phi(L)}y_t = c +  \underbrace{ {\color{red} (I - \Theta_1 L - \ldots - \Theta_q L^q)}}_{={\color{red}\Theta(L)}} B \eta_{t}. \nonumber
\end{eqnarray}\]</span></p>
<p>If <span class="math inline">\(y_t\)</span> is stationary, then it has to be that the roots of <span class="math inline">\(\det(\Phi(z))=0\)</span> are outside the unit circle.</p>
<p>Equivalently, the eigenvalues of
<span class="math display">\[
\left[\begin{array}{cccc}
\Phi_{1} &amp; \Phi_{2} &amp; \cdots &amp; \Phi_{p}\\
I &amp; 0 &amp; \cdots &amp; 0\\
0 &amp; \ddots &amp; 0 &amp; 0\\
0 &amp; 0 &amp; I &amp; 0\end{array}\right]
\]</span>
have to be within the unit circle.</p>
<p>Let’s derive the first two unconditional moments of a (covariance-stationary) VARMA process.</p>
<p>Based on Eq. @ref{eq:VARMA2), we have <span class="math inline">\(\mathbb{E}(\Phi(L)y_t)=c \Rightarrow \Phi(1)\mathbb{E}(y_t)=c\)</span>. Hence:
<span class="math display">\[
\mathbb{E}(y_t) = (I - \Phi_1 - \dots - \Phi_p)^{-1}c.
\]</span>
The autocovariances of <span class="math inline">\(y_t\)</span> can be deduced from the infinite MA representation (Eq. <a href="vector-auto-regressive-var-models.html#eq:InfMA">(3.4)</a>).</p>
<!-- \hyperlink{appendix:getMAinf}{\beamergotobutton{methodology to get the $\Psi_k$'s}} -->
<p>We have:
<span class="math display">\[
\gamma_j \equiv \mathbb{C}ov(y_t,y_{t-j}) = \sum_{i=j}^\infty \Psi_i \Psi_{i-j}'.
\]</span>
(NB: This infinite sum exists as soon as Eq. <a href="vector-auto-regressive-var-models.html#eq:condiInfiniteMA">(3.7)</a> is satisfied.)</p>
<p>Conditional means and autocovariances can also be deduced from Eq. <a href="vector-auto-regressive-var-models.html#eq:InfMA">(3.4)</a>. For <span class="math inline">\(0 \le h\)</span> and <span class="math inline">\(0 \le h_1 \le h_2\)</span>:</p>
<p><span class="math display">\[\begin{eqnarray*}
\mathbb{E}_t(y_{t+h}) &amp;=&amp; \mu + \sum_{k=0}^\infty \Psi_{k+h} \eta_{t-k} \\
\mathbb{C}ov_t(y_{t+1+h_1},y_{t+1+h_2}) &amp;=&amp; \sum_{k=0}^{h_1} \Psi_{k}\Psi_{k+h_2-h_1}'.
\end{eqnarray*}\]</span></p>
<p>The previous formula implies in particular that the forecasting error <span class="math inline">\(y_{t+h} - \mathbb{E}_t(y_{t+h})\)</span> has a variance equal to:
<span class="math display">\[
\mathbb{V}ar_t(y_{t+h}) = \sum_{k=1}^{h} \Psi_{k}\Psi_{k}'.
\]</span>
Because the <span class="math inline">\(\eta_t\)</span> are mutually and serially independent (and therefore uncorrelated), we have:
<span class="math display">\[
\mathbb{V}ar(\Psi_k \eta_{t-k}) = \mathbb{V}ar\left(\sum_{i=1}^n \psi_{k,i} \eta_{i,t-k}\right)  = \sum_{i=1}^n \psi_{k,i}\psi_{k,i}',
\]</span>
where <span class="math inline">\(\psi_{k,i}\)</span> denotes the <span class="math inline">\(i^{th}\)</span> column of <span class="math inline">\(\Psi_k\)</span>.</p>
<p>This suggests the following decomposition of the variance of the forecast error (called <strong>variance decomposition</strong>):
<span class="math display">\[
\mathbb{V}ar_t(y_{t+h}) = \sum_{i=1}^n \underbrace{\sum_{k=1}^{h}  \psi_{k,i}\psi_{k,i}'}_{\mbox{Contribution of $\eta_{i,t}$}}.
\]</span></p>
<p>The estimation of VAR models is covered in Section <a href="#Section:BasicsVAR"><strong>??</strong></a>. In this case, the <span class="math inline">\(\Phi_k\)</span> matrices can be consistently estimated by simple OLS regressions.</p>
<p>If there is a MA component, OLS regressions yield biased estimates (even for asymptotically large samples).</p>
<p>Assume <span class="math inline">\(y_t\)</span> follows a VARMA(1,1) model. We have:
<span class="math display">\[
y_{i,t} = \phi_i y_{t-1} + \varepsilon_{i,t},
\]</span>
where <span class="math inline">\(\phi_i\)</span> is the <span class="math inline">\(i^{th}\)</span> row of <span class="math inline">\(\Phi_1\)</span>, and where <span class="math inline">\(\varepsilon_{i,t}\)</span> is a linear combination of <span class="math inline">\(\eta_t\)</span> and <span class="math inline">\(\eta_{t-1}\)</span>.</p>
<p>Since <span class="math inline">\(y_{t-1}\)</span> (the regressor) is correlated to <span class="math inline">\(\eta_{t-1}\)</span>, it is also correlated to <span class="math inline">\(\varepsilon_{i,t}\)</span>.</p>
<p>The OLS regression of <span class="math inline">\(y_{i,t}\)</span> on <span class="math inline">\(y_{t-1}\)</span> yields a biased estimator of <span class="math inline">\(\phi_i\)</span>.</p>
<p>Estimation methods of VARMA models will be presented in Section <a href="#Section:AlternII"><strong>??</strong></a>.</p>
</div>
<div id="var-estimation" class="section level3" number="3.0.3">
<h3>
<span class="header-section-number">3.0.3</span> VAR estimation<a class="anchor" aria-label="anchor" href="#var-estimation"><i class="fas fa-link"></i></a>
</h3>
<p>Let us start with the case where the shocks are Gaussian.</p>
<div class="proposition">
<p><span id="prp:estimVARGaussian" class="proposition"><strong>Proposition 3.1  (MLE of a Gaussian VAR) </strong></span>If <span class="math inline">\(y_t\)</span> follows a VAR(p) (see Definition <a href="vector-auto-regressive-var-models.html#def:SVAR">3.1</a>), and if <span class="math inline">\(\varepsilon_t \sim \,i.i.d.\,\mathcal{N}(0,\Omega)\)</span>, then the ML estimate of <span class="math inline">\(\Pi\)</span>, denoted by <span class="math inline">\(\hat{\Pi}\)</span> (see Eq. <a href="vector-auto-regressive-var-models.html#eq:PIVAR">(3.2)</a>), is given by
<span class="math display" id="eq:Pi">\[\begin{equation}
\hat{\Pi}=\left[\sum_{t=1}^{T}x_{t}x'_{t}\right]^{-1}\left[\sum_{t=1}^{T}y_{t}'x_{t}\right]= (\mathbf{X}'\mathbf{X})^{-1}\mathbf{X}'\mathbf{y},\tag{3.9}
\end{equation}\]</span>
where <span class="math inline">\(\mathbf{X}\)</span> is the <span class="math inline">\(T \times (np)\)</span> matrix whose <span class="math inline">\(t^{th}\)</span> row is <span class="math inline">\(x_t\)</span> and where <span class="math inline">\(\mathbf{y}\)</span> is the <span class="math inline">\(T \times n\)</span> matrix whose <span class="math inline">\(t^{th}\)</span> row is <span class="math inline">\(y_{t}'\)</span>.</p>
<p>That is, the <span class="math inline">\(i^{th}\)</span> column of <span class="math inline">\(\hat{\Pi}\)</span> (<span class="math inline">\(b_i\)</span>, say) is the OLS estimate of <span class="math inline">\(\beta_i\)</span>, where:
<span class="math display" id="eq:betayx">\[\begin{equation}
y_{i,t} = \beta_i'x_t + \varepsilon_{i,t},\tag{3.10}
\end{equation}\]</span>
(i.e., <span class="math inline">\(\beta_i' = [c_i,\phi_{i,1}',\dots,\phi_{i,p}']'\)</span>).</p>
<p>The ML estimate of <span class="math inline">\(\Omega\)</span>, denoted by <span class="math inline">\(\hat{\Omega}\)</span>, coincides with the sample covariance matrix of the <span class="math inline">\(n\)</span> series of the OLS residuals in Eq. <a href="vector-auto-regressive-var-models.html#eq:betayx">(3.10)</a>, i.e.:
<span class="math display">\[\begin{equation}
\hat{\Omega} = \frac{1}{T} \sum_{i=1}^T \hat{\varepsilon}_t\hat{\varepsilon}_t',\quad\mbox{with } \hat{\varepsilon}_t= y_t - \hat{\Pi}'x_t.
\end{equation}\]</span></p>
<p>The asymptotic distributions of these estimators are the ones resulting from standard OLS formula.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-1" class="proof"><em>Proof</em>. </span>See Appendix <a href="appendix.html#estimVARGaussian">4.4.8</a>.</p>
</div>
<p>As stated by Proposition <a href="appendix.html#OLSVAR">4.4.9</a>, when the shocks are not Gaussian, then the OLS regressions still provide consistent estimates of the model parameters. However, since <span class="math inline">\(x_t\)</span> correlates to <span class="math inline">\(\varepsilon_s\)</span> for <span class="math inline">\(s&lt;t\)</span>, the OLS estimator <span class="math inline">\(\mathbf{b}_i\)</span> of <span class="math inline">\(\boldsymbol\beta_i\)</span> is biased in small sample. (That is also the case for the ML estimator.)</p>
<p>Indeed, denoting by <span class="math inline">\(\boldsymbol\varepsilon_i\)</span> the <span class="math inline">\(T \times 1\)</span> vector of <span class="math inline">\(\varepsilon_{i,t}\)</span>’s, and using the notations of <span class="math inline">\(b_i\)</span> and <span class="math inline">\(\beta_i\)</span> introduced in Proposition <a href="vector-auto-regressive-var-models.html#prp:estimVARGaussian">3.1</a>, we have:
<span class="math display" id="eq:olsar1">\[\begin{equation}
\mathbf{b}_i = \beta_i + (\mathbf{X}'\mathbf{X})^{-1}\mathbf{X}'\boldsymbol\varepsilon_i.\tag{3.11}
\end{equation}\]</span>
We have non-zero correlation between <span class="math inline">\(x_t\)</span> and <span class="math inline">\(\varepsilon_{i,s}\)</span> for <span class="math inline">\(s&lt;t\)</span> and, therefore, <span class="math inline">\(\mathbb{E}[(\mathbf{X}'\mathbf{X})^{-1}\mathbf{X}'\boldsymbol\varepsilon_i] \ne 0\)</span>.</p>
<p>However, when <span class="math inline">\(y_t\)</span> is covariance stationary, then <span class="math inline">\(\frac{1}{n}\mathbf{X}'\mathbf{X}\)</span> converges to a positive definite matrix <span class="math inline">\(\mathbf{Q}\)</span>, and <span class="math inline">\(\frac{1}{n}X'\boldsymbol\varepsilon_i\)</span> converges to 0. Hence <span class="math inline">\(\mathbf{b}_i \overset{p}{\rightarrow} \beta_i\)</span>. More precisely:</p>
<div class="proposition">
<p><span id="prp:OLSVAR" class="proposition"><strong>Proposition 3.2  (Asymptotic distribution of the OLS estimate of $\beta_i$) </strong></span>If <span class="math inline">\(y_t\)</span> follows a VAR model, as defined in Definition <a href="vector-auto-regressive-var-models.html#def:SVAR">3.1</a>, we have:
<span class="math display">\[
\sqrt{T}(\mathbf{b}_i-\beta_i) =  \underbrace{\left[\frac{1}{T}\sum_{t=p}^T x_t x_t' \right]^{-1}}_{\overset{p}{\rightarrow} \mathbf{Q}^{-1}}
\underbrace{\sqrt{T} \left[\frac{1}{T}\sum_{t=1}^T x_t\varepsilon_{i,t} \right]}_{\overset{d}{\rightarrow} \mathcal{N}(0,\sigma_i^2\mathbf{Q})},
\]</span>
where <span class="math inline">\(\sigma_i = \mathbb{V}ar(\varepsilon_{i,t})\)</span> and where <span class="math inline">\(\mathbf{Q} = \mbox{plim }\frac{1}{T}\sum_{t=p}^T x_t x_t'\)</span> is given by:
<span class="math display" id="eq:Qols">\[\begin{equation}
\mathbf{Q} = \left[
\begin{array}{ccccc}
1 &amp; \mu' &amp;\mu' &amp; \dots &amp; \mu' \\
\mu &amp; \gamma_0 + \mu\mu' &amp; \gamma_1 + \mu\mu' &amp; \dots &amp; \gamma_{p-1} + \mu\mu'\\
\mu &amp; \gamma_1 + \mu\mu' &amp; \gamma_0 + \mu\mu' &amp; \dots &amp; \gamma_{p-2} + \mu\mu'\\
\vdots &amp;\vdots &amp;\vdots &amp;\dots &amp;\vdots \\
\mu &amp; \gamma_{p-1} + \mu\mu' &amp; \gamma_{p-2} + \mu\mu' &amp; \dots &amp; \gamma_{0} + \mu\mu'
\end{array}
\right].\tag{3.12}
\end{equation}\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-2" class="proof"><em>Proof</em>. </span>See Appendix <a href="appendix.html#OLSVAR">4.4.9</a>.</p>
</div>
<p>The following proposition extends the previous proposition and includes covariances between different <span class="math inline">\(\beta_i\)</span>’s as well as the asymptotic distribution of the ML estimates of <span class="math inline">\(\Omega\)</span>.</p>
<div class="proposition">
<p><span id="prp:OLSVAR2" class="proposition"><strong>Proposition 3.3  (Asymptotic distribution of the OLS estimates) </strong></span>If <span class="math inline">\(y_t\)</span> follows a VAR model, as defined in Definition <a href="vector-auto-regressive-var-models.html#def:SVAR">3.1</a>, we have:
<span class="math display" id="eq:asymptPi">\[\begin{equation}
\sqrt{T}\left[
\begin{array}{c}
vec(\hat\Pi - \Pi)\\
vec(\hat\Omega - \Omega)
\end{array}
\right]
\sim \mathcal{N}\left(0,
\left[
\begin{array}{cc}
\Omega \otimes \mathbf{Q}^{-1} &amp; 0\\
0 &amp; \Sigma_{22}
\end{array}
\right]\right),\tag{3.13}
\end{equation}\]</span>
where the component of <span class="math inline">\(\Sigma_{22}\)</span> corresponding to the covariance between <span class="math inline">\(\hat\sigma_{i,j}\)</span> and <span class="math inline">\(\hat\sigma_{k,l}\)</span> (for <span class="math inline">\(i,j,l,m \in \{1,\dots,n\}^4\)</span>) is equal to <span class="math inline">\(\sigma_{i,l}\sigma_{j,m}+\sigma_{i,m}\sigma_{j,l}\)</span>.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-3" class="proof"><em>Proof</em>. </span>See <span class="citation">Hamilton (<a href="references.html#ref-Hamilton_1994" role="doc-biblioref">1994</a>)</span>, Appendix of Chapter 11.</p>
</div>
<p>Naturally, in practice, <span class="math inline">\(\Omega\)</span> is replaced by <span class="math inline">\(\hat{\Omega}\)</span>, <span class="math inline">\(Q\)</span> is replaced with <span class="math inline">\(\hat{\mathbf{Q}} = \frac{1}{T}\sum_{t=p}^T x_t x_t'\)</span> and <span class="math inline">\(\Sigma\)</span> with the matrix whose components are of the form <span class="math inline">\(\hat\sigma_{i,l}\hat\sigma_{j,m}+\hat\sigma_{i,m}\hat\sigma_{j,l}\)</span>, where the <span class="math inline">\(\hat\sigma_{i,l}\)</span>’s are the components of <span class="math inline">\(\hat\Omega\)</span>.</p>
<p>The simplicity of the VAR framework and the tractability of its MLE open the way to convenient econometric testing. Let’s illustrate this with the likelihood ratio test. The maximum value achieved by the MLE is
<span class="math display">\[
\log\mathcal{L}(Y_{T};\hat{\Pi},\hat{\Omega}) = -\frac{Tn}{2}\log(2\pi)+\frac{T}{2}\log\left|\hat{\Omega}^{-1}\right| -\frac{1}{2}\sum_{t=1}^{T}\left[\hat{\varepsilon}_{t}'\hat{\Omega}^{-1}\hat{\varepsilon}_{t}\right].
\]</span>
The last term is:
<span class="math display">\[\begin{eqnarray*}
\sum_{t=1}^{T}\hat{\varepsilon}_{t}'\hat{\Omega}^{-1}\hat{\varepsilon}_{t} &amp;=&amp; \mbox{Tr}\left[\sum_{t=1}^{T}\hat{\varepsilon}_{t}'\hat{\Omega}^{-1}\hat{\varepsilon}_{t}\right] = \mbox{Tr}\left[\sum_{t=1}^{T}\hat{\Omega}^{-1}\hat{\varepsilon}_{t}\hat{\varepsilon}_{t}'\right]\\
&amp;=&amp;\mbox{Tr}\left[\hat{\Omega}^{-1}\sum_{t=1}^{T}\hat{\varepsilon}_{t}\hat{\varepsilon}_{t}'\right] = \mbox{Tr}\left[\hat{\Omega}^{-1}\left(T\hat{\Omega}\right)\right]=Tn.
\end{eqnarray*}\]</span>
Therefore, the optimized log-likelihood is simply obtained by:
<span class="math display" id="eq:optimzedLogL">\[\begin{equation}
\log\mathcal{L}(Y_{T};\hat{\Pi},\hat{\Omega})=-(Tn/2)\log(2\pi)+(T/2)\log\left|\hat{\Omega}^{-1}\right|-Tn/2.\tag{3.14}
\end{equation}\]</span></p>
<p>Assume that we want to test the null hypothesis that a set of variables follows a VAR(<span class="math inline">\(p_{0}\)</span>) against the alternative
specification of <span class="math inline">\(p_{1}\)</span> (<span class="math inline">\(&gt;p_{0}\)</span>).</p>
<p>Let us denote by <span class="math inline">\(\hat{L}_{0}\)</span> and <span class="math inline">\(\hat{L}_{1}\)</span> the maximum log-likelihoods obtained with <span class="math inline">\(p_{0}\)</span> and <span class="math inline">\(p_{1}\)</span> lags, respectively.</p>
<p>Under the null hypothesis (<span class="math inline">\(H_0\)</span>: <span class="math inline">\(p=p_0\)</span>), we have:
<span class="math display">\[\begin{eqnarray*}
2\left(\hat{L}_{1}-\hat{L}_{0}\right)&amp;=&amp;T\left(\log\left|\hat{\Omega}_{1}^{-1}\right|-\log\left|\hat{\Omega}_{0}^{-1}\right|\right)  \sim \chi^2(n^{2}(p_{1}-p_{0})).
\end{eqnarray*}\]</span></p>
<p><strong>Block exogeneity</strong></p>
<p>Let’s decompose <span class="math inline">\(y_t\)</span> into two subvectors <span class="math inline">\(y^{(1)}_{t}\)</span> (<span class="math inline">\(n_1 \times 1\)</span>) and <span class="math inline">\(y^{(2)}_{t}\)</span> (<span class="math inline">\(n_2 \times 1\)</span>), with <span class="math inline">\(y_t' = [{y^{(1)}_{t}}',{y^{(2)}_{t}}']\)</span> (and therefore <span class="math inline">\(n=n_1 +n_2\)</span>), such that:
<span class="math display">\[
\left[
\begin{array}{c}
y^{(1)}_{t}\\
y^{(2)}_{t}
\end{array}
\right] = \left[
\begin{array}{cc}
\Phi^{(1,1)} &amp; \Phi^{(1,2)}\\
\Phi^{(2,1)} &amp; \Phi^{(2,2)}
\end{array}
\right]
\left[
\begin{array}{c}
y^{(1)}_{t-1}\\
y^{(2)}_{t-1}
\end{array}
\right] + \varepsilon_t.
\]</span>
One can easily test for block exogeneity of <span class="math inline">\(y_t^{(2)}\)</span> (say). The null assumption ca n be expressed as <span class="math inline">\(\Phi^{(2,1)}=0\)</span> and <span class="math inline">\(\Sigma^{(2,1)}=0\)</span>.</p>
<p><strong>Lag selection</strong></p>
<p>In a VAR, adding lags consumes numerous degrees of freedom: with <span class="math inline">\(p\)</span> lags, each of the <span class="math inline">\(n\)</span> equations in the VAR contains <span class="math inline">\(n\times p\)</span> coefficients plus the intercept term.</p>
<p>Adding lags improve in-sample fit, but is likely to result in over-parameterization and affect the <strong>out-of-sample</strong> prediction performance.</p>
<p>To select appropriate lag length, so-called <strong>selection criteria</strong> can be used (see Definition <a href="#def:infocriteria"><strong>??</strong></a>). These criteria have to be minimized. That is, the best specification is the one giving the lowest criteria.</p>
<p>In the context of VAR models, using Eq. <a href="vector-auto-regressive-var-models.html#eq:optimzedLogL">(3.14)</a>, we have:
<span class="math display">\[\begin{eqnarray*}
AIC &amp; = &amp; cst + \log\left|\hat{\Omega}\right|+\frac{2}{T}N\\
BIC &amp; = &amp; cst + \log\left|\hat{\Omega}\right|+\frac{\log T}{T}N,
\end{eqnarray*}\]</span>
where <span class="math inline">\(N=p \times n^{2}\)</span>.</p>
<p><strong>Companion Form and Stability of a VAR process</strong></p>
<p>Let us introduce vector <span class="math inline">\(y_{t}^{*}\)</span>, whihc stacks the last <span class="math inline">\(p\)</span> values of <span class="math inline">\(y_t\)</span>:
<span class="math display">\[
y_{t}^{*}=\left[\begin{array}{cccc}
y'_{t} &amp; y'_{t-1} &amp; \ldots &amp; y'_{t-p+1}\end{array}\right]^{'},
\]</span>
Eq. <a href="vector-auto-regressive-var-models.html#eq:yVAR">(3.1)</a> can then be rewritten in its companion form:
<span class="math display" id="eq:ystarVAR">\[\begin{equation}
y_{t}^{*} =
\underbrace{\left[\begin{array}{c}
c\\
0\\
\vdots\\
0\end{array}\right]}_{=c^*}+
\underbrace{\left[\begin{array}{cccc}
\Phi_{1} &amp; \Phi_{2} &amp; \cdots &amp; \Phi_{p}\\
I &amp; 0 &amp; \cdots &amp; 0\\
0 &amp; \ddots &amp; 0 &amp; 0\\
0 &amp; 0 &amp; I &amp; 0\end{array}\right]}_{=\Phi}
y_{t-1}^{*}+
\underbrace{\left[\begin{array}{c}
\varepsilon_{t}\\
0\\
\vdots\\
0\end{array}\right]}_{\varepsilon_t^*}\tag{3.15}
\end{equation}\]</span></p>
<p>Matrices <span class="math inline">\(\Phi\)</span> and <span class="math inline">\(\Sigma^* = \mathbb{V}ar(\varepsilon_t^*)\)</span> are of dimension <span class="math inline">\(np \times np\)</span>. <span class="math inline">\(\Sigma^*\)</span> is filled with zeros, except the <span class="math inline">\(n\times n\)</span> upper-left block that is equal to <span class="math inline">\(\Sigma = \mathbb{V}ar(\varepsilon_t)\)</span>.</p>
<p>We then have:
<span class="math display">\[\begin{eqnarray*}
y_{t}^{*} &amp; = &amp; c^{*}+\Phi\left(c^{*}+\Phi y_{t-2}^{*}+\varepsilon_{t-1}^{*}\right)+\varepsilon_{t}^{*} \nonumber \\
&amp; = &amp; c^{*}+\varepsilon_{t}^{*}+\Phi(c^{*}+\varepsilon_{t-1}^{*})+\ldots+\Phi^{k}(c^{*}+\varepsilon_{t-k}^{*})+\Phi^k y_{t-k}^{*}.
\end{eqnarray*}\]</span></p>
<p>If the eigenvalues of <span class="math inline">\(\Phi\)</span> are strictly within the unit circle, then <span class="math inline">\(\Phi^k\)</span> geometrically decays to the zero matrix and we get the following Wold decomposition for <span class="math inline">\(y_t\)</span>:
<span class="math display" id="eq:VARstar">\[\begin{eqnarray}
y_{t}^{*}  &amp; = &amp; c^{*}+\varepsilon_{t}^{*}+\Phi(c^{*}+\varepsilon_{t-1}^{*})+\ldots+\Phi^{k}(c^{*}+\varepsilon_{t-k}^{*})+\ldots \nonumber \\
&amp; = &amp; \mu^{*} +\varepsilon_{t}^{*}+\Phi\varepsilon_{t-1}^{*}+\ldots+\Phi^{k}\varepsilon_{t-k}^{*}+\ldots,\tag{3.16}
\end{eqnarray}\]</span>
where <span class="math inline">\(\mu^* = (I - \Phi)^{-1} c^*\)</span>.</p>
<p>(It can also be seen that <span class="math inline">\(\mu^{*} = [\mu',\dots,\mu']'\)</span>, where <span class="math inline">\(\mu = (I - \Phi_1 - \dots - \Phi_p)^{-1}c\)</span>).</p>
<p>The unconditional variance of <span class="math inline">\(y_t\)</span> can be derived from Eq. <a href="vector-auto-regressive-var-models.html#eq:VARstar">(3.16)</a>, exploiting the fact that the <span class="math inline">\(\varepsilon_{t}^{*}\)</span> are serially uncorrelated:
<span class="math display">\[
\mathbb{V}ar(y_t^*)=\Omega^*+\Phi\Omega^*\Phi'+\ldots+\Phi^{k}\Omega^*\Phi'^{k}+\ldots,
\]</span>
with <span class="math inline">\(\mathbb{V}ar(\varepsilon_t^*)=\Omega^*\)</span>.</p>
<p>The unconditional variance of <span class="math inline">\(y_t\)</span> is the upper-left <span class="math inline">\(n\times n\)</span> block of matrix <span class="math inline">\(\mathbb{V}ar(y_t^*)\)</span>.</p>
<p>Eq. <a href="vector-auto-regressive-var-models.html#eq:VARstar">(3.16)</a> also implies that the <span class="math inline">\(\Psi_k\)</span> matrices defining the IRFs (see Eq. <a href="vector-auto-regressive-var-models.html#eq:InfMA">(3.4)</a>) are given by: <span class="math inline">\(\Psi_k = \widetilde{\Phi^k}B\)</span>, where <span class="math inline">\(\widetilde{\Phi^k}\)</span> is the upper-left matrix block of <span class="math inline">\(\Phi^k\)</span>.</p>
<p><strong>Granger Causality</strong></p>
<p><span class="citation">Granger (<a href="references.html#ref-Granger_1969" role="doc-biblioref">1969</a>)</span> developed a method to explore <strong>causal relationships</strong> among variables. The approach consists in determining whether the past values of <span class="math inline">\(y_{1,t}\)</span> can help explain the current <span class="math inline">\(y_{2,t}\)</span> (beyond the information already included in the past values of <span class="math inline">\(y_{2,t}\)</span>).</p>
<p>Formally, let us denote three information sets:
<span class="math display">\[\begin{eqnarray*}
\mathcal{I}_{1,t} &amp; = &amp; \left\{ y_{1,t},y_{1,t-1},\ldots\right\} \\
\mathcal{I}_{2,t} &amp; = &amp; \left\{ y_{2,t},y_{2,t-1},\ldots\right\} \\
\mathcal{I}_{t} &amp; = &amp; \left\{ y_{1,t},y_{1,t-1},\ldots y_{2,t},y_{2,t-1},\ldots\right\}.
\end{eqnarray*}\]</span>
We say that <span class="math inline">\(y_{1,t}\)</span> Granger-causes <span class="math inline">\(y_{2,t}\)</span> if
<span class="math display">\[
\mathbb{E}\left[y_{2,t}\mid \mathcal{I}_{2,t-1}\right]\neq \mathbb{E}\left[y_{2,t}\mid \mathcal{I}_{t-1}\right].
\]</span></p>
<p>To get the intuition behind the testing procedure, consider the following
bivariate VAR(<span class="math inline">\(p\)</span>) process:
<span class="math display">\[\begin{eqnarray*}
y_{1,t} &amp; = &amp; c_1+\Sigma_{i=1}^{p}\Phi_i^{(11)}y_{1,t-i}+\Sigma_{i=1}^{p}\Phi_i^{(12)}y_{2,t-i}+\varepsilon_{1,t}\\
y_{2,t} &amp; = &amp; c_2+\Sigma_{i=1}^{p}\Phi_i^{(21)}y_{1,t-i}+\Sigma_{i=1}^{p}\Phi_i^{(22)}y_{2,t-i}+\varepsilon_{2,t},
\end{eqnarray*}\]</span>
where <span class="math inline">\(\Phi_k^{(ij)}\)</span> denotes the element <span class="math inline">\((i,j)\)</span> of <span class="math inline">\(\Phi_k\)</span>.</p>
<p>Then, <span class="math inline">\(y_{1,t}\)</span> is said not to Granger-cause <span class="math inline">\(y_{2,t}\)</span> if
<span class="math display">\[
\Phi_1^{(21)}=\Phi_2^{(21)}=\ldots=\Phi_p^{(21)}=0.
\]</span>
Therefore the hypothesis testing is
<span class="math display">\[
\begin{cases}
H_{0}: &amp; \Phi_1^{(21)}=\Phi_2^{(21)}=\ldots=\Phi_p^{(21)}=0\\
H_{1}: &amp; \Phi_1^{(21)}\neq0\mbox{ or }\Phi_2^{(21)}\neq0\mbox{ or}\ldots\Phi_p^{(21)}\neq0.\end{cases}
\]</span>
Loosely speaking, we reject <span class="math inline">\(H_{0}\)</span> if some of the coefficients on the lagged <span class="math inline">\(y_{1,t}\)</span>’s are statistically significant. Formally, this can be tested using the <span class="math inline">\(F\)</span>-test or asymptotic chi-square test. The <span class="math inline">\(F\)</span>-statistic is
<span class="math display">\[
F=\frac{(RSS-USS)/p}{USS/(T-2p-1)},
\]</span>
where RSS is the Restricted sum of squared residuals and USS is the Unrestricted sum of squared residuals. Under <span class="math inline">\(H_{0}\)</span>, the <span class="math inline">\(F\)</span>-statistic is distributed as <span class="math inline">\(\mathcal{F}(p,T-2p-1)\)</span>.</p>
<p>Note that <span class="math inline">\(pF\underset{T \rightarrow \infty}{\rightarrow}\chi^{2}(p)\)</span>. Therefore, for large samples and under <span class="math inline">\(H_0\)</span>:
<span class="math display">\[
F \sim \chi^{2}(p)/p.
\]</span></p>
<p><strong>Factor-Augmented VAR (FAVAR)</strong></p>
<p>See <a href="https://colab.research.google.com/github/jbduarte/blog/blob/master/_notebooks/2020-04-24-FAVAR-Replication.ipynb#scrollTo=-ArJCCP-WUvl">Blog by Joao B. Duarte</a></p>
<p>VAR models are subject to the curse of dimensionality: If <span class="math inline">\(n\)</span>, is large, then the number of parameters (in <span class="math inline">\(n^2\)</span>) explodes.</p>
<p>In the case where one suspects that the <span class="math inline">\(y_{i,t}\)</span>’s are mainly driven by a small number of random sources, a <strong>factor structure</strong> may be imposed (<span class="citation">Bernanke, Boivin, and Eliasz (<a href="references.html#ref-Bernanke_Boivin_Eliasz_2005" role="doc-biblioref">2005</a>)</span>).</p>
<p>Let us denote by <span class="math inline">\(f_t\)</span> a <span class="math inline">\(k\)</span>-dimensional vector of latent factors accounting for important shares of the variances of the <span class="math inline">\(y_{i,t}\)</span>’s (with <span class="math inline">\(k \ll n\)</span>) and by <span class="math inline">\(x_t\)</span> is a small <span class="math inline">\(q\)</span>-dimensional subset of <span class="math inline">\(y_t\)</span> (with <span class="math inline">\(q \ll n\)</span>). The following factor structure is posited:
<span class="math display">\[
y_t = \Lambda^f f_t + \Lambda^x x_t + e_t,
\]</span>
where the <span class="math inline">\(e_t\)</span> are ``small’’ serially and mutually i.i.d. error terms.</p>
<p>The model is complemented by positing a VAR dynamics for <span class="math inline">\([f_t',x_t']'\)</span>:
<span class="math display" id="eq:FAVAR">\[\begin{equation}
\left[\begin{array}{c}f_t\\x_t\end{array}\right] = \Phi(L)\left[\begin{array}{c}f_{t-1}\\x_{t-1}\end{array}\right] + v_t.\tag{3.17}
\end{equation}\]</span></p>
<p><span class="math inline">\(f_t\)</span> e.g. <span class="math inline">\(\equiv\)</span> the first <span class="math inline">\(k\)</span> principal components of <span class="math inline">\(y_t\)</span>.</p>
<p>Standard identification techniques of structural shocks can be employed in Eq. <a href="vector-auto-regressive-var-models.html#eq:FAVAR">(3.17)</a>: Cholesky approach can be used for instance if the last component of <span class="math inline">\(x_t\)</span> is the short-term interest rate and if it is assumed that a MP shock has no contemporaneous impact on other macro-variables (in <span class="math inline">\(y_t\)</span>).</p>
</div>
<div id="identification-problem-and-standard-identification-techniques" class="section level2" number="3.1">
<h2>
<span class="header-section-number">3.1</span> Identification Problem and Standard Identification Techniques<a class="anchor" aria-label="anchor" href="#identification-problem-and-standard-identification-techniques"><i class="fas fa-link"></i></a>
</h2>
<p><strong>The Identification Issue</strong>*</p>
<p>In the previous section, we have seen how to estimate <span class="math inline">\(\Omega\)</span> and the <span class="math inline">\(\Phi_k\)</span> matrices in the context of a VAR model. But the IRFs are functions of <span class="math inline">\(B\)</span> and the <span class="math inline">\(\Phi_k\)</span>’s, not of <span class="math inline">\(\Omega\)</span> the <span class="math inline">\(\Phi_k\)</span>’s. We have <span class="math inline">\(\Omega = BB'\)</span>, but this is not sufficient to recover <span class="math inline">\(B\)</span>.</p>
<p>Indeed, seen a system of equations whose unknowns are the <span class="math inline">\(b_{i,j}\)</span>’s (components of <span class="math inline">\(B\)</span>), the system <span class="math inline">\(\Omega = BB'\)</span> contains only <span class="math inline">\(n(n+1)/2\)</span> linearly independent equations. Example for <span class="math inline">\(n=2\)</span>:
<span class="math display">\[\begin{eqnarray*}
&amp;&amp;\left[
\begin{array}{cc}
\omega_{11} &amp; \omega_{12} \\
\omega_{12} &amp; \omega_{22}
\end{array}
\right] = \left[
\begin{array}{cc}
b_{11} &amp; b_{12} \\
b_{21} &amp; b_{22}
\end{array}
\right]\left[
\begin{array}{cc}
b_{11} &amp; b_{21} \\
b_{12} &amp; b_{22}
\end{array}
\right]\\
&amp;\Leftrightarrow&amp;\left[
\begin{array}{cc}
\omega_{11} &amp; \omega_{12} \\
\omega_{12} &amp; \omega_{22}
\end{array}
\right] = \left[
\begin{array}{cc}
b_{11}^2+b_{12}^2 &amp; \color{red}{b_{11}b_{21}+b_{12}b_{22}} \\
\color{red}{b_{11}b_{21}+b_{12}b_{22}} &amp; b_{22}^2 + b_{21}^2
\end{array}
\right].
\end{eqnarray*}\]</span></p>
<p>We have 3 linearly independent equations but 4 unknowns. Therefore, <span class="math inline">\(B\)</span> is not identified based on second-order moments. Additional restrictions are required to identify <span class="math inline">\(B\)</span>.</p>
<p>This section covers two standard identification schemes: <strong>short-run</strong> and <strong>long-run</strong> restrictions:</p>
<ol style="list-style-type: decimal">
<li>a <strong>short-run restriction (SRR)</strong> prevents a structural shock from affecting an endogenous variable contemporaneously.</li>
</ol>
<ul>
<li>Easy to implement: the appropriate entries of <span class="math inline">\(B\)</span> are set to 0.</li>
<li>Particular case: <strong>Cholesky, or recursive approach</strong>.</li>
<li>Examples: <span class="citation">Bernanke (<a href="references.html#ref-BERNANKE198649" role="doc-biblioref">1986</a>)</span>, <span class="citation">Sims (<a href="references.html#ref-Sims_1986" role="doc-biblioref">1986</a>)</span>, <span class="citation">Galí (<a href="references.html#ref-Gali_1992" role="doc-biblioref">1992</a>)</span>, <span class="citation">Ruibio-Ramírez, Waggoner, and Zha (<a href="references.html#ref-RubioRamirez_et_al_2010" role="doc-biblioref">2010</a>)</span>.</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>a <strong>long-run restriction (LRR)</strong> prevents a structural shock from having a cumulative impact on one of the endogenous variables.</li>
</ol>
<ul>
<li>Additional computations are required to implement this. One needs to compute the cumulative effect of one of the structural shocks <span class="math inline">\(u_{t}\)</span> on one of the endogenous variable.</li>
<li>Examples: <span class="citation">Blanchard and Quah (<a href="references.html#ref-Blanchard_Quah_1989" role="doc-biblioref">1989</a>)</span>, <span class="citation">Faust and Leeper (<a href="references.html#ref-Faust_Leeper_1997" role="doc-biblioref">1997</a>)</span>, <span class="citation">Galí (<a href="references.html#ref-Gali_1999" role="doc-biblioref">1999</a>)</span>, <span class="citation">Erceg, Guerrieri, and Gust (<a href="references.html#ref-Erceg_et_al_2005" role="doc-biblioref">2005</a>)</span>, <span class="citation">Christiano, Eichenbaum, and Vigfusson (<a href="references.html#ref-NBERc11177" role="doc-biblioref">2007</a>)</span>.</li>
</ul>
<p>The two approaches can be combined (see, e.g., <span class="citation">Gerlach and Smets (<a href="references.html#ref-Gerlach_Smets_1995" role="doc-biblioref">1995</a>)</span>).</p>
<p><strong>A Simple Example</strong></p>
<p>Consider the following stylized economic dynamics:
<span class="math display" id="eq:systemI">\[\begin{equation}
\begin{array}{clll}
g_{t}&amp;=&amp; \bar{g}-\lambda(i_{t-1}-\mathbb{E}_{t-1}\pi_{t})+ \underbrace{{\color{blue}\sigma_d \eta_{d,t}}}_{\mbox{demand shock}}&amp; (\mbox{IS curve})\\
\Delta \pi_{t} &amp; = &amp; \beta (g_{t} - \bar{g})+ \underbrace{{\color{blue}\sigma_{\pi} \eta_{\pi,t}}}_{\mbox{cost push shock}} &amp; (\mbox{Phillips curve})\\
i_{t} &amp; = &amp; \rho i_{t-1} + \left[ \gamma_\pi \mathbb{E}_{t}\pi_{t+1}  + \gamma_g (g_{t} - \bar{g}) \right]\\
&amp;&amp; \qquad \qquad+\underbrace{{\color{blue}\sigma_{mp} \eta_{mp,t}}}_{\mbox{Mon. Pol. shock}} &amp; (\mbox{Taylor rule}),
\end{array}\tag{3.18}
\end{equation}\]</span>
where:
<span class="math display" id="eq:covU">\[\begin{equation}
\eta_t =
\left[
\begin{array}{c}
\eta_{\pi,t}\\
\eta_{d,t}\\
\eta_{mp,t}
\end{array}
\right]
\sim i.i.d.\,\mathcal{N}(0,I).\tag{3.19}
\end{equation}\]</span></p>
<p>Vector <span class="math inline">\(\eta_t\)</span> is a vector of Gaussian {structural shocks}, mutually and serially independent.</p>
<p>On date <span class="math inline">\(t\)</span>:</p>
<ul>
<li>
<span class="math inline">\(g_t\)</span> is contemporaneously affected by <span class="math inline">\(\eta_{d,t}\)</span> only;</li>
<li>
<span class="math inline">\(\pi_t\)</span> is contemporaneously affected by <span class="math inline">\(\eta_{\pi,t}\)</span> and <span class="math inline">\(\eta_{d,t}\)</span>;</li>
<li>
<span class="math inline">\(i_t\)</span> is contemporaneously affected by <span class="math inline">\(\eta_{mp,t}\)</span>, <span class="math inline">\(\eta_{\pi,t}\)</span> and <span class="math inline">\(\eta_{d,t}\)</span>.</li>
</ul>
<p>System <a href="vector-auto-regressive-var-models.html#eq:systemI">(3.18)</a> could be rewritten in the form:
<span class="math display" id="eq:BBBB">\[\begin{equation}
\left[\begin{array}{c}
d_t\\
\pi_t\\
i_t
\end{array}\right]
= \Phi(L)
\left[\begin{array}{c}
d_{t-1}\\
\pi_{t-1}\\
i_{t-1} +
\end{array}\right] +\underbrace{\underbrace{
\left[
\begin{array}{ccc}
0 &amp; \bullet &amp; 0 \\
\bullet &amp; \bullet &amp; 0 \\
\bullet &amp; \bullet &amp; \bullet
\end{array}
\right]}_{=B} \eta_t}_{=\varepsilon_t}\tag{3.20}
\end{equation}\]</span></p>
<p>This is the <strong>reduced-form</strong> of the model. This representation suggests three additional restrictions on the entries of <span class="math inline">\(B\)</span>; the latter matrix is therefore identified (up to the signs of its columns) as soon as <span class="math inline">\(\Omega = BB'\)</span> is known.</p>
<p>There are particular cases in which some well-known matrix decompositions of <span class="math inline">\(\mathbb{V}ar(\varepsilon_t)=\Omega_\varepsilon\)</span> can be used to easily estimate some specific SVAR.</p>
<p>Consider the following context:</p>
<ul>
<li>A first shock (say, <span class="math inline">\(\eta_{n_1,t}\)</span>) can affect instantaneously
(i.e., on date <span class="math inline">\(t\)</span>) only one of the endogenous variable (say, <span class="math inline">\(y_{n_1,t}\)</span>);</li>
<li>A second shock (say, <span class="math inline">\(\eta_{n_2,t}\)</span>) can affect instantaneously
(i.e., on date <span class="math inline">\(t\)</span>) the first two endogenous variables (say, <span class="math inline">\(y_{n_1,t}\)</span>
and <span class="math inline">\(y_{n_2,t}\)</span>);</li>
<li>…</li>
</ul>
<p>This implies (1) that column <span class="math inline">\(n_1\)</span> of <span class="math inline">\(B\)</span> has only 1 non-zero entry (this is the <span class="math inline">\(n_1^{th}\)</span> entry), (2) that column <span class="math inline">\(n_2\)</span> of <span class="math inline">\(B\)</span> has 2 non-zero entries (the <span class="math inline">\(n_1^{th}\)</span> and the <span class="math inline">\(n_2^{th}\)</span> ones), …</p>
<p>Without loss of generality, we can set <span class="math inline">\(n_1=n\)</span>, <span class="math inline">\(n_2=n-1\)</span>, … In this context, matrix <span class="math inline">\(B\)</span> is lower triangular.</p>
<p>The Cholesky decomposition of <span class="math inline">\(\Omega_{\varepsilon}\)</span> then provides an appropriate estimate of <span class="math inline">\(B\)</span>, that is a lower triangular matrix <span class="math inline">\(B\)</span> that is such that:
<span class="math display">\[
\Omega_\varepsilon = BB'.
\]</span></p>
<p>For instance, <span class="citation">Dedola and Lippi (<a href="references.html#ref-DEDOLA20051543" role="doc-biblioref">2005</a>)</span> estimate 5 structural VAR models for the US, the UK, Germany, France and Italy to analyse the monetary-policy transmission mechanisms. They estimate SVAR(5) models over the period 1975-1997. The shock-identification scheme is based on Cholesky decompositions, the ordering of the endogenous variables being: the industrial production, the consumer price index, a commodity price index, the short-term rate, monetary aggregate and the effective exchange rate (except for the US). This ordering implies that monetary policy reacts to the shocks affecting
the first three variables but that the latter react to monetary policy shocks with a one-period lag.</p>
<p>Importantly, the Cholesky approach can be useful if you are essentially interested in one structural shock. This was the case, e.g., of <span class="citation">Christiano, Eichenbaum, and Evans (<a href="references.html#ref-Christiano_Eichenbaum_Evans_1996" role="doc-biblioref">1996</a>)</span>. Their identification is based on the following relationship between <span class="math inline">\(\varepsilon_t\)</span> and <span class="math inline">\(\eta_t\)</span>:
<span class="math display">\[
\left[\begin{array}{c}
\boldsymbol\varepsilon_{S,t}\\
\varepsilon_{r,t}\\
\boldsymbol\varepsilon_{F,t}
\end{array}\right] =
\left[\begin{array}{ccc}
B_{SS} &amp; 0 &amp; 0 \\
B_{rS} &amp; B_{rr} &amp; 0 \\
B_{FS} &amp; B_{Fr} &amp; B_{FF}
\end{array}\right]
\left[\begin{array}{c}
\boldsymbol\eta_{S,t}\\
\eta_{r,t}\\
\boldsymbol\eta_{F,t}
\end{array}\right],
\]</span>
where <span class="math inline">\(S\)</span>, <span class="math inline">\(r\)</span> and <span class="math inline">\(F\)</span> respectively correspond to <em>slow-moving variables</em>, the policy variable (short-term rate) and <em>fast-moving variables</em>. While <span class="math inline">\(\eta_{r,t}\)</span> is scalar, <span class="math inline">\(\boldsymbol\eta_{S,t}\)</span> and <span class="math inline">\(\boldsymbol\eta_{F,t}\)</span> may be vectors. The space spanned by <span class="math inline">\(\boldsymbol\varepsilon_{S,t}\)</span> is the same as that spanned by <span class="math inline">\(\boldsymbol\eta_{S,t}\)</span>. As a result, because <span class="math inline">\(\varepsilon_{r,t}\)</span> is a linear combination of <span class="math inline">\(\eta_{r,t}\)</span> and <span class="math inline">\(\boldsymbol\eta_{S,t}\)</span> (which are <span class="math inline">\(\perp\)</span>), it comes that the <span class="math inline">\(B_{rr}\eta_{r,t}\)</span>’s are the (population) residuals in the regression of <span class="math inline">\(\varepsilon_{r,t}\)</span> on <span class="math inline">\(\boldsymbol\varepsilon_{S,t}\)</span>. Because <span class="math inline">\(\mathbb{V}ar(\eta_{r,t})=1\)</span>, <span class="math inline">\(B_{rr}\)</span> is given by the square root of the variance of <span class="math inline">\(B_{rr}\eta_{r,t}\)</span>. <span class="math inline">\(B_{F,r}\)</span> is finally obtained by regressing the components of <span class="math inline">\(\boldsymbol\varepsilon_{F,t}\)</span> on <span class="math inline">\(\eta_{r,t}\)</span>.</p>
<p>An equivalent approach consists in computing the Cholesky decomposition of <span class="math inline">\(BB'\)</span> and keep only the column corresponding to the policy variable.</p>
<p><strong>Long-run restrictions</strong></p>
<p>A second type of restriction relates to the long-run influence of a shock on an endogenous variable. Let us consider for instance a structural shock that is assumed to have no “long-run influence” on GDP. How to express this? The long-run change in GDP can be expressed as <span class="math inline">\(GDP_{t+h} - GDP_t\)</span>, with <span class="math inline">\(h\)</span> large. Note further that:
<span class="math display">\[
GDP_{t+h} - GDP_t = \Delta GDP_{t+h} +\Delta GDP_{t+h-1} + \dots + \Delta GDP_{t+1}.
\]</span>
Hence, the fact that a given structural shock (<span class="math inline">\(\eta_{i,t}\)</span>, say) has no long-run influence on GDP means that
<span class="math display">\[
\lim_{h\rightarrow\infty}\frac{\partial GDP_{t+h}}{\partial \eta_{i,t}} = \lim_{h\rightarrow\infty} \frac{\partial}{\partial \eta_{i,t}}\left(\sum_{k=1}^h \Delta  GDP_{t+k}\right)= 0.
\]</span></p>
<p>This can be easily formulated as a function of <span class="math inline">\(B\)</span> when <span class="math inline">\(y_t\)</span> (including <span class="math inline">\(\Delta GDP_t\)</span>) follows a VAR(MA) process.</p>
<p>As was shown previously (Eq. <a href="vector-auto-regressive-var-models.html#eq:ystarVAR">(3.15)</a>), one can always write a VAR(<span class="math inline">\(p\)</span>) as a VAR(1). Consequently, let us focus on the VAR(1) case:
<span class="math display">\[\begin{eqnarray}
y_{t} &amp;=&amp; c+\Phi y_{t-1}+\varepsilon_{t}\\
&amp; = &amp; c+\varepsilon_{t}+\Phi(c+\varepsilon_{t-1})+\ldots+\Phi^{k}(c+\varepsilon_{t-k})+\ldots \nonumber \\
&amp; = &amp; \mu +\varepsilon_{t}+\Phi\varepsilon_{t-1}+\ldots+\Phi^{k}\varepsilon_{t-k}+\ldots \\
&amp; = &amp; \mu +B\eta_{t}+\Phi B\eta_{t-1}+\ldots+\Phi^{k}B\eta_{t-k}+\ldots,
\end{eqnarray}\]</span></p>
<p>The sequence of shocks <span class="math inline">\(\{\eta_t\}\)</span> determines the sequence <span class="math inline">\(\{y_t\}\)</span>. What if <span class="math inline">\(\{\eta_t\}\)</span> is replaced by <span class="math inline">\(\{\tilde{\eta}_t\}\)</span>, where <span class="math inline">\(\tilde{\eta}_t=\eta_t\)</span> if <span class="math inline">\(t \ne s\)</span> and <span class="math inline">\(\tilde{\eta}_s=\eta_s + \gamma\)</span>?</p>
<p>Assume <span class="math inline">\(\{\tilde{y}_t\}\)</span> is the associated “perturbated” sequence. We have <span class="math inline">\(\tilde{y}_t = y_t\)</span> if <span class="math inline">\(t&lt;s\)</span>. For <span class="math inline">\(t \ge s\)</span>, the Wold decomposition of <span class="math inline">\(\{\tilde{y}_t\}\)</span> implies:
<span class="math display">\[
\tilde{y}_t = y_t + \Phi^{t-s} B \gamma.
\]</span></p>
<p>Therefore, the cumulative impact of <span class="math inline">\(\gamma\)</span> on <span class="math inline">\(\tilde{y}_t\)</span> will be (for <span class="math inline">\(t \ge s\)</span>):
<span class="math display" id="eq:cumul">\[\begin{eqnarray}
(\tilde{y}_t - y_t) +  (\tilde{y}_{t-1} - y_{t-1}) + \dots +  (\tilde{y}_s - y_s) &amp;=&amp; \nonumber \\
(Id + \Phi + \Phi^2 + \dots + \Phi^{t-s}) B \gamma.&amp;&amp; \tag{3.21}
\end{eqnarray}\]</span></p>
<p>Consider a shock on <span class="math inline">\(\eta_{1,t}\)</span>, with a magnitude of <span class="math inline">\(1\)</span>. This shock is <span class="math inline">\(\gamma = [1,0,\dots,0]'\)</span>. Given Eq. @ref{eq:cumul), the long-run cumulative effect of this shock on the endogenous variables is given by:
<span class="math display">\[
(Id+\Phi+\ldots+\Phi^{k}+\ldots)B\left[\begin{array}{c}
1\\
0\\
\vdots\\
0\end{array}\right],
\]</span>
that is the first column of <span class="math inline">\(\Theta \equiv (I+\Phi+\ldots+\Phi^{k}+\ldots)B\)</span>.</p>
<p>In this context, consider the following long-run restriction: <em>“<span class="math inline">\(j^{th}\)</span> structural shock has no cumulative impact on the <span class="math inline">\(i^{th}\)</span> endogenous variable”</em> is equivalent to
<span class="math display">\[
\Theta_{ij}=0,
\]</span>
where <span class="math inline">\(\Theta_{ij}\)</span> is the element <span class="math inline">\((i,j)\)</span> of <span class="math inline">\(\Theta\)</span>.</p>
<p><span class="citation">Blanchard and Quah (<a href="references.html#ref-Blanchard_Quah_1989" role="doc-biblioref">1989</a>)</span> implement long-run restrictions in a small-scale VAR. Two variables are considered: GDP and unemployment. Consequently, the VAR is affected by two types of shocks. The authors want to identify <strong>supply shocks</strong> (that can have a permanent effect on output) and <strong>demand shocks</strong> (that cannot have a permanent effect on output).</p>
<p>The motivation of the authors regarding their long-run restrictions can be obtained from a traditional Keynesian view of fluctuations. The authors propose a variant of a model from <span class="citation">Fischer (<a href="references.html#ref-Fischer_1977" role="doc-biblioref">1977</a>)</span>:
<span class="math display" id="eq:WS">\[\begin{eqnarray}
Y_{t} &amp; = &amp; M_{t}-P_{t}+a.\theta_{t}\tag{3.22}\\
Y_{t} &amp; = &amp; N_{t}+\theta_{t}\tag{3.23}\\
P_{t} &amp; = &amp; W_{t}-\theta_{t}\tag{3.24}\\
W_{t} &amp; = &amp; W\mid\left\{ \mathbb{E}_{t-1}N_{t}=\overline{N}\right\}. \tag{3.25}
\end{eqnarray}\]</span>
To close the model, the authors assume the following dynamics for the money supply and the productivity:
<span class="math display">\[\begin{eqnarray*}
M_{t} &amp; = &amp; M_{t-1}+\varepsilon_{t}^{d}\\
\theta_{t} &amp; = &amp; \theta_{t-1}+\varepsilon_{t}^{s}.
\end{eqnarray*}\]</span>
In this context, it can be shown that
<span class="math display">\[\begin{eqnarray*}
\Delta Y_{t} &amp; = &amp; (\varepsilon_{t}^{d}-\varepsilon_{t-1}^{d})+a.(\varepsilon_{t}^{s}-\varepsilon_{t-1}^{s})+\varepsilon_{t}^{s}\\
u_{t} &amp; = &amp; -\varepsilon_{t}^{d}-a\varepsilon_{t}^{s}
\end{eqnarray*}\]</span>
Then, it appears that the demand shocks have no long-run cumulative impact on <span class="math inline">\(\Delta Y_{t}\)</span>, the GDP growth, i.e. no long-term impact on output <span class="math inline">\(Y_t\)</span>. The vector of endogenous variables is <span class="math inline">\(y_t = [\Delta Y_{t} \quad u_{t}]'\)</span> where <span class="math inline">\(\Delta Y_{t}\)</span> denotes the GDP growth. Estimation data are quarterly, and span the period from 1950:2 to 1987:4; 8 lags are used in the VAR model.</p>
<div id="Signs" class="section level3" number="3.1.1">
<h3>
<span class="header-section-number">3.1.1</span> Sign restrictions<a class="anchor" aria-label="anchor" href="#Signs"><i class="fas fa-link"></i></a>
</h3>
<p>Let us go back to the VAR(1) case:<span class="math display">\[ y_{t}=c+\Phi
y_{t-1}+\varepsilon_{t}.\]</span></p>
<p>Remember: any <span class="math inline">\(VAR(p)\)</span> can be
written in the form of a VAR(1) companion <span class="math inline">\(VAR(1)\)</span>.</p>
<p>The **residuals
<span class="math inline">\(\varepsilon_{t}\)</span> are assumed to be some linear combinations of
the , that is:<span class="math display">\[
\varepsilon_{t}=B\eta_{t}.\]</span></p>
<p><span class="math inline">\(\eta_t\)</span> is a vector of Gaussian <strong>structural shocks</strong>, mutually and serially independent:
<span class="math display">\[\eta_t = \sim i.i.d.\,\mathcal{N}(0,\Omega_\eta), \quad \mbox{ with }
\Omega_\eta = Id.
\]</span></p>
<p><span class="math inline">\(B\)</span> has to satisfy
<span class="math display">\[\Omega_{\varepsilon}=B\Omega_{\eta}B'=BB',\]</span> which corresponds to
<span class="math inline">\(n(n+1)/2\)</span> restrictions (<span class="math inline">\(&lt;n^2\)</span> required to identify <span class="math inline">\(B\)</span>).</p>
<p><span class="math inline">\(\Rightarrow\)</span> We need some restrictions on <span class="math inline">\(B\)</span>.</p>
<p>So far <strong>Short-run restrictions</strong></p>
<p><span class="math inline">\(B\)</span> is lower triangular. There exists a
unique lower triangular matrix <span class="math inline">\(P\)</span> (Cholesky decomposition) such
that <span class="math inline">\(PP'=\Omega_{\varepsilon}\)</span></p>
<p><span class="math inline">\(B=P\)</span>: identification!</p>
<p><strong>Long-run restrictions</strong></p>
<p>Cumulative effect of the shock <span class="math inline">\(\eta_{t}\)</span> from time <span class="math inline">\(t\)</span> to
<span class="math inline">\(t+\infty\)</span>:
<span class="math display">\[\bar y_{t,t+\infty}=\sum_{j=0}^{+\infty}\Phi^jB\eta_{t}=\underbrace{(I-\Phi)^{-1}B}_{D}\eta_{t}\]</span></p>
<p>Note that
<span class="math display">\[DD'= (I -\Phi)^{-1}BB'(I
-\Phi)^{-1'} = \underbrace{(I -\Phi)^{-1}\Omega_{\varepsilon}(I
-\Phi)^{-1'}}_{\text{known}}\]</span></p>
<p>There exists a unique lower triangular matrix <span class="math inline">\(P\)</span> such that <span class="math inline">\(PP' =(I-\Phi)^{-1}\Omega_{\varepsilon}(I -\Phi)^{-1'}\)</span>. If we assume <span class="math inline">\(D\)</span> is lower triangular, then <span class="math inline">\(D=P\)</span>.</p>
<p><span class="math inline">\(B=(I-\Phi)P\)</span>: identification!</p>
<p>Limits: Restrictions are either short-run or long-run</p>
<p>What about intermediate horizons? Forecast error variance maximization</p>
<p>Zero restrictions = very strong assumptions</p>
<p>Macro variables typically comove within a quarter (or worse, a year)<br></p>
<p><strong>Sign restrictions</strong></p>
<p>In the zero short-run restriction identification we used the fact that <span class="math inline">\(\Omega_{\varepsilon} = BB'\)</span> and <span class="math inline">\(\Omega_{\varepsilon} = PP'\)</span> where the lower triangular <span class="math inline">\(P\)</span> matrix is the Cholesky decomposition of <span class="math inline">\(\Omega_{\varepsilon}\)</span>.</p>
<p>An <strong>orthonormal matrix</strong> <span class="math inline">\(Q\)</span> is a matrix such that <span class="math display">\[QQ' = I,\]</span> i.e., all columns (rows) of <span class="math inline">\(Q\)</span> are are
orthogonal and unit vectors:
<span class="math display">\[q_i'q_j=0\text{ if }i\neq j\text{ and }q_i'q_j=1\text{ if }i= j,\]</span>
where <span class="math inline">\(q_i\)</span> is the <span class="math inline">\(i^{th}\)</span> column of <span class="math inline">\(Q\)</span>.</p>
<p>For a given random {orthonormal matrix} we have that <span class="math display">\[\Omega_{\varepsilon} = PP' = PQQ'P'  =\mathcal{P}\mathcal{P}'\]</span> where <span class="math inline">\(\mathcal{P}=PQ\)</span> is generally not triangular anymore.</p>
<p><span class="math inline">\(B = \mathcal{P}\)</span> is clearly a valid solution to the identification problem. But <span class="math inline">\(Q\)</span> is a random matrix… is the solution <span class="math inline">\(B = \mathcal{P}\)</span> plausible? Identification is achieved by checking whether the impulse responses implied by <span class="math inline">\(Q\)</span> satisfy a set of a priori (and possibly theory-driven) sign restrictions. We can draw as many <span class="math inline">\(Q\)</span> as we want and construct a distribution of the solutions that satisfy the sign
restrictions.</p>
<p>Important issue: What does the set of orthonormal matrices <span class="math inline">\(Q\)</span> look like and how can we manage to truly draw <span class="math inline">\(Q\)</span>s randomly from that set?</p>
<p>In linear algebra, a rotation matrix is a matrix that is used to perform a rotation in Euclidean space.</p>
<p>For example, in <span class="math inline">\(\mathbb{R}^2\)</span>,
<span class="math display">\[Q_x=\begin{pmatrix}\cos(x)&amp;\cos\left(x+\frac{\pi}{2}\right)\\
\sin(x)&amp;\sin\left(x+\frac{\pi}{2}\right)\end{pmatrix}=\begin{pmatrix}\cos(x)&amp;-\sin(x)\\
\sin(x)&amp;\cos(x)\end{pmatrix}\]</span>
applies an <span class="math inline">\(x\)</span> angle counter-clockwise rotation to a vector.</p>
<p><span class="math inline">\(Q_x=\begin{pmatrix}\cos(x)&amp;-\sin(x)\\ \sin(x)&amp;\cos(x)\end{pmatrix}\)</span> is orthonormal (its vectors lie on the unit circle and are orthogonal).</p>
<p>It is parametrized by <span class="math inline">\(x\)</span>. <span class="math inline">\(x\in[0,2\pi]\)</span> spans the entire space of rotation matrices in <span class="math inline">\(\mathbb{R}^2\)</span>.</p>
<p>By drawing <span class="math inline">\(x\)</span> randomly from <span class="math inline">\(U[0,2\pi]\)</span>, we draw randomly from the set of <span class="math inline">\(2\times2\)</span> rotation matrices.</p>
<p>It is not always possible to parametrize a rotation matrix (high-dimentional VARs).</p>
<p>How do we do then?</p>
<p><span class="citation">Arias, Rubio-Ramírez, and Waggoner (<a href="references.html#ref-Arias_et_al_2018" role="doc-biblioref">2018</a>)</span> provide a procedure. Note: any square matrix <span class="math inline">\(X\)</span> may be decomposed as <span class="math inline">\(X=QR\)</span> where <span class="math inline">\(Q\)</span> is an orthogonal matrix and <span class="math inline">\(R\)</span> is an upper diagonal matrix (<span class="math inline">\(QR\)</span> decomposition).</p>
<ol style="list-style-type: decimal">
<li>Draw a random matrix <span class="math inline">\(X\)</span> by drawing each element from independent standard normal distribution.</li>
<li>Let <span class="math inline">\(X = QR\)</span> be the <span class="math inline">\(QR\)</span> decomposition of <span class="math inline">\(X\)</span> with the diagonal of <span class="math inline">\(R\)</span> normalized to be
positive. The random matrix <span class="math inline">\(Q\)</span> is orthogonal and is a draw from the uniform distribution over the set of orthogonal matrices.</li>
</ol>
<p><strong>Algorithm</strong></p>
<ol style="list-style-type: decimal">
<li>Draw a random orthonormal matrix <span class="math inline">\(Q\)</span>
</li>
<li>Compute <span class="math inline">\(B = PQ\)</span> where <span class="math inline">\(P\)</span> is the Cholesky decomposition of the reduced form residuals <span class="math inline">\(\Omega_{\varepsilon}\)</span>
</li>
<li>Compute the impulse response associated with <span class="math inline">\(B\)</span> <span class="math display">\[ y_{t,t+k}=\Phi^kB\]</span> or the cumulated response <span class="math display">\[\bar y_{t,t+k}=\sum_{j=0}^{k}\Phi^jB\]</span>
</li>
<li>Are the sign restrictions satisfied?</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>
<strong>Yes</strong>. Store the impulse response</li>
<li>
<strong>No</strong>. Discard the impulse response</li>
</ol>
<ol start="5" style="list-style-type: decimal">
<li>Perform N replications and report the median impulse response (and its confidence intervals)</li>
</ol>
<p>Note: to take into account the uncertainty in <span class="math inline">\(B\)</span> and <span class="math inline">\(\Phi\)</span>, you can draw <span class="math inline">\(B\)</span> and <span class="math inline">\(\Phi\)</span> in steps 2 and 3 using an inference method.</p>
<p><strong>Advantages:</strong></p>
<ul>
<li>Relatively agnostic</li>
<li>Flexible (can impose sign restrictions on any variable, at any horizon)</li>
</ul>
<p>Example: <span class="citation">Uhlig (<a href="references.html#ref-Uhlig_2005" role="doc-biblioref">2005</a>)</span> “What are the effects of monetary policy on output? Results from an agnostic
identification procedure,.” US monthly data from 1965.I to 2003.XII</p>
<p>Before asking what are the effects of a monetary policy shocks we should be asking, what is a <strong>monetary policy shock?</strong>
In the inflation targeting era a monetary policy shock is an increase in the policy rate that is ordered last in a Cholesky decomposition? has no permanent effect on output? ….?</p>
<p>According to conventional wisdom, monetary contractions should</p>
<ul>
<li>Raise the federal funds rate</li>
<li>Lower prices</li>
<li>Decrease non-borrowed reserves</li>
<li>Reduce real output</li>
</ul>
<p>Standard identification schemes do not fully accomplish the 4 points above</p>
<ul>
<li>Liquidity puzzle: when identifying monetary policy shocks as surprise increases in the stock of money, interest rates tend to go up, not down</li>
<li>Price puzzle: after a contractionary monetary policy shock, even with interest rates going up and money supply going down, inflation goes up rather than down</li>
</ul>
<p>Successful identification needs to deliver results matching the conventional wisdom</p>
<p><span class="citation">Uhlig (<a href="references.html#ref-Uhlig_2005" role="doc-biblioref">2005</a>)</span>’s assumption: a contractionary monetary policy shock does not lead to</p>
<ul>
<li>Increases in prices</li>
<li>Increase in nonborrowed reserves</li>
<li>Decreases in the federal funds rate</li>
</ul>
<p>How about output? Since is the response of interest, we leave it un-restricted.</p>
<p>Another approach</p>
<p>If <span class="math inline">\(B\)</span> satisfies <span class="math inline">\(BB'=\Omega_\varepsilon\)</span>, the vectors of <span class="math inline">\(B\)</span> are called <strong>impulse vectors</strong></p>
<p>Let <span class="math inline">\(b\)</span> be en impulse vector, there exists a unit-length vector <span class="math inline">\(q\)</span> (i.e. <span class="math inline">\(q'q=1\)</span>) so that <span class="math display">\[b=Pq\]</span></p>
<p><span class="math inline">\(b\)</span> describes the response of the variables to a shock that is a linear combination (with weights given by <span class="math inline">\(q\)</span>) of the shocks associated to the Cholesky decomposition. It’s a “candidate shock” for the sign restrictions.</p>
<p>Note that <span class="math inline">\(b\)</span> is associated to a unique unit-length vector <span class="math inline">\(q\)</span>. To span the
potential <span class="math inline">\(b\)</span>s, it is enough to span the <span class="math inline">\(q\)</span>s.</p>
<p>Let <span class="math inline">\(\psi_k^i\)</span> be the vector response at horizon <span class="math inline">\(k\)</span> to the <span class="math inline">\(i^{th}\)</span> shock in the
Cholesky decomposition of <span class="math inline">\(\Omega_\varepsilon\)</span>. The <span class="math inline">\(\psi_k^i\)</span> are the columns of <span class="math inline">\(\Psi_k\)</span>, defined as follows:
<span class="math display">\[\Psi_k=\Phi^kP.\]</span></p>
<p>The impulse response <span class="math inline">\(\psi_k(q)\)</span> associated to <span class="math inline">\(q\)</span> is then given by
<span class="math display">\[\psi_k(q)=\sum_{i=1}^m q_i\psi_k^i=\Psi_kq\]</span></p>
<ol style="list-style-type: decimal">
<li>Compute <span class="math inline">\(\Psi_k=\Phi^kP\)</span> (or <span class="math inline">\(\sum_{j=0}^k\Psi_k\)</span>) using <span class="math inline">\(P\)</span>,
the Cholesky decomposition of <span class="math inline">\(\Omega_\varepsilon\)</span>.</li>
<li>Draw a random orthonormal vector <span class="math inline">\(q\)</span>
</li>
<li>Compute the impulse response associated with <span class="math inline">\(q\)</span> <span class="math display">\[ y_{t,t+k}=\Psi_kq\]</span> or the cumulated response <span class="math display">\[\bar y_{t,t+k}=\left(\sum_{j=0}^k\Psi_k\right)q\]</span>
</li>
<li>Are the sign restrictions satisfied?</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>
<strong>Yes</strong>. Store the impulse response</li>
<li>
<strong>No</strong>. Discard the impulse response</li>
</ol>
<ol start="5" style="list-style-type: decimal">
<li>Perform N times (starting from 2.) and report the median impulse response (and its confidence intervals)</li>
</ol>
<p>How to draw a unit-length vector?</p>
<ol style="list-style-type: decimal">
<li>Draw a vector <span class="math inline">\(u\)</span> from the standard normal distribution on
<span class="math inline">\(\mathbb{R}^m\)</span>.</li>
<li>Compute <span class="math inline">\(q = u/||u||\)</span>.</li>
</ol>
<p>What if we identify <span class="math inline">\(l&gt;1\)</span> shocks? We need to draw <span class="math inline">\(q_1\)</span>,…,<span class="math inline">\(q_l\)</span> that are orthonormal.</p>
<ul>
<li>For <span class="math inline">\(1\le j\le l\)</span>, draw <span class="math inline">\(u_j\in \mathbb{R}^{m+1-j}\)</span> from a standard normal distribution and set <span class="math inline">\(w_j = u_j/||u_j||\)</span>.</li>
<li>Define <span class="math inline">\(\begin{pmatrix}q_1&amp;...&amp;q_l\end{pmatrix}\)</span> recursively by <span class="math inline">\(q_j = K_jw_j\)</span> for any matrix <span class="math inline">\(K_j\)</span> whose columns form an orthonormal basis for the null space of the matrix <span class="math display">\[M_j = \begin{pmatrix} q_1&amp;...&amp;q_{j-1}\end{pmatrix}'\]</span> (<span class="math inline">\(q_j\)</span> will be orthogonal to <span class="math inline">\(\begin{pmatrix} q_1&amp;...&amp;q_{j-1}\end{pmatrix}\)</span>)</li>
</ul>
<p>Characteristics of sign restrictions: there is not a unique IRF (set-identified, not point-identified).</p>
<p>By drawing the rotation matrices (<span class="math inline">\(Q\)</span>) from a uniform distribution and taking the median, we adopt an agnostic approach: “pure sign restriction approach”</p>
<p>Alternative approach: “Penalty-function approach” (PFA, <span class="citation">Uhlig (<a href="references.html#ref-Uhlig_2005" role="doc-biblioref">2005</a>)</span>, present in <span class="citation">Danne (<a href="references.html#ref-Danne_2015" role="doc-biblioref">2015</a>)</span>’s package)</p>
<p>Penalizes sign violation, rewards correct sign (but also magnitude)</p>
<p>Selects the “best” rotation matrix (equivalently, the ``best’’ IRF).</p>
<p><strong>PFA</strong></p>
<p>Define the <strong>penalty function</strong>:
<span class="math display">\[\begin{array}{llll}f(x)&amp;=&amp;x&amp;\text{ if }x\le0\\
&amp;&amp;100.x&amp;\text{ if }x&gt;0\end{array}\]</span> which penalizes positive
responses and rewards negative responses.</p>
<p>Let <span class="math inline">\(\psi_k^j(q)\)</span> be the impulse response of variable <span class="math inline">\(j\)</span>. The <span class="math inline">\(\psi_k^j(q)\)</span>s are the elements of <span class="math inline">\(\psi_k(q)=\Psi_kq\)</span>.</p>
<p>Let <span class="math inline">\(\sigma_j\)</span> be the standard deviation of variable <span class="math inline">\(j\)</span>. Let <span class="math inline">\(\iota_{j,k}=1\)</span> if we restrict the response of variable <span class="math inline">\(j\)</span> at the <span class="math inline">\(k^th\)</span> horizon to be negative, <span class="math inline">\(\iota_{j,k}=-1\)</span> if we restrict it to be positive, and <span class="math inline">\(\iota_{j,k}=0\)</span> if there is no restriction. The total penalty is <span class="math display">\[\mathbf{P}(q)=\sum_{j=1}^m\sum_{k=0}^Kf\left(\iota_{j,k}\frac{\psi_k^j(q)}{\sigma_j}\right)\]</span></p>
<p>We are looking for a solution to
<span class="math display">\[\begin{array}{ll}&amp;\min_q \mathbf{P}(q)\\
&amp;\\
\text{s.t. }&amp;q'q=1\end{array}\]</span></p>
<p>Here you can use standard minimization routines in R or Matlab.</p>
<p><strong>Combining zero and sign restrictions</strong></p>
<p>Sometimes we need to combine more then one restriction approach. For instance:
* one shock satisfies both zero and sign restrictions
* some shocks can be identified with zero restrictions (SR or LR), others with sign restrictions
* Some shocks satisfy the same zero restrictions (e.g. no LR effect on output) but can be distinguished from each other through sign restrictions</p>
<p>We must make independent draws from the set of all structural parameters satisfying the zero
restrictions. How to do that?</p>
<p><span class="citation">Arias, Rubio-Ramírez, and Waggoner (<a href="references.html#ref-Arias_et_al_2018" role="doc-biblioref">2018</a>)</span>: Idea: impose zero restrictions on <span class="math inline">\(B\)</span>, then check signs</p>
<p>Remember, <span class="math inline">\(B=PQ\)</span> is a candidate impact IRF. For each structural shock <span class="math inline">\(j\)</span>, define the <span class="math inline">\(m\)</span>-column matrices</p>
<p><span class="math inline">\(Z_j\)</span> (zero restrictions) and $S_j$ (sign restrictions).</p>
<p>Each row corresponds to one zero (or sign) restriction.</p>
<p><span class="math inline">\(Z_j\)</span> has <span class="math inline">\(m-j\)</span> rows at most (i.e. <span class="math inline">\(m-j\)</span> zero restriction at most).</p>
<p>Example: In a 4-variable VAR, we want to impose that the first structural shock has no effect on variable 1, affects positively variable 2 and negatively variable 3 on impact:
<span class="math display">\[Z_1 = \begin{pmatrix}1 &amp; 0 &amp; 0 &amp; 0\end{pmatrix} \]</span>
<span class="math display">\[S_1 = \begin{pmatrix}0 &amp; 1 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; -1 &amp; 0\end{pmatrix} \]</span></p>
<p>For both zero and sign restrictions to be satisfied, we must have that <span class="math display">\[Z_jb_j=0\]</span> <span class="math display">\[S_jb_j&gt;0\]</span> where <span class="math inline">\(b_j\)</span> is the <span class="math inline">\(j^{th}\)</span> column of <span class="math inline">\(B\)</span>, i.e. the impact effect of the <span class="math inline">\(j^{th}\)</span> structural shock.</p>
<p><strong>Algorithm</strong></p>
<ol style="list-style-type: decimal">
<li>For <span class="math inline">\(1\le j\le m\)</span>, draw <span class="math inline">\(u_j\in \mathbb{R}^{m+1-j-z_j}\)</span>, where <span class="math inline">\(z_j\)</span> is the number of zero restrictions imposed on the <span class="math inline">\(j^{th}\)</span> shock, from a standard normal distribution and set <span class="math inline">\(w_j = u_j/||u_j||\)</span>.</li>
<li>Define <span class="math inline">\(Q= \begin{pmatrix}q_1&amp;...&amp;q_m\end{pmatrix}\)</span> recursively by <span class="math inline">\(q_j = K_jw_j\)</span> for any matrix <span class="math inline">\(K_j\)</span> whose columns form an orthonormal basis for the null space of the matrix <span class="math display">\[M_j =
\begin{pmatrix} q_1&amp;...&amp;q_{j-1}&amp;{\color{blue}(Z_jP)'}\end{pmatrix}'\]</span> (<span class="math inline">\(q_j\)</span> will be orthogonal to <span class="math inline">\(\begin{pmatrix} q_1&amp;...&amp;q_{j-1}\end{pmatrix}\)</span> and satisfy the zero restriction)</li>
<li>Set <span class="math inline">\(B=PQ\)</span>.</li>
<li>Check sign restrictions (<span class="math inline">\(S_jb_j&gt;0\)</span> for all <span class="math inline">\(j\)</span>?).</li>
</ol>
<p>Perform N replications and report the median impulse response (and its confidence intervals)</p>
<p><strong>Forecast error variance maximization</strong></p>
<p>See also <span class="citation">Barsky and Sims (<a href="references.html#ref-BARSKY2011273" role="doc-biblioref">2011</a>)</span>: <em>The news shock is identified as the shock orthogonal to the innovation in current utilization-adjusted TFP that best explains variation in future TFP.</em></p>
<p><span class="citation">Uhlig (<a href="references.html#ref-Uhlig_2004" role="doc-biblioref">2004</a>)</span>: We can write <span class="math inline">\(y_t\)</span> as <span class="math display">\[y_t=\sum_{h=0}^{+\infty}\Phi^h\varepsilon_{t-h}\]</span> where <span class="math inline">\(\varepsilon_t\)</span> are the residuals.</p>
<p>Let <span class="math inline">\(P\)</span> be the Cholesky decomposition <span class="math inline">\(\Omega_\varepsilon=PP'\)</span>.</p>
<p>With the Cholesky decomposition
<span class="math display">\[\begin{array}{lll}y_t&amp;=&amp;\sum_{h=0}^{+\infty}\Phi^h\underbrace{\varepsilon_{t-h}}_{P\eta_{t-h}}\\
&amp;=&amp;\sum_{h=0}^{+\infty}\underbrace{\Phi^hP}_{\Psi_h}\eta_{t-h}\\
&amp;=&amp;\sum_{h=0}^{+\infty}\Psi_h\eta_{t-h}\end{array}\]</span> where <span class="math inline">\(\Psi_h=\Phi^hP\)</span> are the impulse responses at horizon <span class="math inline">\(h\)</span> to the shocks identified in this decomposition.</p>
<p>Let <span class="math inline">\(Q\)</span> be an orthogonal matrix, an alternative decomposition is <span class="math display">\[\begin{array}{lll}y_t&amp;=&amp;\sum_{h=0}^{+\infty}\Psi_h\underbrace{\eta_{t-h}}_{Q\tilde \eta_{t-h}}\\
&amp;=&amp;\sum_{h=0}^{+\infty}\underbrace{\Psi_hQ}_{\tilde\Psi_h}\tilde
\eta_{t-h}\\
&amp;=&amp;\sum_{h=0}^{+\infty}\tilde\Psi_h\tilde \eta_{t-h}\end{array}\]</span>
where <span class="math inline">\(\tilde\Psi_h=\Phi^hPQ\)</span> are the impulse responses at horizon <span class="math inline">\(h\)</span> to the shocks identified in this alternative decomposition, and <span class="math inline">\(\tilde \eta_{t-h}=Q'\eta_{t-h}\)</span> are the corresponding shocks.</p>
<p>The <span class="math inline">\(h\)</span>-step ahead prediction error of <span class="math inline">\(y_{t+h}\)</span> given all the data up to and including <span class="math inline">\(t-1\)</span> is given by
<span class="math display">\[e_{t+h}(h)=y_{t+h}-E_{t-1}(y_{t+h})=\sum_{j=0}^h\tilde \Psi_h\tilde \eta_{t+h-j}\]</span></p>
<p>The variance-covariance matrix of <span class="math inline">\(e_{t+h}(h)\)</span> is <span class="math display">\[\Omega(h)=\sum_{j=0}^h\tilde \Psi_j\tilde \Psi_j'=\sum_{j=0}^h \Psi_j \Psi_j'\]</span></p>
<p>We can decompose <span class="math inline">\(\Omega(h)\)</span> into the contribution of each shock <span class="math inline">\(l\)</span>: <span class="math display">\[\Omega(h)=\sum_{l=1}^m\Omega(h,l)\]</span>
with <span class="math display">\[\Omega(h,l)=\sum_{j=0}^h(\Psi_jq_l)(\Psi_jq_l)'\]</span></p>
<p>This method aims at finding an <strong>impulse vector <span class="math inline">\(b\)</span></strong>, so that this impulse vector explains as much as possible of the sum of the <span class="math inline">\(h\)</span>-step ahead prediction error variance of some
variable <span class="math inline">\(i\)</span>, say, for prediction horizons <span class="math inline">\(h = \underline{h} \le \overline{h}\)</span>.</p>
<p>Formally then, the task is to explain as much as possible of the variance
<span class="math display">\[\sigma^2(\underline{h},\overline{h})=\sum_{h=\underline{h}}^{\overline{h}} \Omega(h)_{ii}\]</span> with a single impulse vector.</p>
<p>This amounts to finding a vector <span class="math inline">\(q_1\)</span> of unit length, maximizing
<span class="math display">\[\sigma^2(\underline{h},\overline{h},q_1)=\sum_{h=\underline{h}}^{\overline{h}} \Omega(h,1)_{ii}\]</span></p>
<p>Calculate
<span class="math display">\[\begin{array}{lll}\sigma^2(\underline{h},\overline{h},q_1)&amp;=&amp;\sum_{h=\underline{h}}^{\overline{h}}
\Omega(h,1)_{ii}\\
&amp;=&amp; \sum_{h=\underline{h}}^{\overline{h}}\sum_{l=0}^{h}\left((\Psi_lq_1)(\Psi_lq_1)'\right)_{ii}\\
&amp;=&amp; \sum_{h=\underline{h}}^{\overline{h}}\sum_{l=0}^{h}trace\left(E_{ii}(\Psi_lq_1)(\Psi_lq_1)'\right)\\
&amp;=&amp; q_1'Sq_1\\
\end{array}\]</span>
where
<span class="math display">\[\begin{array}{lll}S&amp;=&amp;\sum_{h=\underline{h}}^{\overline{h}}\sum_{l=0}^{h}\Psi_l'E_{ii}\Psi_l\\
&amp;=&amp;\sum_{l=0}^{\overline{h}}(\overline{h}+1-max(\underline{h},l))\Psi_l'E_{ii}\Psi_l\\
&amp;=&amp;\sum_{l=0}^{\overline{h}}(\overline{h}+1-max(\underline{h},l))\Psi_{l,i}'\Psi_{l,i}\\
\end{array}\]</span>
where <span class="math inline">\(\Psi_{l,i}\)</span> denotes row <span class="math inline">\(i\)</span> of <span class="math inline">\(\Psi_{l}\)</span>, i.e. the response of variable <span class="math inline">\(i\)</span> at horizon <span class="math inline">\(l\)</span>.</p>
<p>The maximization problem subject to the side constraint <span class="math inline">\(q_1'q_1=1\)</span> can be written as a Lagrangian, <span class="math display">\[L=q_1'Sq_1-\lambda(q_1'q_1-1)\]</span> with the first-order condition
<span class="math display">\[Sq_1=\lambda q_1\]</span> and the side constraint <span class="math inline">\(q_1'q_1=1\)</span>.</p>
<p>From this equation, we see that the solution <span class="math inline">\(q_1\)</span> is an eigenvector of <span class="math inline">\(S\)</span> with eigenvalue <span class="math inline">\(\lambda\)</span>.</p>
<p>We also see that <span class="math display">\[\sigma^2(\underline{h},\overline{h},q_1)=\lambda\]</span></p>
<p>Thus, to maximize this variance, we need to find the eigenvector with the maximal eigenvalue <span class="math inline">\(\lambda\)</span>, i.e., we need to find the first principal component.</p>
<p>The impulse vector <span class="math inline">\(b\)</span> is then found as <span class="math display">\[b=Pq_1\]</span>.</p>
</div>
<div id="NonGaussian" class="section level3" number="3.1.2">
<h3>
<span class="header-section-number">3.1.2</span> Non-Gaussian Shocks<a class="anchor" aria-label="anchor" href="#NonGaussian"><i class="fas fa-link"></i></a>
</h3>
<p>In this section, we show that the non-identification of the structural shocks (<span class="math inline">\(\eta_t\)</span>) is very specific to the Gaussian case. We propose consistent estimation approaches in the context of non-Gaussian shocks. In a first part, we focus on non-Gaussian SVAR models; in a second part, we discuss the case of non-Gaussian SVARMA models.</p>
<p><strong>Non-Gaussian SVAR models</strong></p>
<p>The estimation of (S)VARs is more common than that of (S)VARMAs. (Simpler estimation of <span class="math inline">\(\Phi_k\)</span>’s). We have seen in what precedes that, in the Gaussian case, we cannot identify <span class="math inline">\(B\)</span> in the Gaussian case. That is, even if we observe an infinite number of i.i.d. <span class="math inline">\(B \eta_t\)</span>, we cannot recover <span class="math inline">\(B\)</span> is the <span class="math inline">\(\eta_t\)</span>’s are Gaussian. Indeed, if <span class="math inline">\(\eta_t \sim \mathcal{N}(0,Id)\)</span>, then the distribution of <span class="math inline">\(\varepsilon_t \equiv B \eta_t\)</span> is <span class="math inline">\(\mathcal{N}(0,BB')\)</span>.</p>
<p>Hence <span class="math inline">\(\Omega = B B'\)</span> is observed (in the population), but for any orthogonal matrix <span class="math inline">\(Q\)</span> (i.e. <span class="math inline">\(QQ'=Id\)</span>), we also have <span class="math inline">\(BQ \eta_t \sim \mathcal{N}(0,\Omega)\)</span>.</p>
<p>Example: Bivariate Gaussian case (Eq. <a href="vector-auto-regressive-var-models.html#eq:VARMA111">(3.6)</a>, with <span class="math inline">\(\Theta_1=0\)</span>)</p>
<p><span class="math inline">\(\left[\begin{array}{c}\eta_{1,t}\\ \eta_{2,t}\end{array}\right]\sim \mathcal{N}(0,Id)\)</span>,
<span class="math inline">\(B = \left[\begin{array}{cc} 1 &amp; 2 \\ -1 &amp; 1 \end{array}\right]\)</span> and
<span class="math inline">\(Q = \left[\begin{array}{cc} \cos(\pi/3) &amp; -\sin(\pi/3) \\ \sin(\pi/3) &amp; \cos(\pi/3) \end{array}\right]\)</span> (rotation).</p>
<p><span class="math inline">\(\Rightarrow\)</span> Distribution of <span class="math inline">\(B \eta_t\)</span> versus that of <span class="math inline">\(BQ\eta_t\)</span>?</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">theta.angle</span> <span class="op">&lt;-</span> <span class="va">pi</span><span class="op">/</span><span class="fl">3</span></span>
<span><span class="va">Q</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Trig.html">cos</a></span><span class="op">(</span><span class="va">theta.angle</span><span class="op">)</span>,<span class="fu"><a href="https://rdrr.io/r/base/Trig.html">sin</a></span><span class="op">(</span><span class="va">theta.angle</span><span class="op">)</span>,<span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/Trig.html">sin</a></span><span class="op">(</span><span class="va">theta.angle</span><span class="op">)</span>,<span class="fu"><a href="https://rdrr.io/r/base/Trig.html">cos</a></span><span class="op">(</span><span class="va">theta.angle</span><span class="op">)</span><span class="op">)</span>,<span class="fl">2</span>,<span class="fl">2</span><span class="op">)</span></span>
<span><span class="co">#nb.sim &lt;- 10^4</span></span>
<span><span class="va">nb.sim</span> <span class="op">&lt;-</span> <span class="fl">10</span><span class="op">^</span><span class="fl">2</span></span>
<span><span class="va">distri.1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>type<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"gaussian"</span><span class="op">)</span>,name<span class="op">=</span><span class="st">"Panel (a) Gaussian"</span>,name.4.table<span class="op">=</span><span class="st">"Gaussian"</span><span class="op">)</span></span>
<span><span class="va">distri.2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>type<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"mixt.gaussian"</span><span class="op">)</span>,mu<span class="op">=</span><span class="fl">0</span>,sigma<span class="op">=</span><span class="fl">5</span>,p<span class="op">=</span><span class="fl">.03</span>,name<span class="op">=</span><span class="st">"Panel (b) Mixture of Gaussian"</span>,name.4.table<span class="op">=</span><span class="st">"Mixture of Gaussian"</span><span class="op">)</span></span>
<span><span class="va">distri.3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>type<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"student"</span><span class="op">)</span>,df<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">5</span><span class="op">)</span>,name<span class="op">=</span><span class="st">"Panel (c) Student (df: 5)"</span>,name.4.table<span class="op">=</span><span class="st">"Student (df: 5)"</span><span class="op">)</span></span>
<span><span class="va">distri.4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>type<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"student"</span><span class="op">)</span>,df<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span>,name<span class="op">=</span><span class="st">"Panel (d) Student (df: 10)"</span>,name.4.table<span class="op">=</span><span class="st">"Student (df: 10)"</span><span class="op">)</span></span>
<span><span class="va">x.lim</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">7</span>,<span class="fl">7</span><span class="op">)</span></span>
<span><span class="va">y.lim</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">5</span>,<span class="fl">5</span><span class="op">)</span></span>
<span><span class="va">nb.points</span> <span class="op">&lt;-</span> <span class="fl">100</span></span>
<span><span class="va">x.points</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="va">x.lim</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>,<span class="va">x.lim</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>,length.out<span class="op">=</span><span class="va">nb.points</span><span class="op">)</span></span>
<span><span class="va">y.points</span> <span class="op">&lt;-</span> <span class="va">x.points</span></span>
<span><span class="va">all.x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="va">x.points</span>,<span class="va">nb.points</span>,<span class="va">nb.points</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">all.y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="va">x.points</span>,<span class="va">nb.points</span>,<span class="va">nb.points</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">eps</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">all.x</span>,<span class="va">all.y</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>plt<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">.25</span>,<span class="fl">.9</span>,<span class="fl">.25</span>,<span class="fl">.8</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">eta.1</span> <span class="op">&lt;-</span> <span class="fu">simul.distri</span><span class="op">(</span><span class="va">distri.1</span>,<span class="va">nb.sim</span><span class="op">)</span></span>
<span><span class="va">eta.2</span> <span class="op">&lt;-</span> <span class="fu">simul.distri</span><span class="op">(</span><span class="va">distri.1</span>,<span class="va">nb.sim</span><span class="op">)</span></span>
<span><span class="va">epsilon.C</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">eta.1</span>,<span class="va">eta.2</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">C</span><span class="op">)</span></span>
<span><span class="va">epsilon.CQ</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">eta.1</span>,<span class="va">eta.2</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">C</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">Q</span><span class="op">)</span></span>
<span><span class="va">Model</span><span class="op">$</span><span class="va">distri</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>type<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"gaussian"</span>,<span class="st">"gaussian"</span><span class="op">)</span>,df<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="cn">NaN</span>,<span class="cn">NaN</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/plot.html">plot</a></span><span class="op">(</span><span class="va">epsilon.C</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span>,<span class="va">epsilon.C</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span>,pch<span class="op">=</span><span class="fl">19</span>,</span>
<span>     xlim<span class="op">=</span><span class="va">x.lim</span>,ylim<span class="op">=</span><span class="va">y.lim</span>,col<span class="op">=</span><span class="st">"#00000044"</span>,</span>
<span>     xlab<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">epsilon</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span>,</span>
<span>     ylab<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">epsilon</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span>,cex.lab<span class="op">=</span><span class="fl">1.6</span>,cex.main<span class="op">=</span><span class="fl">1.6</span>,</span>
<span>     main<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"Distribution of "</span>,<span class="va">epsilon</span><span class="op">[</span><span class="va">t</span><span class="op">]</span>,<span class="st">" = "</span>,<span class="va">B</span>,<span class="va">eta</span><span class="op">[</span><span class="va">t</span><span class="op">]</span>,sep<span class="op">=</span><span class="st">""</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">z</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="fu">g</span><span class="op">(</span><span class="va">eps</span>,<span class="va">Model</span><span class="op">)</span><span class="op">)</span>,<span class="va">nb.points</span>,<span class="va">nb.points</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>new<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">max.z</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">z</span><span class="op">)</span></span>
<span><span class="va">levels</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">.01</span>,<span class="fl">.1</span>,<span class="fl">.3</span>,<span class="fl">.6</span>,<span class="fl">.9</span><span class="op">)</span><span class="op">*</span><span class="va">max.z</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/contour.html">contour</a></span><span class="op">(</span><span class="va">x.points</span>,<span class="va">y.points</span>,<span class="va">z</span>,levels<span class="op">=</span><span class="va">levels</span>,xlim<span class="op">=</span><span class="va">x.lim</span>,ylim<span class="op">=</span><span class="va">y.lim</span>,col<span class="op">=</span><span class="st">"red"</span>,lwd<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/plot.html">plot</a></span><span class="op">(</span><span class="va">epsilon.CQ</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span>,<span class="va">epsilon.CQ</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span>,pch<span class="op">=</span><span class="fl">19</span>,</span>
<span>     xlim<span class="op">=</span><span class="va">x.lim</span>,ylim<span class="op">=</span><span class="va">y.lim</span>,col<span class="op">=</span><span class="st">"#00000044"</span>,</span>
<span>     xlab<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">epsilon</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span>,</span>
<span>     ylab<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">epsilon</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span>,cex.lab<span class="op">=</span><span class="fl">1.6</span>,cex.main<span class="op">=</span><span class="fl">1.6</span>,</span>
<span>     main<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"Distribution of "</span>,<span class="va">epsilon</span><span class="op">[</span><span class="va">t</span><span class="op">]</span>,<span class="st">" = "</span>,<span class="va">BQ</span>,<span class="va">eta</span><span class="op">[</span><span class="va">t</span><span class="op">]</span>,sep<span class="op">=</span><span class="st">""</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">z</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="fu">g</span><span class="op">(</span><span class="va">eps</span>,<span class="va">Model</span><span class="op">)</span><span class="op">)</span>,<span class="va">nb.points</span>,<span class="va">nb.points</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>new<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">max.z</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">z</span><span class="op">)</span></span>
<span><span class="va">levels</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">.01</span>,<span class="fl">.1</span>,<span class="fl">.3</span>,<span class="fl">.6</span>,<span class="fl">.9</span><span class="op">)</span><span class="op">*</span><span class="va">max.z</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/contour.html">contour</a></span><span class="op">(</span><span class="va">x.points</span>,<span class="va">y.points</span>,<span class="va">z</span>,levels<span class="op">=</span><span class="va">levels</span>,xlim<span class="op">=</span><span class="va">x.lim</span>,ylim<span class="op">=</span><span class="va">y.lim</span>,col<span class="op">=</span><span class="st">"red"</span>,lwd<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:preMadeFigureICA"></span>
<img src="images/Figure_A.png" alt="XXXX." width="95%"><p class="caption">
Figure 3.1: XXXX.
</p>
</div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:preMadeFigureICA2"></span>
<img src="AdvECTS_files/figure-html/preMadeFigureICA2-1.png" alt="XXXX." width="95%"><p class="caption">
Figure 3.2: XXXX.
</p>
</div>
<p>External restrictions (economic hypotheses) are needed to identify <span class="math inline">\(B\)</span> (see previous sections). But such restrictions may not be necessary if the structural shocks are not Gaussian.</p>
<p>That is, the identification problem is very specific to normally-distributed <span class="math inline">\(\eta_t\)</span>’s.</p>
<p><a href="https://www.mitpressjournals.org/doi/abs/10.1162/003465303772815727?journalCode=rest">Rigobon (2003)</a>
<a href="https://www.sciencedirect.com/science/article/abs/pii/S0304393204000698">Normandin and Phaneuf (2004)</a>
<a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1538-4616.2008.00151.x">Lanne and Lutkepohl (2008)</a></p>
<p>Example: Bivariate Gaussian + Student (5) case:</p>
<p><span class="math inline">\(\eta_{1,t} \sim \mathcal{N}(0,1)\)</span>, <span class="math inline">\(\eta_{2,t} \sim t(5)\)</span>,
<span class="math inline">\(B = \left[\begin{array}{cc} 1 &amp; 2 \\ -1 &amp; 1 \end{array}\right]\)</span> and
<span class="math inline">\(Q = \left[\begin{array}{cc} \cos(\pi/3) &amp; -\sin(\pi/3) \\ \sin(\pi/3) &amp; \cos(\pi/3) \end{array}\right]\)</span>.</p>
<p>Distribution of <span class="math inline">\(B \eta_t\)</span> versus that of <span class="math inline">\(BQ\eta_t\)</span>?</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">theta.angle</span> <span class="op">&lt;-</span> <span class="va">pi</span><span class="op">/</span><span class="fl">3</span></span>
<span><span class="va">Q</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Trig.html">cos</a></span><span class="op">(</span><span class="va">theta.angle</span><span class="op">)</span>,<span class="fu"><a href="https://rdrr.io/r/base/Trig.html">sin</a></span><span class="op">(</span><span class="va">theta.angle</span><span class="op">)</span>,<span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/Trig.html">sin</a></span><span class="op">(</span><span class="va">theta.angle</span><span class="op">)</span>,<span class="fu"><a href="https://rdrr.io/r/base/Trig.html">cos</a></span><span class="op">(</span><span class="va">theta.angle</span><span class="op">)</span><span class="op">)</span>,<span class="fl">2</span>,<span class="fl">2</span><span class="op">)</span></span>
<span><span class="co">#nb.sim &lt;- 10^4</span></span>
<span><span class="va">nb.sim</span> <span class="op">&lt;-</span> <span class="fl">10</span><span class="op">^</span><span class="fl">2</span></span>
<span><span class="va">distri.1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>type<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"gaussian"</span><span class="op">)</span>,name<span class="op">=</span><span class="st">"Panel (a) Gaussian"</span>,name.4.table<span class="op">=</span><span class="st">"Gaussian"</span><span class="op">)</span></span>
<span><span class="va">distri.2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>type<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"mixt.gaussian"</span><span class="op">)</span>,mu<span class="op">=</span><span class="fl">0</span>,sigma<span class="op">=</span><span class="fl">5</span>,p<span class="op">=</span><span class="fl">.03</span>,name<span class="op">=</span><span class="st">"Panel (b) Mixture of Gaussian"</span>,name.4.table<span class="op">=</span><span class="st">"Mixture of Gaussian"</span><span class="op">)</span></span>
<span><span class="va">distri.3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>type<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"student"</span><span class="op">)</span>,df<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">5</span><span class="op">)</span>,name<span class="op">=</span><span class="st">"Panel (c) Student (df: 5)"</span>,name.4.table<span class="op">=</span><span class="st">"Student (df: 5)"</span><span class="op">)</span></span>
<span><span class="va">distri.4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>type<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"student"</span><span class="op">)</span>,df<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span>,name<span class="op">=</span><span class="st">"Panel (d) Student (df: 10)"</span>,name.4.table<span class="op">=</span><span class="st">"Student (df: 10)"</span><span class="op">)</span></span>
<span><span class="va">x.lim</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">7</span>,<span class="fl">7</span><span class="op">)</span></span>
<span><span class="va">y.lim</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">5</span>,<span class="fl">5</span><span class="op">)</span></span>
<span><span class="va">nb.points</span> <span class="op">&lt;-</span> <span class="fl">100</span></span>
<span><span class="va">x.points</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="va">x.lim</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>,<span class="va">x.lim</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>,length.out<span class="op">=</span><span class="va">nb.points</span><span class="op">)</span></span>
<span><span class="va">y.points</span> <span class="op">&lt;-</span> <span class="va">x.points</span></span>
<span><span class="va">all.x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="va">x.points</span>,<span class="va">nb.points</span>,<span class="va">nb.points</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">all.y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="va">x.points</span>,<span class="va">nb.points</span>,<span class="va">nb.points</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">eps</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">all.x</span>,<span class="va">all.y</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>plt<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">.25</span>,<span class="fl">.9</span>,<span class="fl">.25</span>,<span class="fl">.8</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">eta.1</span> <span class="op">&lt;-</span> <span class="fu">simul.distri</span><span class="op">(</span><span class="va">distri.1</span>,<span class="va">nb.sim</span><span class="op">)</span></span>
<span><span class="va">eta.2</span> <span class="op">&lt;-</span> <span class="fu">simul.distri</span><span class="op">(</span><span class="va">distri.3</span>,<span class="va">nb.sim</span><span class="op">)</span></span>
<span><span class="va">epsilon.C</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">eta.1</span>,<span class="va">eta.2</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">C</span><span class="op">)</span></span>
<span><span class="va">epsilon.CQ</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">eta.1</span>,<span class="va">eta.2</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">C</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">Q</span><span class="op">)</span></span>
<span><span class="va">Model</span><span class="op">$</span><span class="va">distri</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>type<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"gaussian"</span>,<span class="st">"student"</span><span class="op">)</span>,df<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="cn">NaN</span>,<span class="fl">5</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/plot.html">plot</a></span><span class="op">(</span><span class="va">epsilon.C</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span>,<span class="va">epsilon.C</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span>,pch<span class="op">=</span><span class="fl">19</span>,</span>
<span>     xlim<span class="op">=</span><span class="va">x.lim</span>,ylim<span class="op">=</span><span class="va">y.lim</span>,col<span class="op">=</span><span class="st">"#00000044"</span>,</span>
<span>     xlab<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">epsilon</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span>,</span>
<span>     ylab<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">epsilon</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span>,cex.lab<span class="op">=</span><span class="fl">1.6</span>,cex.main<span class="op">=</span><span class="fl">1.6</span>,</span>
<span>     main<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"Distribution of "</span>,<span class="va">epsilon</span><span class="op">[</span><span class="va">t</span><span class="op">]</span>,<span class="st">" = "</span>,<span class="va">B</span>,<span class="va">eta</span><span class="op">[</span><span class="va">t</span><span class="op">]</span>,sep<span class="op">=</span><span class="st">""</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">z</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="fu">g</span><span class="op">(</span><span class="va">eps</span>,<span class="va">Model</span><span class="op">)</span><span class="op">)</span>,<span class="va">nb.points</span>,<span class="va">nb.points</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>new<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">max.z</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">z</span><span class="op">)</span></span>
<span><span class="va">levels</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">.01</span>,<span class="fl">.1</span>,<span class="fl">.3</span>,<span class="fl">.6</span>,<span class="fl">.9</span><span class="op">)</span><span class="op">*</span><span class="va">max.z</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/contour.html">contour</a></span><span class="op">(</span><span class="va">x.points</span>,<span class="va">y.points</span>,<span class="va">z</span>,levels<span class="op">=</span><span class="va">levels</span>,xlim<span class="op">=</span><span class="va">x.lim</span>,ylim<span class="op">=</span><span class="va">y.lim</span>,col<span class="op">=</span><span class="st">"red"</span>,lwd<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/plot.html">plot</a></span><span class="op">(</span><span class="va">epsilon.CQ</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span>,<span class="va">epsilon.CQ</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span>,pch<span class="op">=</span><span class="fl">19</span>,</span>
<span>     xlim<span class="op">=</span><span class="va">x.lim</span>,ylim<span class="op">=</span><span class="va">y.lim</span>,col<span class="op">=</span><span class="st">"#00000044"</span>,</span>
<span>     xlab<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">epsilon</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span>,</span>
<span>     ylab<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">epsilon</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span>,cex.lab<span class="op">=</span><span class="fl">1.6</span>,cex.main<span class="op">=</span><span class="fl">1.6</span>,</span>
<span>     main<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"Distribution of "</span>,<span class="va">epsilon</span><span class="op">[</span><span class="va">t</span><span class="op">]</span>,<span class="st">" = "</span>,<span class="va">BQ</span>,<span class="va">eta</span><span class="op">[</span><span class="va">t</span><span class="op">]</span>,sep<span class="op">=</span><span class="st">""</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">z</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="fu">g</span><span class="op">(</span><span class="va">eps</span>,<span class="va">Model</span><span class="op">)</span><span class="op">)</span>,<span class="va">nb.points</span>,<span class="va">nb.points</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>new<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">max.z</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">z</span><span class="op">)</span></span>
<span><span class="va">levels</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">.01</span>,<span class="fl">.1</span>,<span class="fl">.3</span>,<span class="fl">.6</span>,<span class="fl">.9</span><span class="op">)</span><span class="op">*</span><span class="va">max.z</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/contour.html">contour</a></span><span class="op">(</span><span class="va">x.points</span>,<span class="va">y.points</span>,<span class="va">z</span>,levels<span class="op">=</span><span class="va">levels</span>,xlim<span class="op">=</span><span class="va">x.lim</span>,ylim<span class="op">=</span><span class="va">y.lim</span>,col<span class="op">=</span><span class="st">"red"</span>,lwd<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:preMadeFigureICAGaussianStudent"></span>
<img src="images/Figure_C.png" alt="XXXX." width="95%"><p class="caption">
Figure 3.3: XXXX.
</p>
</div>
<p>NB: In both cases, we have <span class="math inline">\(\mathbb{V}ar(\varepsilon_t)=BB'\)</span>.</p>
<p>Example: Bivariate Student (5) case</p>
<p><span class="math inline">\(\eta_{1,t} \sim t(5)\)</span>, <span class="math inline">\(\eta_{2,t} \sim t(5)\)</span>,
<span class="math inline">\(B = \left[\begin{array}{cc} 1 &amp; 2 \\ -1 &amp; 1 \end{array}\right]\)</span> and
<span class="math inline">\(Q = \left[\begin{array}{cc} \cos(\pi/3) &amp; -\sin(\pi/3) \\ \sin(\pi/3) &amp; \cos(\pi/3) \end{array}\right]\)</span>.</p>
<p><span class="math inline">\(\Rightarrow\)</span> Distribution of <span class="math inline">\(B \eta_t\)</span> versus that of <span class="math inline">\(BQ\eta_t\)</span>?</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">theta.angle</span> <span class="op">&lt;-</span> <span class="va">pi</span><span class="op">/</span><span class="fl">3</span></span>
<span><span class="va">Q</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Trig.html">cos</a></span><span class="op">(</span><span class="va">theta.angle</span><span class="op">)</span>,<span class="fu"><a href="https://rdrr.io/r/base/Trig.html">sin</a></span><span class="op">(</span><span class="va">theta.angle</span><span class="op">)</span>,<span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/Trig.html">sin</a></span><span class="op">(</span><span class="va">theta.angle</span><span class="op">)</span>,<span class="fu"><a href="https://rdrr.io/r/base/Trig.html">cos</a></span><span class="op">(</span><span class="va">theta.angle</span><span class="op">)</span><span class="op">)</span>,<span class="fl">2</span>,<span class="fl">2</span><span class="op">)</span></span>
<span><span class="co">#nb.sim &lt;- 10^4</span></span>
<span><span class="va">nb.sim</span> <span class="op">&lt;-</span> <span class="fl">10</span><span class="op">^</span><span class="fl">2</span></span>
<span><span class="va">distri.1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>type<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"gaussian"</span><span class="op">)</span>,name<span class="op">=</span><span class="st">"Panel (a) Gaussian"</span>,name.4.table<span class="op">=</span><span class="st">"Gaussian"</span><span class="op">)</span></span>
<span><span class="va">distri.2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>type<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"mixt.gaussian"</span><span class="op">)</span>,mu<span class="op">=</span><span class="fl">0</span>,sigma<span class="op">=</span><span class="fl">5</span>,p<span class="op">=</span><span class="fl">.03</span>,name<span class="op">=</span><span class="st">"Panel (b) Mixture of Gaussian"</span>,name.4.table<span class="op">=</span><span class="st">"Mixture of Gaussian"</span><span class="op">)</span></span>
<span><span class="va">distri.3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>type<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"student"</span><span class="op">)</span>,df<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">5</span><span class="op">)</span>,name<span class="op">=</span><span class="st">"Panel (c) Student (df: 5)"</span>,name.4.table<span class="op">=</span><span class="st">"Student (df: 5)"</span><span class="op">)</span></span>
<span><span class="va">distri.4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>type<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"student"</span><span class="op">)</span>,df<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span>,name<span class="op">=</span><span class="st">"Panel (d) Student (df: 10)"</span>,name.4.table<span class="op">=</span><span class="st">"Student (df: 10)"</span><span class="op">)</span></span>
<span><span class="va">x.lim</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">7</span>,<span class="fl">7</span><span class="op">)</span></span>
<span><span class="va">y.lim</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">5</span>,<span class="fl">5</span><span class="op">)</span></span>
<span><span class="va">nb.points</span> <span class="op">&lt;-</span> <span class="fl">100</span></span>
<span><span class="va">x.points</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="va">x.lim</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>,<span class="va">x.lim</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>,length.out<span class="op">=</span><span class="va">nb.points</span><span class="op">)</span></span>
<span><span class="va">y.points</span> <span class="op">&lt;-</span> <span class="va">x.points</span></span>
<span><span class="va">all.x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="va">x.points</span>,<span class="va">nb.points</span>,<span class="va">nb.points</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">all.y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="va">x.points</span>,<span class="va">nb.points</span>,<span class="va">nb.points</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">eps</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">all.x</span>,<span class="va">all.y</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>plt<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">.25</span>,<span class="fl">.9</span>,<span class="fl">.25</span>,<span class="fl">.8</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">eta.1</span> <span class="op">&lt;-</span> <span class="fu">simul.distri</span><span class="op">(</span><span class="va">distri.3</span>,<span class="va">nb.sim</span><span class="op">)</span></span>
<span><span class="va">eta.2</span> <span class="op">&lt;-</span> <span class="fu">simul.distri</span><span class="op">(</span><span class="va">distri.3</span>,<span class="va">nb.sim</span><span class="op">)</span></span>
<span><span class="va">epsilon.C</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">eta.1</span>,<span class="va">eta.2</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">C</span><span class="op">)</span></span>
<span><span class="va">epsilon.CQ</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">eta.1</span>,<span class="va">eta.2</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">C</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">Q</span><span class="op">)</span></span>
<span><span class="va">Model</span><span class="op">$</span><span class="va">distri</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>type<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"student"</span>,<span class="st">"student"</span><span class="op">)</span>,df<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">5</span>,<span class="fl">5</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/plot.html">plot</a></span><span class="op">(</span><span class="va">epsilon.C</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span>,<span class="va">epsilon.C</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span>,pch<span class="op">=</span><span class="fl">19</span>,</span>
<span>     xlim<span class="op">=</span><span class="va">x.lim</span>,ylim<span class="op">=</span><span class="va">y.lim</span>,col<span class="op">=</span><span class="st">"#00000044"</span>,</span>
<span>     xlab<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">epsilon</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span>,</span>
<span>     ylab<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">epsilon</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span>,cex.lab<span class="op">=</span><span class="fl">1.6</span>,cex.main<span class="op">=</span><span class="fl">1.6</span>,</span>
<span>     main<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"Distribution of "</span>,<span class="va">epsilon</span><span class="op">[</span><span class="va">t</span><span class="op">]</span>,<span class="st">" = "</span>,<span class="va">B</span>,<span class="va">eta</span><span class="op">[</span><span class="va">t</span><span class="op">]</span>,sep<span class="op">=</span><span class="st">""</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">z</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="fu">g</span><span class="op">(</span><span class="va">eps</span>,<span class="va">Model</span><span class="op">)</span><span class="op">)</span>,<span class="va">nb.points</span>,<span class="va">nb.points</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>new<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">max.z</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">z</span><span class="op">)</span></span>
<span><span class="va">levels</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">.01</span>,<span class="fl">.1</span>,<span class="fl">.3</span>,<span class="fl">.6</span>,<span class="fl">.9</span><span class="op">)</span><span class="op">*</span><span class="va">max.z</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/contour.html">contour</a></span><span class="op">(</span><span class="va">x.points</span>,<span class="va">y.points</span>,<span class="va">z</span>,levels<span class="op">=</span><span class="va">levels</span>,xlim<span class="op">=</span><span class="va">x.lim</span>,ylim<span class="op">=</span><span class="va">y.lim</span>,col<span class="op">=</span><span class="st">"red"</span>,lwd<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/plot.html">plot</a></span><span class="op">(</span><span class="va">epsilon.CQ</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span>,<span class="va">epsilon.CQ</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span>,pch<span class="op">=</span><span class="fl">19</span>,</span>
<span>     xlim<span class="op">=</span><span class="va">x.lim</span>,ylim<span class="op">=</span><span class="va">y.lim</span>,col<span class="op">=</span><span class="st">"#00000044"</span>,</span>
<span>     xlab<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">epsilon</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span>,</span>
<span>     ylab<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">epsilon</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span>,cex.lab<span class="op">=</span><span class="fl">1.6</span>,cex.main<span class="op">=</span><span class="fl">1.6</span>,</span>
<span>     main<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"Distribution of "</span>,<span class="va">epsilon</span><span class="op">[</span><span class="va">t</span><span class="op">]</span>,<span class="st">" = "</span>,<span class="va">BQ</span>,<span class="va">eta</span><span class="op">[</span><span class="va">t</span><span class="op">]</span>,sep<span class="op">=</span><span class="st">""</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">z</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="fu">g</span><span class="op">(</span><span class="va">eps</span>,<span class="va">Model</span><span class="op">)</span><span class="op">)</span>,<span class="va">nb.points</span>,<span class="va">nb.points</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>new<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">max.z</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">z</span><span class="op">)</span></span>
<span><span class="va">levels</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">.01</span>,<span class="fl">.1</span>,<span class="fl">.3</span>,<span class="fl">.6</span>,<span class="fl">.9</span><span class="op">)</span><span class="op">*</span><span class="va">max.z</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/contour.html">contour</a></span><span class="op">(</span><span class="va">x.points</span>,<span class="va">y.points</span>,<span class="va">z</span>,levels<span class="op">=</span><span class="va">levels</span>,xlim<span class="op">=</span><span class="va">x.lim</span>,ylim<span class="op">=</span><span class="va">y.lim</span>,col<span class="op">=</span><span class="st">"red"</span>,lwd<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<p>NB: In both cases, we have <span class="math inline">\(\mathbb{V}ar(\varepsilon_t)=BB'\)</span>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:preMadeFigureICAStudentStudent"></span>
<img src="images/Figure_D.png" alt="XXXX." width="95%"><p class="caption">
Figure 3.4: XXXX.
</p>
</div>
<p><strong>Relationship with Signal Processing Literature</strong></p>
<p>Task to be performed:</p>
<p>you observe <span class="math inline">\(n\)</span> linear combinations of <span class="math inline">\(n\)</span> <strong>independent signals</strong>; you want to estimate these linear combinations (<span class="math inline">\(\Leftrightarrow\)</span> recover independent signals).</p>
<p>Without loss of generality, we can assume that <span class="math inline">\(BB' = Id\)</span> (i.e. <span class="math inline">\(B\)</span> is orthogonal)</p>
<p>(If not the case, i.e. if <span class="math inline">\(\mathbb{V}ar(\varepsilon_t)=\Omega \ne Id\)</span>, pre-multiply the data by <span class="math inline">\(\Omega^{-1/2}\)</span>).</p>
<p><strong>Classical signal processing problem: Independent Component Analysis (ICA)</strong></p>
<p>Find <span class="math inline">\(B\)</span> such that <span class="math inline">\(\varepsilon_t = B \eta_t\)</span> (or $_t= B’ _t $) given that
i. you observe the <span class="math inline">\(\varepsilon_t\)</span>’s,
ii. The components of <span class="math inline">\(\eta_t\)</span> are independent,
iii. <span class="math inline">\(BB'=Id\)</span> (<span class="math inline">\(B\)</span> is orthogonal).</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ThreePlots"></span>
<img src="images/Figure_E.png" alt="XXXX." width="95%"><p class="caption">
Figure 3.5: XXXX.
</p>
</div>
<p>In all cases, we have <span class="math inline">\(\mathbb{V}ar(\varepsilon_t)=\mathbb{V}ar(\eta_t)=Id\)</span>. Assume you observe the distribution of <span class="math inline">\(\varepsilon_t\)</span> (in ). How to rotate <span class="math inline">\(\varepsilon_t\)</span> to get obtain <em>independent signals</em> (<span class="math inline">\(\eta_t = B'\varepsilon_t\)</span>)?</p>
<p>NB: <span class="math inline">\(\varepsilon_{1,t}\)</span> and <span class="math inline">\(\varepsilon_{2,t}\)</span> are not independent.</p>
<p>For instance: We have <span class="math inline">\(\mathbb{E}(\varepsilon_{2,t}|\varepsilon_{1,t}&gt;4)&lt;0\)</span> (whereas <span class="math inline">\(\mathbb{E}(\eta_{2,t}|\eta_{1,t}&gt;4)=0\)</span>).</p>
<div class="hypothesis">
<p><span id="hyp:NonGauss" class="hypothesis"><strong>Hypothesis 3.1  </strong></span>We have:</p>
<ol style="list-style-type: lower-roman">
<li>The shocks <span class="math inline">\(\eta_t\)</span> are i.i.d. with <span class="math inline">\(\mathbb{E}(\eta_t) = 0\)</span> and <span class="math inline">\(\mathbb{V}ar(\eta_t) = Id.\)</span>
</li>
<li>The components <span class="math inline">\(\eta_{1,t}, \ldots, \eta_{n,t}\)</span> are mutually independent.
iii We have
<span class="math display">\[
\boxed{Y_t = B_0 \eta_t,}
\]</span>
with <span class="math inline">\(\mathbb{E}(Y_t) = Id\)</span> (i.e. <span class="math inline">\(B_0\)</span> is orthogonal).</li>
</ol>
</div>
<div class="theorem">
<p><span id="thm:EK2004" class="theorem"><strong>Theorem 3.1  (Eriksson, Koivunen (2004)) </strong></span>If Hypothesis <a href="vector-auto-regressive-var-models.html#hyp:NonGauss">3.1</a> is satisfied and if at most one of the components of <span class="math inline">\(\eta\)</span> is Gaussian, then matrix <span class="math inline">\(B_0\)</span> is identifiable up to the post multiplication by <span class="math inline">\(DP\)</span>, where <span class="math inline">\(P\)</span> is a permutation matrix and <span class="math inline">\(D\)</span> is a diagonal matrix whose diagonal entries are 1 or <span class="math inline">\(-1\)</span>.}</p>
</div>
<p><strong>The PML approach</strong></p>
<p>We introduce a set of p.d.f. <span class="math inline">\(g_i (\eta_i), i=1,\ldots,n,\)</span> and consider the <strong>pseudo log-likelihood function</strong>:
<span class="math display" id="eq:pseudolog">\[\begin{equation}
\log \mathcal{L}_T (B) = \sum^T_{t=1} \sum^n_{i=1} \log g_i (b'_i Y_t),\tag{3.26}
\end{equation}\]</span>
where <span class="math inline">\(b_i\)</span> is the <span class="math inline">\(i^{th}\)</span> column of matrix <span class="math inline">\(B\)</span> (or <span class="math inline">\(b'_i\)</span> is the <span class="math inline">\(i^{th}\)</span> row of <span class="math inline">\(B^{-1}\)</span> since <span class="math inline">\(B^{-1}=B'\)</span>).</p>
<p>The log-likelihood function <a href="vector-auto-regressive-var-models.html#eq:pseudolog">(3.26)</a> is computed as if the errors <span class="math inline">\(\eta_{i,t}\)</span> had the p.d.f. <span class="math inline">\(g_i (\eta_i)\)</span>.</p>
A <strong>pseudo maximum likelihood (PML) estimator</strong> of matrix <span class="math inline">\(B\)</span> maximizes the pseudo log-likelihood function:
<span class="math display" id="eq:optimprob">\[\begin{equation}
\widehat{B_T} = \arg \max_B \sum^T_{t=1} \sum^n_{i=1} \log g_i (b'_i Y_t),\tag{3.27}
\end{equation}\]</span>
<p>The restrictions <span class="math inline">\(B'B = Id\)</span> can be eliminated by parameterizing <span class="math inline">\(B\)</span>.</p>
<p><strong>Cayley’s representation:</strong></p>
<p>Any orthogonal matrix with no eigenvalue equal to <span class="math inline">\(-1\)</span> can be written as
<span class="math display">\[\begin{equation}
  B(A) = (Id+A) (Id-A)^{-1},
\end{equation}\]</span>
where <span class="math inline">\(A\)</span> is a skew symmetric (or antisymmetric) matrix, such that <span class="math inline">\(A'=-A\)</span>.</p>
<p>There is a one-to-one relationship with <span class="math inline">\(A\)</span>, since:
<span class="math display">\[\begin{equation}
  A = (B(A)+Id)^{-1} (B(A)-Id).
\end{equation}\]</span></p>
<p>PML estimator of matrix <span class="math inline">\(B\)</span>: <span class="math inline">\(\widehat{B_T} = B(\hat{A}_T),\)</span> where:
<span class="math display" id="eq:optimprob2">\[\begin{equation}
  \hat{A}_T = \arg \max_{a_{i,j}, i&gt;j} \sum^T_{t=1} \sum^n_{i=1} \log g_i [b_i (A)' Y_t].\tag{3.28}
\end{equation}\]</span></p>
<p><strong>Asymptotic properties of the PML approach</strong></p>
<div class="hypothesis">
<p><span id="hyp:NonGauss2" class="hypothesis"><strong>Hypothesis 3.2  </strong></span>We have:</p>
<ol style="list-style-type: lower-roman">
<li>The functions <span class="math inline">\(\log g_i\)</span>, <span class="math inline">\(i=1,\ldots,n\)</span>, are twice continuously differentiable.</li>
<li>
<span class="math inline">\(sup_{B: B'B = Id} \left|\sum^n_{i=1} \log g_i (b'_i y)\right| \leq h(y),\)</span> where <span class="math inline">\(\mathbb{E}_0 [h (Y)] &lt; \infty\)</span>.</li>
</ol>
</div>
<div class="hypothesis">
<p><span id="hyp:NonGauss3" class="hypothesis"><strong>Hypothesis 3.3  (Identification from the asymptotic FOC) </strong></span>The only solutions of the system of equations:
<span class="math display">\[
\left\{
\begin{array}{l} \mathbb{E}_0 \left[b'_j Y_t \frac{d\log g_i}{d\eta} (b'_i Y_t)\right] = 0,\;  i \neq j, \\
B' B = Id,
\end{array}
\right.
\]</span>
are the elements of <span class="math inline">\(\mathcal{P}_0 \equiv \mathcal{P}(B_0)\)</span>, which is the set of matrices obtained by permutation and sign change of the columns of <span class="math inline">\(B_0\)</span>.</p>
</div>
<div class="hypothesis">
<p><span id="hyp:NonGauss4" class="hypothesis"><strong>Hypothesis 3.4  (Local concavity) </strong></span>The asymptotic objective function is locally concave in a neighbourhood of a matrix <span class="math inline">\(B\)</span> of <span class="math inline">\(\mathcal{P}(B_0)\)</span>, which is the case if and only if
<span class="math display">\[
\mathbb{E}_0 \left[ \frac{d^2 \log g_i (\eta_{i,t})}{d\eta^2} + \frac{d^2 \log g_j (\eta_{j,t})}{d\eta^2} - \eta_{j,t} \frac{d\log g_j (\eta_{j,t})}{d\eta}- \eta_{i,t} \frac{d\log g_i (\eta_{i,t})}{d\eta} \right] &lt; 0, \forall i&lt;j,
\]</span>
where <span class="math inline">\(\eta_{i,t}\)</span> is the <span class="math inline">\(i^{th}\)</span> component of the <span class="math inline">\(\eta_t\)</span> associated with this particular element <span class="math inline">\(B\)</span> of <span class="math inline">\(\mathcal{P}(B_0)\)</span>.</p>
</div>
<p>This condition is in particular satisfied under the following set of conditions: derived in Hyvarinen (1997) XXX
<span class="math display" id="eq:HKO">\[\begin{equation}
\mathbb{E}_0 \left[\frac{d^2 \log g_i(\eta_{i,t})}{d\eta^2} - \eta_{i,t} \frac{d\log g_i(\eta_{i,t})}{d\eta}\right] &lt;0,\quad  i=1,\ldots, n. \tag{3.29}
\end{equation}\]</span></p>
<p>Hyperbolic secant and the subgaussian distributions (see table on next slide): either one, or the other satisfy the inequality <a href="vector-auto-regressive-var-models.html#eq:HKO">(3.29)</a> [Hyvarinen, Karhunen, Oja, 2001 XXXX].</p>
<p>XXXXXXXXXXXXXXX
<!-- \begin{table} -->
<!-- \begin{center} -->
<!-- \caption{Zero-mean unit-variance distributions}\label{tab:distri}%\vspace{-0.2in} -->
<!-- \begin{tabular}{lccccc} -->
<!-- \hline -->
<!-- & $\log g(x)$ & $\dfrac{d \log g(x)}{d x}$ & $\dfrac{d^2 \log g(x)}{d x^2}$ -->
<!-- \\ -->
<!-- %& (a) & (b) & (c) \\ -->
<!-- \hline -->
<!-- \\ -->
<!-- Gaussian & $cst - x^2/2$& $-x$ &$-1$\\%&$0$\\ -->
<!-- \\ -->
<!-- Student $t(\nu>4)$ & $-\dfrac{1-\nu}{2}\log\left( 1 +\dfrac{x^2}{\nu-2} \right)$&$-\dfrac{x(1+\nu)}{\nu - 2 + x^2}$\\ %$- (1+\nu)  \dfrac{\nu - 2 - x^2}{\nu - 2 + x^2}$&$\dfrac{6}{\nu-4}$ if $\nu>4$\\ -->
<!-- Hyperbolic secant &$cst - \log\left( \cosh\left\{\dfrac{\pi}{2}x\right\} \right)$&$-\dfrac{\pi}{2}\tanh\left(\dfrac{\pi}{2}x\right)$&$ -->
<!-- -\left(\dfrac{\pi}{2}\dfrac{1}{\cosh\left(\dfrac{\pi}{2}x\right)}\right)^2 -->
<!-- $\\%$2$\\ -->
<!-- Subgaussian &$cst + \pi x^2 + \log \left(\cosh\left\{\dfrac{\pi}{2}x\right\}\right)$& -->
<!-- $2\pi x+\dfrac{\pi}{2}\tanh\left(x \dfrac{\pi}{2}\right)$& -->
<!-- $2\pi + \left(\dfrac{\pi}{2}\dfrac{1}{\cosh\left(\dfrac{\pi}{2}x\right)}\right)^2$\\%$\dfrac{-2\pi^2 + 8\pi - 8}{\pi^2}<0$\\ -->
<!-- \hline -->
<!-- \end{tabular} -->
<!-- \end{center} -->
<!-- \end{table} --></p>
<p>Note: Except for the Gaussian distribution, we have <span class="math inline">\(E[d^2 \log g(X)/d \varepsilon^2 - X d\log g(X)/d \varepsilon] &lt; 0\)</span> (i.e. Assumption,4 is satisfied) when these pseudo distributions coincide to the distribution of <span class="math inline">\(X\)</span>. The subGaussian distribution is a mixture of Gaussian distributions: <span class="math inline">\(X\)</span> is drawn from this distribution if it is equal to <span class="math inline">\(BY - (1-B)Y\)</span>, where <span class="math inline">\(B\)</span> is drawn from a Bernoulli distribution of parameter <span class="math inline">\(1/2\)</span> and <span class="math inline">\(Y \sim \mathcal{N}(\sqrt{(\pi-2)/\pi},2/\pi)\)</span>.</p>
<p>Under Hypotheses <a href="#NonGauss"><strong>??</strong></a>-<a href="#NonGauss4"><strong>??</strong></a>, the PML estimator <span class="math inline">\(\widehat{B_T}\)</span> of <span class="math inline">\(B_0\)</span> is consistent (in <span class="math inline">\(\mathcal{P}_0\)</span>) and asymptotically normal, with speed of convergence <span class="math inline">\(1/\sqrt{T}\)</span>.</p>
<p>The asymptotic variance-covariance matrix of <span class="math inline">\(vec \sqrt{T} (\widehat{B_T} - B_0)\)</span> is <span class="math inline">\(A^{-1} \left[\begin{array}{cc} \Gamma &amp; 0 \\ 0 &amp; 0 \end{array} \right] (A')^{-1}\)</span>, where matrices <span class="math inline">\(A\)</span> and <span class="math inline">\(\Gamma\)</span> are detailed in Gouri'eroux, Monfort and Renne (2017) XXX.</p>
<p>The potential misspecification of pseudo-distributions <span class="math inline">\(g_i\)</span> has no effect on the consistency of these specific PML estimators.</p>
<p>The previous proposition can be exploited to build a test whose null hypothesis is:</p>
<p><em><span class="math inline">\(H_0\)</span>: <span class="math inline">\(B\)</span> belongs to <span class="math inline">\(\mathcal{P}_0\)</span>, where <span class="math inline">\(\mathcal{P}_0\)</span> is the set of orthogonal matrices obtained by permuting and changing the signs of the columns of a given orthogonal matrix <span class="math inline">\(B_0\)</span>.</em></p>
<p><strong>Application: Structural VAR model</strong></p>
<p>Three dependent variables: inflation (<span class="math inline">\(\pi_t\)</span>), economic activity (<span class="math inline">\(z_t\)</span>) and the nominal short-term interest rate (<span class="math inline">\(r_t\)</span>).</p>
<p>Structural shocks are posited monetary-policy, demand and supply shocks.</p>
<p><span class="math inline">\(W_t\)</span>: set of information made of the past values of <span class="math inline">\(y_t= [\pi_t,z_t,r_t]\)</span>, that is <span class="math inline">\(\{y_{t-1},y_{t-2},\dots\}\)</span>, and of exogenous variables <span class="math inline">\(\{x_{t},x_{t-1},\dots\}\)</span>.</p>
<p>The reduced-form VAR model reads:
<span class="math display">\[
y_t  = \underbrace{\mu + \sum_{i=1}^{p} \Phi_i y_{t-i} + \Theta x_t}_{a(W_t;\theta)} + u_t
\]</span>
where the <span class="math inline">\(u_t\)</span>’s are assumed to be serially independent, with zero mean and variance-covariance matrix <span class="math inline">\(\Sigma\)</span>.</p>
<p>U.S. data. 1959:IV to 2015:I at the quarterly frequency (<span class="math inline">\(T=224\)</span>). Source: Federal Reserve Economic Database (FRED).</p>
<p>Two different measures of economic activity are considered: the output gap and the unemployment gap. Change in the log of oil prices added as an exogenous variable (<span class="math inline">\(x_t\)</span>).</p>
<p><span class="math inline">\(\mu\)</span>, <span class="math inline">\(\Phi_i\)</span>, <span class="math inline">\(\Theta\)</span> and <span class="math inline">\(\Sigma\)</span> are consistently estimated by OLS.</p>
<p>Jarque-Bera tests support the hypothesis of non-normality for all residuals.</p>
<p>We want to estimate the orthogonal matrix <span class="math inline">\(B\)</span> such that <span class="math inline">\(u_t=SB \eta_t\)</span>, where</p>
<ul>
<li>
<span class="math inline">\(S\)</span> results from the Cholesky decomposition of <span class="math inline">\(\Sigma\)</span> and</li>
<li>the components of <span class="math inline">\(\eta_t\)</span> are independent, zero-mean with unit variance.</li>
</ul>
<p>The PML approach is applied on standardized VAR residuals given by:
<span class="math display">\[
\hat{S}_T^{-1}\underbrace{[y_t - a(W_t;\hat\theta_T)]}_{\mbox{VAR residuals}}.
\]</span>
By construction of <span class="math inline">\(\hat{S}_T^{-1}\)</span>, it comes that the covariance matrix of these residuals is <span class="math inline">\(Id\)</span>.</p>
<p>Pseudo density functions: Distinct and asymmetric mixtures of Gaussian distributions.</p>
<p>Once <span class="math inline">\(B\)</span> has been estimated, it remains to associate the structural shocks (monetary-policy, supply or demand) with the different components of <span class="math inline">\(\eta_{t}\)</span>.</p>
<ul>
<li>Contractionary <strong>monetary-policy shocks</strong>: negative impact on real activity and on inflation.</li>
<li>
<strong>Supply shock</strong>: influences of opposite signs on economic activity and on inflation.</li>
<li>
<strong>Demand shock</strong>: influences of same signs on economic activity and on inflation.</li>
</ul>
<p>Important: This method does not rely on the assumption that specific impacts (e.g. contemporaneous or long-run) are null.</p>
<!-- \begin{frame}{} -->
<!-- \begin{footnotesize} -->
<!-- \begin{figure} -->
<!-- \includegraphics[width=.8\linewidth]{figures/ICA/figSVAR1.pdf} -->
<!-- \end{figure} -->
<!-- \end{footnotesize} -->
<!-- \end{frame} -->
<!-- \begin{frame}{} -->
<!-- \begin{footnotesize} -->
<!-- \begin{figure} -->
<!-- \includegraphics[width=.8\linewidth]{figures/ICA/figSVAR2.pdf} -->
<!-- \end{figure} -->
<!-- \end{footnotesize} -->
<!-- \end{frame} -->
<p>Comparison of the previous IRFs with those stemming from “recursive” identification approaches based on specific short-run restrictions (SRRs).</p>
<p>SRRs approach (Section,<span class="math inline">\(\ref{Section:Standard}\)</span>) are based on the assumptions that</p>
<ol style="list-style-type: lower-alpha">
<li>
<span class="math inline">\(Cov(\eta_t)=Id\)</span>,</li>
<li>the <span class="math inline">\(k^{th}\)</span> structural shock does not contemporaneously affects the first <span class="math inline">\(k-1\)</span> endogenous variables and</li>
<li>the contemporaneous effect of the <span class="math inline">\(k^{th}\)</span> structural shock on the <span class="math inline">\(k^{th}\)</span> dependent variable is positive.</li>
</ol>
<p>Under these assumptions, the structural shocks are given by <span class="math inline">\(S^{-1}u_t\)</span>.</p>
<p>SRR approaches assume –potentially wrongly– that the contemporaneous impacts of some structural shocks on given variables are null.</p>
<p>The null hypothesis of these tests is <span class="math inline">\(H_0= (P \in \mathcal{P}(Id))\)</span>.
The null hypothesis <span class="math inline">\(H_0\)</span> stating that the true value of <span class="math inline">\(B\)</span> belongs to <span class="math inline">\(\mathcal{P}_0\)</span> is not standard since it is a finite union of simple hypotheses <span class="math inline">\(H_{0,j} = (B = B_{j,0})\)</span>.</p>
<p><strong>First testing procedure:</strong></p>
<ul>
<li>Define the Wald statistics <span class="math inline">\(\hat\xi_{j,T}\)</span>, <span class="math inline">\(j \in J\)</span>:
<span class="math display">\[\begin{equation}
\hat\xi_{j,T} = T [vec\hat{B}_T-vec B_{j,0}]'\hat{A}_T'
\left[
\begin{array}{cc}
\hat{\Omega}^{-1}_T &amp; 0\\
0&amp;0
\end{array}
\right]\hat{A}_T
[vec\hat{B}_T-vec B_{j,0}],
\end{equation}\]</span>
<span class="math inline">\(\hat{A}_T\)</span> and <span class="math inline">\(\hat{\Omega}_T\)</span> being consistent estimators of the matrices <span class="math inline">\(A\)</span> and <span class="math inline">\(\Omega\)</span>.</li>
</ul>
<p>Since the dimension of the asymptotic distribution of <span class="math inline">\(\sqrt{T}[vec\hat{B}_T-vec B_{j,0}]\)</span> is <span class="math inline">\(\frac{1}{2}n(n-1)\)</span>, the asymptotic distribution of <span class="math inline">\(\hat\xi_{j,T}\)</span> under <span class="math inline">\(H_{0,j}\)</span> is <span class="math inline">\(\chi^2\left(\frac{1}{2}n(n-1)\right)\)</span>.</p>
<ul>
<li>Define <span class="math inline">\(\hat\xi_T = \underset{j \in J}{\min} \hat\xi_{j,T}\)</span> as the test statistic for <span class="math inline">\(H_0\)</span>.</li>
<li>Under <span class="math inline">\(H_0\)</span>, <span class="math inline">\(\hat{B}_T\)</span> converges to <span class="math inline">\(B_{j_0,0}\)</span> (say).</li>
<li>By the asymptotic properties of the Wald statistics for simple hypotheses:
<span class="math display">\[\begin{equation}
\hat\xi_{j_0,T} \overset{D}{\rightarrow} \chi^2\left(\frac{n(n-1)}{2}\right) \quad \mbox{and}\quad  \hat\xi_{j,T} \rightarrow \infty, \mbox{ if } j \ne j_0.
\end{equation}\]</span>
</li>
</ul>
<p>Under the null hypothesis, <span class="math inline">\(\hat\xi_T = \underset{j}{\min}\)</span> <span class="math inline">\(\hat\xi_{j,T}\)</span> is asymptotically equal to <span class="math inline">\(\hat\xi_{j_0,T}\)</span> and its asymptotic distribution, <span class="math inline">\(\chi^2\left(\frac{1}{2}n(n-1)\right)\)</span>, does not depend on <span class="math inline">\(j_0\)</span>. Therefore <span class="math inline">\(\hat\xi_T\)</span> is asymptotically a pivotal statistic for the null hypothesis <span class="math inline">\(H_0\)</span> and the test of critical region <span class="math inline">\(\hat\xi_T \ge \chi^2_{1-\alpha}\left(\frac{1}{2}n(n-1)\right)\)</span> is of asymptotic level <span class="math inline">\(\alpha\)</span> and is consistent.</p>
<p><strong>Second testing procedure</strong></p>
<p>Define <span class="math inline">\(B_{0,T} = \underset{B \in \mathcal{P}_0}{\mbox{Argmin }} d(\hat{B}_T,B)\)</span> where <span class="math inline">\(d\)</span> is any distance, for instance the Euclidean one.</p>
<p>Under the null hypothesis <span class="math inline">\(H_0\)</span>: <span class="math inline">\((B \in \mathcal{P}_0)\)</span>, <span class="math inline">\(\hat{B}_T\)</span> converges almost surely to an element of <span class="math inline">\(\mathcal{P}_0\)</span> denoted by <span class="math inline">\(B_{j_0,0}\)</span> and it is also the case for <span class="math inline">\(B_{0,T}\)</span> since, asymptotically, we have <span class="math inline">\(B_{0,T}=B_{j_0,0}\)</span>.</p>
<p>Moreover:
<span class="math display">\[
\sqrt{T}(\hat{B}_T - B_{0,T})=\sqrt{T}(\hat{B}_T - B_{j_0,0}) + \sqrt{T}(B_{j_0,0} - B_{0,T}),
\]</span>
and, since <span class="math inline">\(B_{0,T}\)</span> is almost surely asymptotically equal to <span class="math inline">\(B_{j_0,0}\)</span>, the asymptotic distribution of <span class="math inline">\(\sqrt{T}(\hat{B}_T - B_{0,T})\)</span> under <span class="math inline">\(H_0\)</span> is the same as that of <span class="math inline">\(\sqrt{T}(\hat{B}_T - B_{j_0,0})\)</span>.</p>
<p>This implies that
<span class="math display">\[
\tilde\xi_{T} = T [vec\hat{B}_T-vec B_{0,T}]'\hat{A}_T'
\left[
\begin{array}{cc}
\hat{\Omega}^{-1}_T &amp; 0\\
0&amp;0
\end{array}
\right]\hat{A}_T
[vec\hat{B}_T-vec B_{0,T}]
\]</span>
is asymptotically distributed as <span class="math inline">\(\chi^2\left(\frac{1}{2}n(n-1)\right)\)</span> under <span class="math inline">\(H_0\)</span>.</p>
<p>An advantage of this second method is that it necessitates the computation of only one Wald test statistic.</p>
<p>We consider two specific SRR schemes:
* In both of them, it is assumed that the monetary-policy shock has no contemporaneous impact on <span class="math inline">\(\pi_t\)</span> and <span class="math inline">\(y_t\)</span>.
* In SRR Scheme 1: Inflation is contemporaneously impacted by one structural shock only.
* In SRR Scheme 2: Economic activity is contemporaneously impacted by one structural shock only.
\end{itemize}
* When economic activity is measured by means of the output gap, both SRRs are rejected at the 5% level.</p>
<p><strong>SVARMA</strong></p>
<p>In what precedes, we have seen that, if <span class="math inline">\(y_t\)</span> follows a VAR
<span class="math display">\[\begin{eqnarray*}
y_t &amp;=&amp; \Phi_1 y_{t-1} + \dots + \Phi_p y_{t-p}  +   B \eta_{t},
\end{eqnarray*}\]</span>
and if the components of <span class="math inline">\(\eta_t\)</span> are non-Gaussian i.i.d. shocks,</p>
<p>then model parameters are identifiable (and can be consistently estimated).</p>
<p>What about Structural VARMAs?
<span class="math display">\[\begin{eqnarray*}
&amp;&amp;y_t = \underbrace{\Phi_1 y_{t-1} + \dots +\Phi_p y_{t-p}}_{{\color{blue}\mbox{AR component}}} + \underbrace{B \eta_t+ \Theta_1 B \eta_{t-1}+ \dots+ \Theta_q B \eta_{t-q}}_{{\color{red}\mbox{MA component}}}\\
&amp;\Leftrightarrow&amp;\underbrace{(I - \Phi_1 L - \dots - \Phi_p L^p)}_{= \Phi(L)}y_t =  \underbrace{ {\color{red} (I - \Theta_1 L - \ldots - \Theta_q L^q)}}_{={\color{red}\Theta(L)}} B \eta_{t}
\end{eqnarray*}\]</span></p>
<p>Still may have identification problems with <span class="math inline">\(B\)</span> (solved if <span class="math inline">\(\eta_t\)</span> non-Gaussian). Additional identification issue (w.r.t. SVAR case):</p>
<p>There are <span class="math inline">\(2^n\)</span> different <span class="math inline">\(\Theta(L)\)</span> yielding the exact same second-order properties for <span class="math inline">\(y_t\)</span>.
%The SVARMA process may have a {non-invertible MA matrix polynomial <span class="math inline">\(\Theta(L)\)</span>} but, still, has the same second-order properties as a VARMA process in which the MA matrix polynomial is invertible (called fundamental representation).</p>
<p><strong>Univariate MA(1) Case</strong></p>
<p>The two MA(1) processes:
<span class="math display">\[\begin{equation}
y_t = \varepsilon_t + \theta \varepsilon_{t-1}
\end{equation}\]</span>
and
<span class="math display">\[\begin{equation}
y^*_t = \theta \varepsilon_t + \varepsilon_{t-1},
\end{equation}\]</span>
have the same second-order properties (same variances, same auto-correlations).</p>
<p>Hence, if $_t $ is Gaussian, <span class="math inline">\(y_t\)</span> and <span class="math inline">\(y^*_t\)</span> are observationally equivalent. However, different IRFs: <span class="math inline">\((1,\theta,0,\dots)\)</span> versus <span class="math inline">\((\theta,1,0,\dots)\)</span>. One of the 2 processes is said to be <strong>fundamental</strong>, or <strong>invertible</strong> (if <span class="math inline">\(|\theta|&lt;1\)</span>):</p>
<p>It is the one that is such that <span class="math inline">\(\varepsilon_t\)</span> can be deduced from past values of <span class="math inline">\(y_t\)</span> only.</p>
<p>The other one is <strong>nonfundamental</strong> (<span class="math inline">\(\varepsilon_t\)</span> cannot be deduced from past values of <span class="math inline">\(y_t\)</span>).</p>
<p>An MA process is said to be <strong>invertible</strong>, or <strong>fundamental</strong>, if we can obtain <span class="math inline">\(\eta_t\)</span> as a function of past values of <span class="math inline">\(y_t\)</span>.</p>
<p>In the context of a univariate MA(1),
<span class="math display">\[
y_t = \eta_t + \theta \eta_{t-1} = (1 + \theta L) \eta_t, \quad \eta_t \sim \,i.i.d,
\]</span>
this is the case iff <span class="math inline">\(|\theta|&lt;1\)</span>. Indeed:
<span class="math display">\[
\begin{array}{lllll}
\mbox{When $|\theta|&lt;1$, } \qquad \eta_t &amp;=&amp; \sum^\infty_{h=0} \theta^h y_{t-h} &amp; \mbox{(invertible case)}\\
\\
\mbox{When $|\theta|&gt;1$, } \qquad \eta_t &amp;=&amp; - \sum^\infty_{h=0} \dfrac{1}{\theta^{h+1}} y_{t+h+1} &amp; \mbox{(non-invertible case)}.
\end{array}
\]</span>
Hence, when <span class="math inline">\(|\theta|&lt;1\)</span> (respect. <span class="math inline">\(|\theta|&gt;1\)</span>), <span class="math inline">\(\eta_t\)</span> is a function of past (respect. future) values of <span class="math inline">\(y_t\)</span>.</p>
<p>Context of a VMA(1): <span class="math inline">\(y_t = \eta_t + \Theta \eta_{t-1}\)</span>. Process <span class="math inline">\(y_t\)</span> is invertible if the eigenvalues of <span class="math inline">\(\Theta\)</span> are strictly within the unit circle.</p>
<p>Consider the following (nonfundamental) VARMA(1,1) models:
<span class="math display">\[
y_t = \left[\begin{array}{cc}
0.6 &amp; 0.4 \\
-0.2 &amp; 0.9
\end{array}\right]
y_{t-1} + B \eta_t - \Theta_1 B \eta_{t-1},
\]</span>
with
<span class="math display">\[
B = \left[\begin{array}{cc}
1.00 &amp; 0.30 \\
0.50 &amp; 1.00
\end{array}\right],\quad \Theta_1 = \left[\begin{array}{cc}
-2.00 &amp; 0.50 \\
-0.20 &amp; -0.70
\end{array}\right].
\]</span></p>
<p>It is possible to compute the three other <span class="math inline">\(\Theta_1\)</span>’s yielding to the same second-order properties (Lippi and Reichlin, 1994). Different IRFs (next slide, Model 2 is the fundamental one).</p>
<p>If the <span class="math inline">\(\eta_t\)</span>’s are Gaussian, the resulting four models observationally equivalent.</p>
<p>Remark: The previous identification problem is still present here. That is: For a given <span class="math inline">\(\Theta_1\)</span>, <span class="math inline">\(B\)</span> can be replaced by <span class="math inline">\(BQ\)</span>, same second-order properties.</p>
<p>Hence, for Gaussian SVARMA models, two identification issues.</p>
<p>Standard estimation toolboxes return fundamental processes. However, in various contexts, no theoretical reasons to rule out <strong>non-fundamentalness</strong> (productivity shocks with lagged impacts, news/noise shocks, non-observability, rational expectations, prediction errors).</p>
<ul>
<li><p><strong>Lagged impact (Lippi and Reichlin, 1993)</strong>
Suppose that the productivity process, denoted by <span class="math inline">\(y_t\)</span>, is given by:
<span class="math display">\[
y_t = \varepsilon_t + \theta \varepsilon_{t-1},
\]</span>
where <span class="math inline">\(\varepsilon_t\)</span> denotes the productivity shock. The impact of the productivity shock may be maximal with a lag, i.e. <span class="math inline">\(\theta &gt; 1\)</span>. The MA(1) process is then non-fundamental.
\end{block}</p></li>
<li><p><strong>Rational expectations</strong>
Simple example of Hansen and Sargent (1991). The economic variable <span class="math inline">\(y_t\)</span> is defined as:
<span class="math display">\[
y_t = E_t (\Sigma^\infty_{h=0} \beta^h w_{t+h}), \; \mbox{with }\; w_t = \varepsilon_t - \theta \varepsilon_{t-1},\; 0 &lt; \beta &lt;1, \; |\theta|&lt;1.
\]</span>
If the information set available to the economic agent at date <span class="math inline">\(t\)</span> is <span class="math inline">\(I_t = (\varepsilon_t, \varepsilon_{t-1}, \ldots)\)</span>:
<span class="math display">\[
y_t  = (1-\beta \theta) \varepsilon_t - \theta \varepsilon_{t-1}.
\]</span>
The abs. value of the root of the moving average polynomial is larger or smaller than 1.</p></li>
<li><p><strong>Advanced indicator (noise / news shocks) and information structure.</strong></p></li>
</ul>
<p>Consider a process <span class="math inline">\((x_t)\)</span> that summarizes ``fundamentals’’ (technology, preferences, endowments, or government policy) s.t.:
<span class="math display">\[\begin{equation}
x_t = a(L)u_{t},
\end{equation}\]</span>
where process <span class="math inline">\((u_t)\)</span> is a strong white noise. On date <span class="math inline">\(t\)</span>, the consumer observes <span class="math inline">\(x_t\)</span> as well as a <em>noisy</em> signal about the future value of fundamentals:
<span class="math display">\[\begin{equation}
s_t = x_{t+1} + v_t,
\end{equation}\]</span>
where <span class="math inline">\((v_t)\)</span> is also a strong white noise, independent of <span class="math inline">\((u_t)\)</span> (incremental information about future fundamentals, Barsky and Sims, 2012). Moving average representation:
<span class="math display">\[\begin{equation}
\left[
\begin{array}{c}
x_t\\
s_t
\end{array}
\right] =
\left[
\begin{array}{cc}
La(L) &amp; 0\\
a(L) &amp; 1
\end{array}
\right]
\left[
\begin{array}{c}
u^a_t\\
v_t
\end{array}
\right],\quad \mbox{where $u^a_t = u_{t+1}$.}
\end{equation}\]</span></p>
<p>The determinant of the moving average polynomial has a root equal to zero, which is within the unit circle <span class="math inline">\(\Rightarrow\)</span> non-fundamentalness.</p>
<p>Standard estimation toolboxes may lead to misspecified IRFs.</p>
<p>Gouri'eroux, Monfort and Renne (2019) XXX show that both identification issues [“Q” (or <strong>static issue</strong>) + fundamentalness regime (or <strong>dynamic issue</strong>)}] disappear when the structural shocks are non-Gaussian.</p>
<p>Moreover: they develop consistent parametric and semi-parametric estimation methods when the MA part of the process may be non-fundamental, they illustrate the functioning and performances of these methods by applying them on both simulated and real data.</p>
<p>If <span class="math inline">\(\mathbb{V}ar(\varepsilon_t)=1\)</span> and <span class="math inline">\(\mathbb{V}ar(\varepsilon^*_t)=\frac{1}{4}\)</span>, then the following two MA processes:
<span class="math display">\[\begin{eqnarray*}
y_t &amp;=&amp; \varepsilon_t + \frac{1}{2} \varepsilon_{t-1}\\
y^*_t &amp;=&amp;  \varepsilon^*_t + 2 \varepsilon^*_{t-1},
\end{eqnarray*}\]</span>
have the same second-order properties.</p>
<p>Processes <span class="math inline">\(y_t\)</span> and <span class="math inline">\(y_t^*\)</span> are observationally equivalent if the shocks are Gaussian.</p>
<p>Next slide: For each of the following four distributions, we compare the distributions of <span class="math inline">\((y_{t-1},y_t)\)</span> and of <span class="math inline">\((y^*_{t-1},y^*_t)\)</span>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:FourDistriSVARMA"></span>
<img src="images/Figure_distri4MC.png" alt="XXXX." width="95%"><p class="caption">
Figure 3.6: XXXX.
</p>
</div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:FourDistriSVARMA2"></span>
<img src="images/Figure_simulSVARMA.png" alt="XXXX." width="95%"><p class="caption">
Figure 3.7: XXXX.
</p>
</div>
<p>The fact that SVARMA parameterization is identified in non-Gaussian context already present in the literature [Chan, Ho and Tong, 2006, Biometrika] XXX</p>
<p>GMR (2019) propose two consistent estimation approaches of potentially-non-fundamental SVARMA(<span class="math inline">\(p\)</span>,<span class="math inline">\(q\)</span>):</p>
<ol style="list-style-type: decimal">
<li>Semi-parametric approach (2SLS-GMM). Two steps:
<ol style="list-style-type: lower-alpha">
<li>Consistent estimates of <span class="math inline">\(\Pi= [\Phi_1,\dots,\Phi_p]\)</span> can be obtained by applying two-stage least squares (2SLS).</li>
<li>Estimate <span class="math inline">\(\Theta(L)\)</span> by fitting higher-order moments of MA components.</li>
</ol>
</li>
<li>Maximum-Likelihood approach. Key ingredient: algorithm to recover <span class="math inline">\(\eta_t\)</span>’s from the <span class="math inline">\(y_t\)</span>’s, whatever the (non)fundamentalness regime.</li>
</ol>
<p>First step of the 2SLS-GMM approach:</p>
<p>Consistent estimates of <span class="math inline">\(\Pi= [\Phi_1,\dots,\Phi_p]\)</span> obtained by 2SLS, using <span class="math inline">\(y_{t-2},\dots,y_{t-k-1}\)</span> (<span class="math inline">\(k \ge p\)</span>) as instruments <span class="math inline">\(\Rightarrow\)</span> Consistent estimates <span class="math inline">\(\hat{Z}_t\)</span> of <span class="math inline">\(\Theta(L)\varepsilon_t\)</span> (<span class="math inline">\(\hat{Z}_t \equiv \hat{\Phi}(L)y_t\)</span>).
\end{block}</p>
<p>Second step of the 2SLS-GMM approach: Using the Taylor expansion of the log-Laplace transf. of <span class="math inline">\((Z_t,Z_{t-1})\)</span>, it can be shown that:
<span class="math display">\[\begin{equation*}
\begin{array}{ccll}
E[(u'Z_t + v'Z_{t-1})^2] &amp;=&amp; \sum_{j=1}^{n} [(u'B_{0j})^2 + (u'B_{1j}+v'B_{0j})^2 + (v'B_{1j})^2] &amp; \mbox{(order 2)}\\
E[(u'Z_t + v'Z_{t-1})^3] &amp;=&amp; \sum_{j=1}^{n} \kappa_{3j}[(u'B_{0j})^3 + (u'B_{1j}+v'B_{0j})^3 + (v'B_{1j})^3] &amp; \mbox{(order 3)}\\
E[(u'Z_t + v'Z_{t-1})^4] &amp;=&amp; \sum_{j=1}^{n} \kappa_{4j}[(u'B_{0j})^4 + (u'B_{1j}+v'B_{0j})^4 + (v'B_{1j})^4]\\
&amp;&amp; +3\left(\sum_{j=1}^{n}[(u'B_{0j})^2 + (u'B_{1j}+v'B_{0j})^2 + (v'B_{1j})^2]\right)^2 &amp; \mbox{(order 4)},
\end{array}
\end{equation*}\]</span>
where <span class="math inline">\(Z_t := \Phi(L)Y_t = B_0 \eta_t + B_1 \eta_{t-1}\)</span> (i.e. <span class="math inline">\(C=B_0\)</span> and <span class="math inline">\(B_1 \equiv - \Theta C\)</span>), and where the <span class="math inline">\(\kappa_{3j}\)</span>’s and <span class="math inline">\(\kappa_{4j}\)</span>’s are the third-order and fourth-order cumulants of <span class="math inline">\(\eta_{j,t}\)</span>.</p>
<p>The previous formula are used to express moment restrictions of the form
<span class="math display">\[
E\left[h(Y_t,Y_{t-1},\dots,Y_{t-p-1};\alpha,\beta)\right]=0.
\]</span></p>
<p>If <span class="math inline">\(r\)</span> is the dimension of <span class="math inline">\(h(Y_t,Y_{t-1},\dots,Y_{t-p-1};\alpha,\beta)\)</span>, then we have the order condition <span class="math inline">\(r \ge 2n^2+2n\)</span> (if both third-order an fourth-order moments are used).</p>
<div class="hypothesis">
<p><span id="hyp:StrongSVARMA" class="hypothesis"><strong>Hypothesis 3.5  (Strong stationary SVARMA process) </strong></span>We have:</p>
<ol style="list-style-type: lower-roman">
<li>The errors <span class="math inline">\(\varepsilon_t\)</span> are i.i.d. and such that <span class="math inline">\(\mathbb{E}(\varepsilon_t)=0\)</span> and <span class="math inline">\(\mathbb{E}(\| \varepsilon_t \|^2)&lt;\infty\)</span>.</li>
<li>
<span class="math inline">\(\varepsilon_t = B \eta_t\)</span>, where the components <span class="math inline">\(\eta_{j,t}\)</span> are zero, unit variance, mutually independent.</li>
<li>All the roots of <span class="math inline">\(\det(\Phi (L))\)</span> have a modulus strictly larger than 1 (stationarity)</li>
<li>The roots of <span class="math inline">\(\det(\Theta(z))\)</span> are not on the unit circle.</li>
<li>The components of the first row of <span class="math inline">\(B\)</span> are positive and in increasing order.</li>
<li>Each component of <span class="math inline">\(\eta_t\)</span> has a non-zero <span class="math inline">\(r^{th}\)</span> cumulant, with <span class="math inline">\(r \ge 3\)</span>, and a finite moment of order <span class="math inline">\(s\)</span>, where <span class="math inline">\(s\)</span> is an even integer greater than, or equal to, <span class="math inline">\(r\)</span>.</li>
</ol>
</div>
<p>Assumption vi is satisfied by most “usual” non-Gaussian distributions.</p>
<p><strong>Maximum Likelihood approach</strong> (Univariate case <span class="math inline">\(y_t = \varepsilon_t - \theta \varepsilon_{t-1}\)</span>)}</p>
<p><span class="math display">\[\begin{eqnarray*}
\mbox{When $|\theta|&lt;1$, } \qquad \varepsilon_t &amp;=&amp; \sum^\infty_{h=0} \theta^h y_{t-h} = \underbrace{\sum^{t-1}_{h=0} \theta^h y_{t-h}}_{\mbox{truncated value }\hat{\varepsilon}_t(\theta)} + \mbox{ trunc. error}\\
\mbox{When $|\theta|&gt;1$, } \qquad \varepsilon_t &amp;=&amp; - \sum^\infty_{h=0} \frac{1}{\theta^{h+1}} y_{t+h+1} = \underbrace{- \sum^{T-t-1}_{h=0} \frac{1}{\theta^{h+1}} y_{t+h+1}}_{\mbox{truncated value }\hat{\varepsilon}_t(\theta)} + \mbox{ trunc. error}.
\end{eqnarray*}\]</span></p>
<p>Truncated log-likelihood function: <span class="math inline">\(\log \mathcal{L}(y_1,\dots,y_T;\theta, \gamma) = \sum^T_{t=1} \log g \left(\hat{\varepsilon}_t(\theta); \gamma\right)\)</span>, where <span class="math inline">\(g(.;\gamma)\)</span> is the (parametric) p.d.f. of <span class="math inline">\(\varepsilon_t\)</span>.
\end{block}</p>
<p>Maximum Likelihood approach (Multivariate case)</p>
<p>We propose an algorithm (<span class="math inline">\(\mathcal{E}\)</span>) to get estimates of the <span class="math inline">\(\varepsilon_t\)</span>’s (<span class="math inline">\(t \in \{1,\dots,T\}\)</span>):
<span class="math display">\[\begin{eqnarray*}
\mathcal{E}: &amp;&amp;\\
&amp;&amp; Y_{-p+1}^T,\Phi_1,\dots,\Phi_p,\Theta
\quad \mapsto \quad \mathcal{E}(Y_{-p+1}^T,\Phi_1,\dots,\Phi_p,\Theta),
\end{eqnarray*}\]</span>
where <span class="math inline">\(Y_{-p+1}^T=\{Y_{-p+1},\dots,Y_1,\dots,Y_T\}\)</span>.</p>
<p>Algorithm <span class="math inline">\(\mathcal{E}\)</span> is based on the Schur decomposition of <span class="math inline">\(\Theta\)</span> and on a mixture of forward and backward recursions.</p>
<p><span class="math inline">\(\mathcal{E}(Y_{-p+1}^T,\Phi_1,\dots,\Phi_p,\Theta)\)</span> converges to <span class="math inline">\(\varepsilon_t\)</span> in mean square.</p>
<p>Truncated log-likelihood:
<span class="math display" id="eq:VARMAapproxML">\[\begin{equation}
\log \mathcal{L} (Y_{-p+1}^T;\Phi,\Theta, \Gamma) = - T \sum_{k=1}^n \log |\lambda_k| \mathbb{I}_{\{|\lambda_k| \ge 1\}} + \sum_{t=1}^{T} \log g(\mathcal{E}(Y_{-p+1}^T,\Phi,\Theta), \Gamma), \tag{3.30}
\end{equation}\]</span>
where the <span class="math inline">\(\lambda_k\)</span>’s are the eigenvalues of <span class="math inline">\(\Theta\)</span> and where <span class="math inline">\(g(.,\Gamma)\)</span> is the p.d.f. of <span class="math inline">\(\varepsilon_t\)</span>.</p>
<p>Monte Carlo experiments</p>
<p>VMA(1) process: <span class="math inline">\(y_t = C \eta_t - \Theta C \eta_{t-1}\)</span>, with
<span class="math display" id="eq:CTHETA">\[\begin{equation}
C = \left[
\begin{array}{cc}
0 &amp; 1 \\
1 &amp; 0.5
\end{array}
\right] \quad \mbox{and} \quad
\Theta = \left[
\begin{array}{cc}
-0.5 &amp; 0 \\
1 &amp; -2
\end{array}
\right], \tag{3.31}
\end{equation}\]</span>
<span class="math inline">\(\eta_{1,t}\)</span> is drawn from a mixture of Gaussian (skewness of 2, excess kurtosis of 6), <span class="math inline">\(\eta_{2,t}\)</span>, is drawn from a Student’s distribution with 6 df.</p>
<p>The data generating process is non-fundamental.</p>
<p>Three sample sizes: <span class="math inline">\(T=100\)</span>, 200 and 500. %Pseudo ML: in the (truncated) log-likelihood, the distributions of both <span class="math inline">\(\eta_{1,t}\)</span> and <span class="math inline">\(\eta_{2,t}\)</span> are mixtures of Gaussian.</p>
<p>Better small-sample performances for MLE than for 2SLS-GMM.</p>
<p><strong>Relation with the Heteroskedasticity Identification</strong></p>
<p>In some cases, where the <span class="math inline">\(\varepsilon_t\)</span>’s are heteroskedastic, the <span class="math inline">\(B\)</span> matrix can be identified</p>
<p><a href="%5Chref%7Bhttps://www.mitpressjournals.org/doi/10.1162/003465303772815727">Rigobon (2003)</a>,</p>
<p><a href="https://www.sciencedirect.com/science/article/pii/S0165188909001481#!">Lanne, Lutkepohl and Maciejowska (2010)</a></p>
<p>Consider the case where we still have <span class="math inline">\(\varepsilon_t = B \eta_t\)</span> but where <span class="math inline">\(\eta_t\)</span>’s variance conditionally depends on a regime <span class="math inline">\(s_t \in \{1,\dots,M\}\)</span>. That is:
<span class="math display">\[
\mathbb{V}ar(\eta_{k,t}|s_t) = \lambda_{s_t,k} \quad \mbox{for } k \in \{1,\dots,n\}
\]</span></p>
<p>Denoting by <span class="math inline">\(\Lambda_i\)</span> the diagonal matrix whose diagonal entries are the <span class="math inline">\(\lambda_{i,k}\)</span>’s, it comes that:
<span class="math display">\[
\mathbb{V}ar(\eta_{t}|s_t) = \Lambda_{s_t},\quad \mbox{and}\quad \mathbb{V}ar(\varepsilon_{t}|s_t) = B\Lambda_{s_t}B'.
\]</span></p>
<p>Without loss of generality, it can be assumed that <span class="math inline">\(\Lambda_1=Id\)</span>.</p>
<p>In this context, <span class="math inline">\(B\)</span> is identified, apart from sign reversal of its columns if for all <span class="math inline">\(k \ne j \in \{1,\dots,n\}\)</span>, there is a regime <span class="math inline">\(i\)</span> s.t. <span class="math inline">\(\lambda_{i,k} \ne \lambda_{i,j}\)</span>. <a href="https://www.sciencedirect.com/science/article/pii/S0165188909001481#!">Prop.1 in Lanne, L"utkepohl and Maciejowska (2010)</a>.</p>
<p>Bivariate regime case (<span class="math inline">\(M=2\)</span>): <span class="math inline">\(B\)</span> identified if the <span class="math inline">\(\lambda_{2,k}\)</span>’s are all different. That is, identification is ensured if “there is sufficient heterogeneity in the volatility changes” [L"utkepohl and Netsunajev (2017)(<a href="https://www.sciencedirect.com/science/article/pii/S2452306216300223" class="uri">https://www.sciencedirect.com/science/article/pii/S2452306216300223</a>).</p>
<p>If the regimes <span class="math inline">\(s_t\)</span> are exogenous and serially independent, then this situation is consistent with the “non-Gaussian” situation described in this section.</p>

</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="intro.html"><span class="header-section-number">2</span> Introduction</a></div>
<div class="next"><a href="appendix.html"><span class="header-section-number">4</span> Appendix</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li>
<a class="nav-link" href="#vector-auto-regressive-var-models"><span class="header-section-number">3</span> Vector Auto-Regressive (VAR) models</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#vars-ans-svarma-models"><span class="header-section-number">3.0.1</span> VARs (ans SVARMA) models</a></li>
<li><a class="nav-link" href="#irfs-svarma"><span class="header-section-number">3.0.2</span> IRFs SVARMA</a></li>
<li><a class="nav-link" href="#var-estimation"><span class="header-section-number">3.0.3</span> VAR estimation</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#identification-problem-and-standard-identification-techniques"><span class="header-section-number">3.1</span> Identification Problem and Standard Identification Techniques</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#Signs"><span class="header-section-number">3.1.1</span> Sign restrictions</a></li>
<li><a class="nav-link" href="#NonGaussian"><span class="header-section-number">3.1.2</span> Non-Gaussian Shocks</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Advanced Econometrics</strong>" was written by Jean-Paul Renne. It was last built on 2022-09-08.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
