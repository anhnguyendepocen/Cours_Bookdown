<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Forecasting | Advanced Econometrics</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.27 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Forecasting | Advanced Econometrics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Forecasting | Advanced Econometrics" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Jean-Paul Renne" />


<meta name="date" content="2022-09-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="append.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Advanced Econometrics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Before starting</a></li>
<li class="chapter" data-level="2" data-path="forecasting.html"><a href="forecasting.html"><i class="fa fa-check"></i><b>2</b> Forecasting</a></li>
<li class="chapter" data-level="3" data-path="append.html"><a href="append.html"><i class="fa fa-check"></i><b>3</b> Appendix</a>
<ul>
<li class="chapter" data-level="3.1" data-path="append.html"><a href="append.html#statistical-tables"><i class="fa fa-check"></i><b>3.1</b> Statistical Tables</a></li>
<li class="chapter" data-level="3.2" data-path="append.html"><a href="append.html#PCAapp"><i class="fa fa-check"></i><b>3.2</b> Principal component analysis (PCA)</a></li>
<li class="chapter" data-level="3.3" data-path="append.html"><a href="append.html#variousResults"><i class="fa fa-check"></i><b>3.3</b> Statistics: definitions and results</a></li>
<li class="chapter" data-level="3.4" data-path="append.html"><a href="append.html#GaussianVar"><i class="fa fa-check"></i><b>3.4</b> Some properties of Gaussian variables</a></li>
<li class="chapter" data-level="3.5" data-path="append.html"><a href="append.html#proofs"><i class="fa fa-check"></i><b>3.5</b> Proofs</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="append.html"><a href="append.html#MLEproperties"><i class="fa fa-check"></i><b>3.5.1</b> Proof of Proposition @ref(prp:MLEproperties)</a></li>
<li class="chapter" data-level="3.5.2" data-path="append.html"><a href="append.html#Walddistri"><i class="fa fa-check"></i><b>3.5.2</b> Proof of Proposition @ref(prp:Walddistri)</a></li>
<li class="chapter" data-level="3.5.3" data-path="append.html"><a href="append.html#LMdistri"><i class="fa fa-check"></i><b>3.5.3</b> Proof of Proposition @ref(prp:LMdistri)</a></li>
<li class="chapter" data-level="3.5.4" data-path="append.html"><a href="append.html#equivLRLMW"><i class="fa fa-check"></i><b>3.5.4</b> Proof of Proposition @ref(prp:equivLRLMW)</a></li>
<li class="chapter" data-level="3.5.5" data-path="append.html"><a href="append.html#proofTVTCL"><i class="fa fa-check"></i><b>3.5.5</b> Proof of Eq. @ref(eq:TCL2)</a></li>
<li class="chapter" data-level="3.5.6" data-path="append.html"><a href="append.html#smallestMSE"><i class="fa fa-check"></i><b>3.5.6</b> Proof of Proposition @ref(prp:smallestMSE)</a></li>
<li class="chapter" data-level="3.5.7" data-path="append.html"><a href="append.html#estimVARGaussian"><i class="fa fa-check"></i><b>3.5.7</b> Proof of Proposition @ref(prp:estimVARGaussian)</a></li>
<li class="chapter" data-level="3.5.8" data-path="append.html"><a href="append.html#OLSVAR"><i class="fa fa-check"></i><b>3.5.8</b> Proof of Proposition @ref(prp:OLSVAR)</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="append.html"><a href="append.html#additional-codes"><i class="fa fa-check"></i><b>3.6</b> Additional codes</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="append.html"><a href="append.html#App:GEV"><i class="fa fa-check"></i><b>3.6.1</b> Simulating GEV distributions</a></li>
<li class="chapter" data-level="3.6.2" data-path="append.html"><a href="append.html#IRFDELTA"><i class="fa fa-check"></i><b>3.6.2</b> Computing the covariance matrix of IRF using the delta method</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Advanced Econometrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="forecasting" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">Chapter 2</span> Forecasting<a href="forecasting.html#forecasting" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Forecasting has always been an important part of the time series field (<span class="citation">De Gooijer and Hyndman (<a href="#ref-DEGOOIJER2006443" role="doc-biblioref">2006</a>)</span>). Macroeconomic forecasts are done in many places: Public Administration (notably Treasuries), Central Banks, International Institutions (e.g. IMF, OECD), banks, big firms. These institutions are interested in the <strong>point estimates</strong> (<span class="math inline">\(\sim\)</span> most likely value) of the variable of interest. They also sometimes need to measure the <strong>uncertainty</strong> (<span class="math inline">\(\sim\)</span> dispersion of likely outcomes) associated to the point estimates.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
<p>Forecasts produced by professional forecasters are available on these web pages:</p>
<ul>
<li><a href="https://www.philadelphiafed.org/research-and-data/real-time-center/survey-of-professional-forecasters/">Philly Fed Survey of Professional Forecasters</a>.</li>
<li><a href="http://www.ecb.europa.eu/stats/prices/indic/forecast/html/index.en.html">ECB Survey of Professional Forecasters</a>.</li>
<li><a href="https://www.imf.org/external/pubs/ft/weo/2016/update/01/">IMF World Economic Outlook</a>.</li>
<li><a href="http://www.oecd.org/eco/economicoutlook.htm">OECD Global Economic Outlook</a>.</li>
<li><a href="http://ec.europa.eu/economy_finance/eu/forecasts/index_en.htm">European Commission Economic Forecasts</a>.</li>
</ul>
<p>How to formalize the forecasting problem? Assume the current date is <span class="math inline">\(t\)</span>. We want to forecast the value that variable <span class="math inline">\(y_t\)</span> will take on date <span class="math inline">\(t+1\)</span> (i.e., <span class="math inline">\(y_{t+1}\)</span>) based on the observation of a set of variables gathered in vector <span class="math inline">\(x_t\)</span> (<span class="math inline">\(x_t\)</span> may contain lagged values of <span class="math inline">\(y_t\)</span>).</p>
<p>The forecaster aims at minimizing (a function of) the forecast error. It is usal to consider the following (quadratic) loss function:
<span class="math display">\[
\underbrace{\mathbb{E}([y_{t+1} - y^*_{t+1}]^2)}_{\mbox{Mean square error (MSE)}}
\]</span>
where <span class="math inline">\(y^*_{t+1}\)</span> is the forecast of <span class="math inline">\(y_{t+1}\)</span> (function of <span class="math inline">\(x_t\)</span>).</p>
<div class="proposition">
<p><span id="prp:smallestMSE" class="proposition"><strong>Proposition 2.1  (Smallest MSE) </strong></span>The smallest MSE is obtained with MSEthe expectation of <span class="math inline">\(y_{t+1}\)</span> conditional on <span class="math inline">\(x_t\)</span>.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-1" class="proof"><em>Proof</em>. </span>See Appendix <a href="append.html#smallestMSE">3.5.6</a>.</p>
</div>
<div class="proposition" names="Smallest MSE for linear forecasts">
<p><span id="prp:smallestMSElinear" class="proposition"><strong>Proposition 2.2  </strong></span>Among the class of linear forecasts, the smallest MSE is obtained with the linear projection of <span class="math inline">\(y_{t+1}\)</span> on <span class="math inline">\(x_t\)</span>.
This projection, denoted by <span class="math inline">\(\hat{P}(y_{t+1}|x_t):=\boldsymbol\alpha&#39;x_t\)</span>, satisfies:
<span class="math display" id="eq:proj">\[\begin{equation}
\mathbb{E}\left( [y_{t+1} - \boldsymbol\alpha&#39;x_t]x_t \right)=\bv{0}.\tag{2.1}
\end{equation}\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-2" class="proof"><em>Proof</em>. </span>Consider the function <span class="math inline">\(f:\)</span> <span class="math inline">\(\boldsymbol\alpha \rightarrow \mathbb{E}\left( [y_{t+1} - \boldsymbol\alpha&#39;x_t]^2 \right)\)</span>. We have:
<span class="math display">\[
f(\boldsymbol\alpha) = \mathbb{E}\left( y_{t+1}^2 - 2 y_t x_t&#39;\boldsymbol\alpha + \boldsymbol\alpha&#39;x_t x_t&#39;\boldsymbol\alpha] \right).
\]</span>
We have <span class="math inline">\(\partial f(\boldsymbol\alpha)/\partial \boldsymbol\alpha = \mathbb{E}(-2 y_{t+1} x_t + 2 x_t x_t&#39;\boldsymbol\alpha)\)</span>. The function is minimised for <span class="math inline">\(\partial f(\boldsymbol\alpha)/\partial \boldsymbol\alpha =0\)</span>.</p>
</div>
<p>Eq. <a href="forecasting.html#eq:proj">(2.1)</a> implies that <span class="math inline">\(\mathbb{E}\left( y_{t+1}x_t \right)=\mathbb{E}\left(x_tx_t&#39; \right)\boldsymbol\alpha\)</span>. (Note that <span class="math inline">\(x_t x_t&#39;\boldsymbol\alpha=x_t (x_t&#39;\boldsymbol\alpha)=(\boldsymbol\alpha&#39;x_t) x_t&#39;\)</span>.)</p>
<p>Hence, if <span class="math inline">\(\mathbb{E}\left(x_tx_t&#39; \right)\)</span> is nonsingular,
<span class="math display" id="eq:linproj">\[\begin{equation}
\boldsymbol\alpha=[\mathbb{E}\left(x_tx_t&#39; \right)]^{-1}\mathbb{E}\left( y_{t+1}x_t \right).\tag{2.2}
\end{equation}\]</span></p>
<p>The MSE then is:
<span class="math display">\[
\mathbb{E}([y_{t+1} - \boldsymbol\alpha&#39;x_t]^2) = \mathbb{E}{(y_{t+1}^2)} - \mathbb{E}\left( y_{t+1}x_t&#39; \right)[\mathbb{E}\left(x_tx_t&#39; \right)]^{-1}\mathbb{E}\left(x_ty_{t+1} \right).
\]</span></p>
<p>Consider the regression <span class="math inline">\(y_{t+1} = \boldsymbol\beta&#39;\bv{x}_t + \varepsilon_{t+1}\)</span>. The OLS estimate is:
<span class="math display">\[
\bv{b} = \left[ \underbrace{ \frac{1}{T} \sum_{i=1}^T \bv{x}_t\bv{x}_t&#39;}_{\bv{m}_1} \right]^{-1}\left[  \underbrace{ \frac{1}{T} \sum_{i=1}^T \bv{x}_t&#39;y_{t+1}}_{\bv{m}_2} \right].
\]</span>
If <span class="math inline">\(\{x_t,y_t\}\)</span> is covariance-stationary and ergodic for the second moments then the sample moments (<span class="math inline">\(\bv{m}_1\)</span> and <span class="math inline">\(\bv{m}_2\)</span>) converges in probability to the associated population moments and <span class="math inline">\(\bv{b} \overset{p}{\rightarrow} \boldsymbol\alpha\)</span> (where <span class="math inline">\(\boldsymbol\alpha\)</span> is defined in Eq. <a href="forecasting.html#eq:linproj">(2.2)</a>).</p>
<div class="example">
<p><span id="exm:fcstMAq" class="example"><strong>Example 2.1  (Forecasting an MA(q) process) </strong></span>Consider the MA(q) process:
<span class="math display">\[
y_t = \mu + \varepsilon_t + \theta_1 \varepsilon_{t-1} + \dots + \theta_q \varepsilon_{t-q},
\]</span>
where <span class="math inline">\(\{\varepsilon_t\}\)</span> is a white noise sequence (Def. <a href="#def:whitenoise"><strong>??</strong></a>).</p>
<p>We have:
<span class="math display">\[\begin{eqnarray*}
&amp;&amp;\mathbb{E}(y_{t+h}|\varepsilon_{t},\varepsilon_{t-1},\dots) =\\
&amp;&amp;\left\{
\begin{array}{lll}
\mu + \theta_h \varepsilon_{t} + \dots + \theta_q \varepsilon_{t-q+h}  \quad &amp;for&amp; \quad h \in [1,q]\\
\mu \quad &amp;for&amp; \quad h &gt; q
\end{array}
\right.
\end{eqnarray*}\]</span>
and
<span class="math display">\[\begin{eqnarray*}
&amp;&amp;\mathbb{V}ar(y_{t+h}|\varepsilon_{t},\varepsilon_{t-1},\dots)= \mathbb{E}\left( [y_{t+h} - \mathbb{E}(y_{t+h}|\varepsilon_{t},\varepsilon_{t-1},\dots)]^2 \right) =\\
&amp;&amp;\left\{
\begin{array}{lll}
\sigma^2(1+\theta_1^2+\dots+\theta_{h-1}^2) \quad &amp;for&amp; \quad h \in [1,q]\\
\sigma^2(1+\theta_1^2+\dots+\theta_q^2) \quad &amp;for&amp; \quad h&gt;q.
\end{array}
\right.
\end{eqnarray*}\]</span></p>
<p>Remark: The previous reasoning relies on the assumption that the <span class="math inline">\(\varepsilon_t\)</span>s are observed. But this is generally not the case in practice. Note that consistent estimates are available if the MA process is invertible (see Eq. <a href="#eq:invertible">(<strong>??</strong>)</a>) .</p>
</div>
<div class="example">
<p><span id="exm:fcstARp" class="example"><strong>Example 2.2  (Forecasting an AR(p) process) </strong></span>(See <a href="https://jrenne.shinyapps.io/ARpFcst">this web interface</a>.) Consider the AR(p) process:
<span class="math display">\[
y_t = c + \phi_1 y_{t-1} + \phi_2 y_{t-2} + \dots + \phi_p y_{t-p} + \varepsilon_t,
\]</span>
where <span class="math inline">\(\{\varepsilon_t\}\)</span> is a white noise sequence (Def. <a href="#def:whitenoise"><strong>??</strong></a>).</p>
<p>Using the notation of Eq. <a href="#eq:F">(<strong>??</strong>)</a>, we have:
<span class="math display">\[
\bv{y}_t - \boldsymbol\mu = F (\bv{y}_{t-1}- \boldsymbol\mu) + \boldsymbol\xi_t,
\]</span>
with <span class="math inline">\(\boldsymbol\mu = [\mu,\dots,\mu]&#39;\)</span> (<span class="math inline">\(\mu\)</span> is defined in Eq. <a href="#eq:EAR">(<strong>??</strong>)</a>). Hence:
<span class="math display">\[
\bv{y}_{t+h} - \boldsymbol\mu = \boldsymbol\xi_{t+h} + F \boldsymbol\xi_{t+h-1} + \dots + F^{h-1} \boldsymbol\xi_{t+1} + F^h (\bv{y}_{t}- \mu).
\]</span>
Therefore:
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}(\bv{y}_{t+h}|y_{t},y_{t-1},\dots) &amp;=&amp; \boldsymbol\mu + F^{h}(\bv{y}_t - \boldsymbol\mu)\\
\mathbb{V}ar\left( [\bv{y}_{t+h} - \mathbb{E}(\bv{y}_{t+h}|y_{t},y_{t-1},\dots)] \right) &amp;=&amp; \Sigma + F\Sigma F&#39; + \dots + F^{h-1}\Sigma (F^{h-1})&#39;,
\end{eqnarray*}\]</span>
where:
<span class="math display">\[
\Sigma = \left[
\begin{array}{ccc}
\sigma^2  &amp; 0&amp; \dots\\
0  &amp; 0 &amp; \\
\vdots  &amp; &amp; \ddots \\
\end{array}
\right].
\]</span></p>
<p>Alternative approach: Taking the (conditional) expectations of both sides of
<span class="math display">\[
y_{t+h} - \mu = \phi_1 (y_{t+h-1} - \mu) + \phi_2 (y_{t+h-2} - \mu) + \dots + \phi_p (y_{t-p} - \mu) + \varepsilon_{t+h},
\]</span>
we obtain:
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}(y_{t+h}|y_{t},y_{t-1},\dots) &amp;=&amp; \mu + \phi_1\left(\mathbb{E}[y_{t+h-1}|y_{t},y_{t-1},\dots] - \mu\right)+\\
&amp;&amp;\phi_2\left(\mathbb{E}[y_{t+h-2}|y_{t},y_{t-1},\dots] - \mu\right) + \dots +\\
&amp;&amp; \phi_p\left(\mathbb{E}[y_{t+h-p}|y_{t},y_{t-1},\dots] - \mu\right),
\end{eqnarray*}\]</span>
which can be exploited recursively.</p>
<p>The recursion begins with <span class="math inline">\(\mathbb{E}(y_{t-k}|y_{t},y_{t-1},\dots)=y_{t-k}\)</span> (for any <span class="math inline">\(k \ge 0\)</span>).</p>
</div>
<div class="example">
<p><span id="exm:fcstARMApq" class="example"><strong>Example 2.3  (Forecasting an ARMA(p,q) process) </strong></span>Consider the process:
<span class="math display" id="eq:armaForecast">\[\begin{equation}
y_t = c + \phi_1 y_{t-1} + \dots + \phi_p y_{t-p} + \varepsilon_t + \theta_1 \varepsilon_{t-1} + \dots + \theta_q \varepsilon_{t-q},\tag{2.3}
\end{equation}\]</span>
where <span class="math inline">\(\{\varepsilon_t\}\)</span> is a white noise sequence (Def. <a href="#def:whitenoise"><strong>??</strong></a>). We assume that the MA part of the process is invertible (see Eq. <a href="#eq:invertible">(<strong>??</strong>)</a>), which implies that the information contained in <span class="math inline">\(\{y_{t},y_{t-1},y_{t-2},\dots\}\)</span> is identical to that in <span class="math inline">\(\{\varepsilon_{t},\varepsilon_{t-1},\varepsilon_{t-2},\dots\}\)</span>.</p>
<p>While one could use a recursive algorithm to compute the conditional mean (as in Example <a href="forecasting.html#exm:fcstARp">2.2</a>), it is convenient to employ the Wold decomposition of this process (see Theorem <a href="#thm:Wold"><strong>??</strong></a> and Prop. <a href="#prp:computPsi"><strong>??</strong></a> for the computation of the <span class="math inline">\(\psi_i\)</span>’s in the context of ARMA processes):
<!-- We have: -->
<!-- \begin{eqnarray*} -->
<!-- &&\mathbb{E}(y_{t+h}|y_{t},y_{t-1},\dots) =\\ -->
<!-- &&\left\{ -->
<!-- \begin{array}{ll} -->
<!-- \mu + \phi_1\left(\mathbb{E}(y_{t+h-1}|y_{t},y_{t-1},\dots) - \mu\right)+\\ -->
<!-- \phi_2\left(\mathbb{E}(y_{t+h-2}|y_{t},y_{t-1},\dots) - \mu\right) + \dots +\\ -->
<!-- \phi_p\left(\mathbb{E}(y_{t+h-p}|y_{t},y_{t-1},\dots) - \mu\right) +\\ -->
<!-- \theta_{h}\varepsilon_{t} + \theta_{h+1}\varepsilon_{t-1} + \dots + \theta_{q}\varepsilon_{t+h-q} &\mbox{for  $h \in[1,q]$},\\ -->
<!-- \\ -->
<!-- \mu + \phi_1\left(\mathbb{E}(y_{t+h-1}|y_{t},y_{t-1},\dots) - \mu\right)+\\ -->
<!-- \phi_2\left(\mathbb{E}(y_{t+h-2}|y_{t},y_{t-1},\dots) - \mu\right) + \dots +\\ -->
<!-- \phi_p\left(\mathbb{E}(y_{t+h-p}|y_{t},y_{t-1},\dots) - \mu\right) & \mbox{for $h>q$}. -->
<!-- \end{array} -->
<!-- \right. -->
<!-- \end{eqnarray*} -->
<!-- To compute the MSE, it is convenient to use the Wold decomposition of the process (see Theorem \@ref(thm:Wold)): -->
<span class="math display">\[
y_t = \mu + \sum_{i=0}^{+\infty} \psi_i \varepsilon_{t-i}.
\]</span>
This implies:
<span class="math display">\[\begin{eqnarray*}
y_{t+h} &amp;=&amp; \mu + \sum_{i=0}^{h-1} \psi_i \varepsilon_{t+h-i} + \sum_{i=h}^{+\infty} \psi_i \varepsilon_{t+h-i}\\
&amp;=&amp; \mu + \sum_{i=0}^{h-1} \psi_i \varepsilon_{t+h-i} + \sum_{i=0}^{+\infty} \psi_{i+h} \varepsilon_{t-i}.
\end{eqnarray*}\]</span></p>
<p>Since <span class="math inline">\(\mathbb{E}(y_{t+h}|y_t,y_{t-1},\dots)=\mu+\sum_{i=0}^{+\infty} \psi_{i+h} \varepsilon_{t-i}\)</span>, we get:
<span class="math display">\[
\mathbb{V}ar(y_{t+h}|y_t,y_{t-1},\dots) =\mathbb{V}ar\left(\sum_{i=0}^{h-1} \psi_i \varepsilon_{t+h-i}\right)= \sigma^2 \sum_{i=0}^{h-1} \psi_i^2.
\]</span></p>
</div>
<p>How to use the previous formulas in practice?</p>
<p>One has first to select a specification and to estimate the model.
Two methods to determine relevant specifications:</p>
<ol style="list-style-type: lower-alpha">
<li>Information criteria (see Definition @ref(def:info_criteria)).</li>
<li>Box-Jenkins approach.</li>
</ol>
<p><span class="citation">Box and Jenkins (<a href="#ref-boxjen76" role="doc-biblioref">1976</a>)</span> have proposed an approach that is now widely used.</p>
<ol style="list-style-type: decimal">
<li>Data transformation. The data should be transformed to “make them stationary”. To do so, one can e.g. take logarithms, take changes in the considered series, remove (deterministic) trends.</li>
<li>Select <span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span>. This can be based on the PACF approach (see Section <a href="#PACFapproach"><strong>??</strong></a>), or on selection criteria (see Definition <a href="#def:infocriteria"><strong>??</strong></a>).</li>
<li>Estimate the model parameters. See Section <a href="#estimARMA"><strong>??</strong></a>.</li>
<li>Check that the estimated model is consistent with the data. See below.</li>
</ol>
<!-- **Sample autocorrelation** -->
<!-- Population autocorrelation: $\rho_i = \gamma_i / \gamma_0$. Natural estimate based on sample moments: $\hat{\rho_i} = \hat\gamma_j / \hat\gamma_0$ where: -->
<!-- $$ -->
<!-- \gamma_j = \frac{1}{T} \sum_{t=j+1}^{T} (y_t - \bar{y})(y_{t-j} - \bar{y}). -->
<!-- $$ -->
<!-- For an MA($q$) process, $\rho_j = 0$ for $j>q$. -->
<!-- If the data are generated by a Gaussian MA($q$) process, then: -->
<!-- $$ -->
<!-- \mathbb{V}ar(\hat\rho_j) \approx \frac{1}{T}\left\{1 + 2 \sum_{i=1}^q \rho_i^2 \right\} -->
<!-- $$ -->
<!-- In particular, if the data correspond to a Gaussian white noise then $\hat\rho_i \in [\pm 2/\sqrt{T}]$ about 95\% of the time. -->
<!-- **Partial autocorrelation** -->
<!-- The $m^{th}$ population partial autocorrelation (see also Def. \@ref(def:partialAC)) is the $m^{th}$ coefficient in a linear projection of $y_{t+1}$ on its $m$ most recent lags: -->
<!-- $$ -->
<!-- \hat{y}_{t+1|t} = \mu + \phi_{1,m}(y_t - \mu) + \phi_{2,m}(y_{t-1} - \mu) + \dots +\phi_{m,m}(y_{t-m+1} - \mu). -->
<!-- $$ -->
<!-- Using the OLS formula, it can be shown that the (population) vector $\boldsymbol\phi_{.,m}=[\phi_{1,m},\dots,\phi_{m,m}]'$ satisfies: -->
<!-- $$ -->
<!-- \boldsymbol\phi_{.,m} = \left[ -->
<!-- \begin{array}{cccc} -->
<!-- \gamma_0 & \gamma_1& \dots & \gamma_{m-1}\\ -->
<!-- \gamma_1 & \gamma_0& \dots & \gamma_{m-2}\\ -->
<!-- \vdots & & \ddots & \\ -->
<!-- \gamma_{m-1} & \gamma_{m-2}& \dots & \gamma_{0} -->
<!-- \end{array} -->
<!-- \right]^{-1}\left[ -->
<!-- \begin{array}{c} -->
<!-- \gamma_1\\ -->
<!-- \gamma_2\\ -->
<!-- \vdots\\ -->
<!-- \gamma_{m} -->
<!-- \end{array} -->
<!-- \right]. -->
<!-- $$ -->
<!-- For an AR($p$) process, $\phi_{m,m}=0$ for $m>p$, which reflects the fact that only the first $p$ lags are useful to forecast $y_{t}$. -->
<!-- A natural estimate $\hat\phi_{m,m}$ of $\phi_{m,m}$ is obtained by running the regression: -->
<!-- $$ -->
<!-- \hat{y}_{t+1} = \hat{c} + \hat\phi_{1,m}y_t + \hat\phi_{2,m}y_{t-1} + \dots + \hat\phi_{m,m}y_{t-m+1} + \hat\varepsilon_{t+1}. -->
<!-- $$ -->
<!-- Under the hypothesis that the data are generated by an AR($p$) process: -->
<!-- $$ -->
<!-- \mathbb{V}ar(\hat\phi_{m,m}) \approx \frac{1}{T} \quad \mbox{for} \quad m > p. -->
<!-- $$ -->
<!-- Besides, for $i,j>p$, $\hat\phi_{i,i}$ and $\hat\phi_{j,j}$ are asymptotically independent. -->
<p><strong>Assessing the performances of a forecasting model</strong></p>
<p>Once one has fitted a model on a given dataset (of length <span class="math inline">\(T\)</span>, say), one compute MSE (mean square errors) to evaluate the performance of the model. But this MSE is the <strong>in-sample</strong> one. It is easy to reduce in-sample MSE. Typically, if the model is estimated by OLS, adding covariates mechanically reduces the MSE (see Props. <a href="#prp:chgeR2"><strong>??</strong></a> and <a href="#prp:chgeInR2"><strong>??</strong></a>). That is, even if additional data are irrelevant, the <span class="math inline">\(R^2\)</span> of the regression increases. Adding irrelevant variables increases the (in-sample) <span class="math inline">\(R^2\)</span> but is bound to increase the <strong>out-of-sample</strong> MSE.</p>
<p>Therefore, it is important to analyse <strong>out-of-sample</strong> performances of the forecasting model:</p>
<ol style="list-style-type: lower-alpha">
<li>Estimate a model on a sample of reduced size (<span class="math inline">\(1,\dots,T^*\)</span>, with <span class="math inline">\(T^*&lt;T\)</span>)</li>
<li>Use the remaining available periods (<span class="math inline">\(T^*+1,\dots,T\)</span>) to compute <strong>out-of-sample</strong> forecasting errors (and compute their MSE). In an out-of-sample exercise, it is important to make sure that the data used to produce a forecasts (as of date <span class="math inline">\(T^*\)</span>) where indeed available on date <span class="math inline">\(T^*\)</span>.</li>
</ol>
<p><strong>Diebold-Mariano test</strong></p>
<p>How to compare different forecasting approaches? <span class="citation">Diebold and Mariano (<a href="#ref-Diebold_Mariano_1995" role="doc-biblioref">1995</a>)</span> have proposed a simple test to address this question.</p>
<p>Assume that you want to compare approaches A and B. You have historical data sets and you have implemented both approaches in the past, providing you with two sets of forecasting errors: <span class="math inline">\(\{e^{A}_t\}_{t=1,\dots,T}\)</span> and <span class="math inline">\(\{e^{B}_t\}_{t=1,\dots,T}\)</span>.</p>
<p>It may be the case that your forecasts serve a specific purpose and that, for instance, you dislike positive forecasting errors and you care less about negative errors. We assume you are able to formalise this by means of a <strong>loss function <span class="math inline">\(L(e)\)</span></strong>. For instance:</p>
<ul>
<li>If you dislike large positive errors, you may set <span class="math inline">\(L(e)=\exp(e)\)</span>.</li>
<li>If you are concerned about both positive and negative errors (indifferently), you may set <span class="math inline">\(L(e)=e^2\)</span> (standard approach).</li>
</ul>
<p>Let us define the sequence <span class="math inline">\(\{d_t\}_{t=1,\dots,T} \equiv \{L(e^{A}_t)-L(e^{B}_t)\}_{t=1,\dots,T}\)</span> and assume that this sequence is covariance stationary. We consider the following null hypothesis: <span class="math inline">\(H_0:\)</span> <span class="math inline">\(\bar{d}=0\)</span>, where <span class="math inline">\(\bar{d}\)</span> denotes the population mean of the <span class="math inline">\(d_t\)</span>s. Under <span class="math inline">\(H_0\)</span> and under the assumption of covariance-stationarity of <span class="math inline">\(d_t\)</span>, we have (Theorem @ref{(hm:CLTcovstat)):
<span class="math display">\[
\sqrt{T} \bar{d}_T \overset{d}{\rightarrow} \mathcal{N}\left(0,\sum_{j=-\infty}^{+\infty} \gamma_j \right),
\]</span><br />
where the <span class="math inline">\(\gamma_j\)</span>s are the autocovariances of <span class="math inline">\(d_t\)</span>.</p>
<p>Hence, assuming that <span class="math inline">\(\hat{\sigma}^2\)</span> is a consistent estimate of <span class="math inline">\(\sum_{j=-\infty}^{+\infty} \gamma_j\)</span> (for instance the one given by the Newey-West formula, see Def. <a href="#def:NW"><strong>??</strong></a>), we have, under <span class="math inline">\(H_0\)</span>:
<span class="math display">\[
DM_T := \sqrt{T}\frac{\bar{d}_T}{\sqrt{\hat{\sigma}^2}} \overset{d}{\rightarrow}  \mathcal{N}(0,1).
\]</span>
<span class="math inline">\(DM_T\)</span> is the test statistics. For a test of size <span class="math inline">\(\alpha\)</span>, the critical region is:<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>
<span class="math display">\[
]-\infty,-\Phi^{-1}(1-\alpha/2)] \cup [\Phi^{-1}(1-\alpha/2),+\infty[,
\]</span>
where <span class="math inline">\(\Phi\)</span> is the c.d.f. of the standard normal distribution.</p>
<div class="example">
<p><span id="exm:SwissOutOfSample" class="example"><strong>Example 2.4  (Forecasting Swiss GDP growth) </strong></span>We use a long historical time series of the Swiss GDP growth taken from the <span class="citation">Jordà, Schularick, and Taylor (<a href="#ref-JST_2017" role="doc-biblioref">2017</a>)</span> dataset (see Figure <a href="#fig:autocov"><strong>??</strong></a>, and Example <a href="#exm:SwissGrowthAIC"><strong>??</strong></a>).</p>
<p>We want to forecast this GDP growth. We envision two specifications : an AR(1) specification (the one advocated by the AIC criteria, see Example <a href="#exm:SwissGrowthAIC"><strong>??</strong></a>), and an ARMA(2,2) specification. We are interested in 2-year-ahead forecasts (i.e., <span class="math inline">\(h=2\)</span> since the data are yearly).</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="forecasting.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(AEC)</span>
<span id="cb1-2"><a href="forecasting.html#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(forecast)</span></code></pre></div>
<pre><code>## Registered S3 method overwritten by &#39;quantmod&#39;:
##   method            from
##   as.zoo.data.frame zoo</code></pre>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="forecasting.html#cb3-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">subset</span>(JST,iso<span class="sc">==</span><span class="st">&quot;CHE&quot;</span>)</span>
<span id="cb3-2"><a href="forecasting.html#cb3-2" aria-hidden="true" tabindex="-1"></a>T <span class="ot">&lt;-</span> <span class="fu">dim</span>(data)[<span class="dv">1</span>]</span>
<span id="cb3-3"><a href="forecasting.html#cb3-3" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="cn">NaN</span>,<span class="fu">log</span>(data<span class="sc">$</span>gdp[<span class="dv">2</span><span class="sc">:</span>T]<span class="sc">/</span>data<span class="sc">$</span>gdp[<span class="dv">1</span><span class="sc">:</span>(T<span class="dv">-1</span>)]))</span>
<span id="cb3-4"><a href="forecasting.html#cb3-4" aria-hidden="true" tabindex="-1"></a>first.date <span class="ot">&lt;-</span> T<span class="dv">-50</span></span>
<span id="cb3-5"><a href="forecasting.html#cb3-5" aria-hidden="true" tabindex="-1"></a>e1 <span class="ot">&lt;-</span> <span class="cn">NULL</span>; e2 <span class="ot">&lt;-</span> <span class="cn">NULL</span>;h<span class="ot">&lt;-</span><span class="dv">2</span></span>
<span id="cb3-6"><a href="forecasting.html#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(T.star <span class="cf">in</span> first.date<span class="sc">:</span>(T<span class="sc">-</span>h)){</span>
<span id="cb3-7"><a href="forecasting.html#cb3-7" aria-hidden="true" tabindex="-1"></a>  estim.model<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">arima</span>(y[<span class="dv">1</span><span class="sc">:</span>T.star],<span class="at">order=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>))</span>
<span id="cb3-8"><a href="forecasting.html#cb3-8" aria-hidden="true" tabindex="-1"></a>  estim.model<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">arima</span>(y[<span class="dv">1</span><span class="sc">:</span>T.star],<span class="at">order=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">0</span>,<span class="dv">2</span>))</span>
<span id="cb3-9"><a href="forecasting.html#cb3-9" aria-hidden="true" tabindex="-1"></a>  e1 <span class="ot">&lt;-</span> <span class="fu">c</span>(e1,y[T.star<span class="sc">+</span>h] <span class="sc">-</span> <span class="fu">predict</span>(estim.model<span class="fl">.1</span>,<span class="at">n.ahead=</span>h)<span class="sc">$</span>pred[h])</span>
<span id="cb3-10"><a href="forecasting.html#cb3-10" aria-hidden="true" tabindex="-1"></a>  e2 <span class="ot">&lt;-</span> <span class="fu">c</span>(e2,y[T.star<span class="sc">+</span>h] <span class="sc">-</span> <span class="fu">predict</span>(estim.model<span class="fl">.2</span>,<span class="at">n.ahead=</span>h)<span class="sc">$</span>pred[h])</span>
<span id="cb3-11"><a href="forecasting.html#cb3-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb3-12"><a href="forecasting.html#cb3-12" aria-hidden="true" tabindex="-1"></a>res.DM <span class="ot">&lt;-</span> <span class="fu">dm.test</span>(e1,e2,<span class="at">h =</span> h,<span class="at">alternative =</span> <span class="st">&quot;greater&quot;</span>)</span>
<span id="cb3-13"><a href="forecasting.html#cb3-13" aria-hidden="true" tabindex="-1"></a>res.DM</span></code></pre></div>
<pre><code>## 
##  Diebold-Mariano Test
## 
## data:  e1e2
## DM = -0.82989, Forecast horizon = 2, Loss function power = 2, p-value =
## 0.7946
## alternative hypothesis: greater</code></pre>
<p>With <code>alternative = "greater"</code> The alternative hypothesis is that method 2 is more accurate than method 1. Since we do not reject the null (the p-value being of 0.795), we are not led to use the more sophisticated model (ARMA(2,2)) and we keep the simple AR(1) model.</p>
<p>Assume now that we want to compare the AR(1) process to a VAR model (see Def. <a href="#def:SVAR"><strong>??</strong></a>). We consider a bivariate VAR, where GDP growth is complemented with CPI-based inflation rate.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="forecasting.html#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(vars)</span>
<span id="cb5-2"><a href="forecasting.html#cb5-2" aria-hidden="true" tabindex="-1"></a>infl <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="cn">NaN</span>,<span class="fu">log</span>(data<span class="sc">$</span>cpi[<span class="dv">2</span><span class="sc">:</span>T]<span class="sc">/</span>data<span class="sc">$</span>cpi[<span class="dv">1</span><span class="sc">:</span>(T<span class="dv">-1</span>)]))</span>
<span id="cb5-3"><a href="forecasting.html#cb5-3" aria-hidden="true" tabindex="-1"></a>y_var <span class="ot">&lt;-</span> <span class="fu">cbind</span>(y,infl)</span>
<span id="cb5-4"><a href="forecasting.html#cb5-4" aria-hidden="true" tabindex="-1"></a>e3 <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb5-5"><a href="forecasting.html#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(T.star <span class="cf">in</span> first.date<span class="sc">:</span>(T<span class="sc">-</span>h)){</span>
<span id="cb5-6"><a href="forecasting.html#cb5-6" aria-hidden="true" tabindex="-1"></a>  estim.model<span class="fl">.3</span> <span class="ot">&lt;-</span> <span class="fu">VAR</span>(y_var[<span class="dv">2</span><span class="sc">:</span>T.star,],<span class="at">p=</span><span class="dv">1</span>)</span>
<span id="cb5-7"><a href="forecasting.html#cb5-7" aria-hidden="true" tabindex="-1"></a>  e3 <span class="ot">&lt;-</span> <span class="fu">c</span>(e3,y[T.star<span class="sc">+</span>h] <span class="sc">-</span> <span class="fu">predict</span>(estim.model<span class="fl">.3</span>,<span class="at">n.ahead=</span>h)<span class="sc">$</span>fcst<span class="sc">$</span>y[h,<span class="dv">1</span>])</span>
<span id="cb5-8"><a href="forecasting.html#cb5-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb5-9"><a href="forecasting.html#cb5-9" aria-hidden="true" tabindex="-1"></a>res.DM <span class="ot">&lt;-</span> <span class="fu">dm.test</span>(e1,e2,<span class="at">h =</span> h,<span class="at">alternative =</span> <span class="st">&quot;greater&quot;</span>)</span>
<span id="cb5-10"><a href="forecasting.html#cb5-10" aria-hidden="true" tabindex="-1"></a>res.DM</span></code></pre></div>
<pre><code>## 
##  Diebold-Mariano Test
## 
## data:  e1e2
## DM = -0.82989, Forecast horizon = 2, Loss function power = 2, p-value =
## 0.7946
## alternative hypothesis: greater</code></pre>
<p>Again, we do not find that the alternative model (here the VAR(1) model) is better than the AR(1) model to forecast GDP growth.</p>
</div>

</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-boxjen76" class="csl-entry">
Box, George.E. P., and Gwilym M. Jenkins. 1976. <em>Time Series Analysis: Forecasting and Control</em>. Holden-Day.
</div>
<div id="ref-DEGOOIJER2006443" class="csl-entry">
De Gooijer, Jan G., and Rob J. Hyndman. 2006. <span>“25 Years of Time Series Forecasting.”</span> <em>International Journal of Forecasting</em> 22 (3): 443–73. https://doi.org/<a href="https://doi.org/10.1016/j.ijforecast.2006.01.001">https://doi.org/10.1016/j.ijforecast.2006.01.001</a>.
</div>
<div id="ref-Diebold_Mariano_1995" class="csl-entry">
Diebold, Francis, and Roberto Mariano. 1995. <span>“Comparing Predictive Accuracy.”</span> <em>Journal of Business &amp; Economic Statistics</em> 13 (3): 253–63. <a href="https://EconPapers.repec.org/RePEc:bes:jnlbes:v:13:y:1995:i:3:p:253-63">https://EconPapers.repec.org/RePEc:bes:jnlbes:v:13:y:1995:i:3:p:253-63</a>.
</div>
<div id="ref-JST_2017" class="csl-entry">
Jordà, Òscar, Moritz Schularick, and Alan M. Taylor. 2017. <span>“<span class="nocase">Macrofinancial History and the New Business Cycle Facts</span>.”</span> <em>NBER Macroeconomics Annual</em> 31 (1): 213–63. <a href="https://ideas.repec.org/a/ucp/macann/doi10.1086-690241.html">https://ideas.repec.org/a/ucp/macann/doi10.1086-690241.html</a>.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>In its inflation report, the Bank of England displays charts showing the conditional distribution of future inflation, called fan charts. This fan charts show the uncertainty associated with future inflation. See <a href="https://www.bankofengland.co.uk/quarterly-bulletin/1998/q1/the-inflation-report-projections-understanding-the-fan-chart">this page</a>.<a href="forecasting.html#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>This <a href="https://jrenne.shinyapps.io/tests/">ShinyApp application</a> illustrates the notion of statistical test (illustrating the p-value and the cirtical region, in particular).<a href="forecasting.html#fnref2" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="append.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/01-Forecasting.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["AdvECTS.pdf", "AdvECTS.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
