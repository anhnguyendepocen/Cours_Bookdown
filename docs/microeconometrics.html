<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 3 Microeconometrics | Advanced Econometrics</title>
<meta name="author" content="Jean-Paul Renne">
<meta name="description" content="3.1 Binary-choice models In many instances, the variables to be explained (\(y_i\)s) have only two possible values (\(0\) and \(1\), say). Assume we suspect some variable \(\mathbf{x}_i\) (\(K...">
<meta name="generator" content="bookdown 0.27 with bs4_book()">
<meta property="og:title" content="Chapter 3 Microeconometrics | Advanced Econometrics">
<meta property="og:type" content="book">
<meta property="og:description" content="3.1 Binary-choice models In many instances, the variables to be explained (\(y_i\)s) have only two possible values (\(0\) and \(1\), say). Assume we suspect some variable \(\mathbf{x}_i\) (\(K...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 3 Microeconometrics | Advanced Econometrics">
<meta name="twitter:description" content="3.1 Binary-choice models In many instances, the variables to be explained (\(y_i\)s) have only two possible values (\(0\) and \(1\), say). Assume we suspect some variable \(\mathbf{x}_i\) (\(K...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.0/transition.js"></script><script src="libs/bs3compat-0.4.0/tabs.js"></script><script src="libs/bs3compat-0.4.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Advanced Econometrics</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Prerequisites</a></li>
<li><a class="" href="intro.html"><span class="header-section-number">2</span> Introduction</a></li>
<li><a class="active" href="microeconometrics.html"><span class="header-section-number">3</span> Microeconometrics</a></li>
<li><a class="" href="appendix.html"><span class="header-section-number">4</span> Appendix</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="microeconometrics" class="section level1" number="3">
<h1>
<span class="header-section-number">3</span> Microeconometrics<a class="anchor" aria-label="anchor" href="#microeconometrics"><i class="fas fa-link"></i></a>
</h1>
<div id="binary-choice-models" class="section level2" number="3.1">
<h2>
<span class="header-section-number">3.1</span> Binary-choice models<a class="anchor" aria-label="anchor" href="#binary-choice-models"><i class="fas fa-link"></i></a>
</h2>
<p>In many instances, the variables to be explained (<span class="math inline">\(y_i\)</span>s) have only two possible values (<span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span>, say).</p>
<p>Assume we suspect some variable <span class="math inline">\(\mathbf{x}_i\)</span> (<span class="math inline">\(K \times 1\)</span>) to be able to account for the probability that <span class="math inline">\(y_i=1\)</span>.</p>
<p>The model reads:
<span class="math display">\[\begin{equation}\label{eq:binaryBenroulli}
y_i | \mathbf{X} \sim \mathcal{B}(g(\mathbf{x}_i;\boldsymbol\theta)),
\end{equation}\]</span>
where <span class="math inline">\(g(\mathbf{x}_i;\boldsymbol\theta)\)</span> is the parameter of the Bernoulli distribution. In other words, conditionally on <span class="math inline">\(\mathbf{X}\)</span>:
<span class="math display">\[
y_i = \left\{
\begin{array}{cl}
1 &amp; \mbox{ with probability } g(\mathbf{x}_i;\boldsymbol\theta)\\
0 &amp; \mbox{ with probability } 1-g(\mathbf{x}_i;\boldsymbol\theta),
\end{array}
\right.
\]</span>
where <span class="math inline">\(\boldsymbol\theta\)</span> is a vector of parameters to be estimated.</p>
<p>The objective is to estimate the vector of population parameters <span class="math inline">\(\boldsymbol\theta\)</span>.</p>
<p>Binary-choice models can be used to account for…</p>
<ul>
<li>any binary decisions (e.g. in referendums, being owner or renter, living in the city or in the countryside, in/out of the labour force,…),</li>
<li>contamination (disease or default),</li>
<li>success/failure (exams).</li>
</ul>
<p>A possibility is to run a linear regression (a situation called <strong>Linear Probability Model, LPM</strong>):
<span class="math display">\[
y_i = \boldsymbol\theta'\mathbf{x}_i + \varepsilon_i.
\]</span></p>
<p>Such a regression could be consistent with the <em>conditional-mean-zero assumption</em> (Hypothesis <a href="#hyp:exogeneity"><strong>??</strong></a>) and with the <em>assumption of non-correlated residuals</em> (Hypothesis <a href="#hyp:noncorrelResid"><strong>??</strong></a>), but more difficultly with the <strong>homoskedasticity assumption</strong> (Hypothesis <a href="#hyp:homoskedasticity"><strong>??</strong></a>). Moreover, the <span class="math inline">\(\varepsilon_i\)</span>s cannot be Gaussian (because <span class="math inline">\(y_i \in \{0,1\}\)</span>). Therefore, using a linear regression to study the relationship between <span class="math inline">\(\mathbf{x}_i\)</span> and <span class="math inline">\(y_i\)</span> can be consistent but it is inefficient.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:LPM"></span>
<img src="AdvECTS_files/figure-html/LPM-1.png" alt="Fitting a binary variable with a linear model (Linear Probability Model, LPM). The model is $\mathbb{P}(y_i=1|x_i)=\Phi(0.5+2x_i)$, where $\Phi$ is the c.d.f. of the normal distribution and where $x_i \sim \,i.i.d.\,\mathcal{N}(0,1)$." width="90%"><p class="caption">
Figure 3.1: Fitting a binary variable with a linear model (Linear Probability Model, LPM). The model is <span class="math inline">\(\mathbb{P}(y_i=1|x_i)=\Phi(0.5+2x_i)\)</span>, where <span class="math inline">\(\Phi\)</span> is the c.d.f. of the normal distribution and where <span class="math inline">\(x_i \sim \,i.i.d.\,\mathcal{N}(0,1)\)</span>.
</p>
</div>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:foo">Table 3.1: </span> This table provides examples of function <span class="math inline">\(g\)</span>, s.t. <span class="math inline">\(\mathbb{P}(y_i=1|\mathbf{x}_i;\boldsymbol heta) = g(\boldsymbol\theta'\mathbf{x}_i)\)</span>. The “linear” case is given for comparison, but note that it does not satisfy <span class="math inline">\(g(\boldsymbol\theta'\mathbf{x}_i)\)</span> for any value of <span class="math inline">\(\boldsymbol\theta'\mathbf{x}_i\)</span>.</caption>
<colgroup>
<col width="6%">
<col width="69%">
<col width="23%">
</colgroup>
<thead><tr class="header">
<th>Model</th>
<th>Function <span class="math inline">\(g\)</span>
</th>
<th>Derivative</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Probit</td>
<td><span class="math inline">\(\Phi\)</span></td>
<td><span class="math inline">\(\phi\)</span></td>
</tr>
<tr class="even">
<td>Logit</td>
<td><span class="math inline">\(\dfrac{\exp(x)}{1+\exp(x)}\)</span></td>
<td><span class="math inline">\(\dfrac{\exp(x)}{(1+\exp(x))^2}\)</span></td>
</tr>
<tr class="odd">
<td>log-log</td>
<td><span class="math inline">\(1 - \exp(-\exp(x))\)</span></td>
<td><span class="math inline">\(\exp(-\exp(x))\exp(x)\)</span></td>
</tr>
<tr class="even">
<td>linear</td>
<td><span class="math inline">\(x\)</span></td>
<td>1</td>
</tr>
</tbody>
</table></div>
<p>Two prominent models to tackle this situation. In both models, we have:
<span class="math display">\[
\mathbb{P}(y_i=1|\mathbf{x}_i;\boldsymbol\theta)=g(\boldsymbol\theta'\mathbf{x}_i).
\]</span></p>
<p>In the <strong>Probit model</strong>, we have
<span class="math display" id="eq:probit">\[\begin{equation}
g(z) = \Phi(z),\tag{3.1}
\end{equation}\]</span>
where <span class="math inline">\(\Phi\)</span> is the c.d.f. of the normal distribution.</p>
<p>And for the <strong>logit model</strong>:
<span class="math display" id="eq:logit">\[\begin{equation}
g(z) = \frac{1}{1+\exp(-z)}.\tag{3.2}
\end{equation}\]</span></p>
<p>Figure <a href="microeconometrics.html#fig:ProbLogit">3.2</a> displays the functions <span class="math inline">\(g\)</span> appearing in Table <a href="microeconometrics.html#tab:foo">3.1</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ProbLogit"></span>
<img src="AdvECTS_files/figure-html/ProbLogit-1.png" alt="Probit, Logit, and Log-log functions." width="90%"><p class="caption">
Figure 3.2: Probit, Logit, and Log-log functions.
</p>
</div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:LPM2"></span>
<img src="AdvECTS_files/figure-html/LPM2-1.png" alt="The model is $\mathbb{P}(y_i=1|x_i)=\Phi(0.5+2x_i)$, where $\Phi$ is the c.d.f. of the normal distribution and where $x_i \sim \,i.i.d.\,\mathcal{N}(0,1)$. Crosses give the model-implied probabilities of having $y_i=1$." width="90%"><p class="caption">
Figure 3.3: The model is <span class="math inline">\(\mathbb{P}(y_i=1|x_i)=\Phi(0.5+2x_i)\)</span>, where <span class="math inline">\(\Phi\)</span> is the c.d.f. of the normal distribution and where <span class="math inline">\(x_i \sim \,i.i.d.\,\mathcal{N}(0,1)\)</span>. Crosses give the model-implied probabilities of having <span class="math inline">\(y_i=1\)</span>.
</p>
</div>
<div id="interpretation-in-terms-of-latent-variable-and-utility-based-models" class="section level3" number="3.1.1">
<h3>
<span class="header-section-number">3.1.1</span> Interpretation in terms of latent variable, and utility-based models<a class="anchor" aria-label="anchor" href="#interpretation-in-terms-of-latent-variable-and-utility-based-models"><i class="fas fa-link"></i></a>
</h3>
<p>The probit model has an interpretation in terms of <strong>latent variables</strong>. In this model, we indeed have:
<span class="math display">\[
\mathbb{P}(y_i=1|\mathbf{x}_i;\boldsymbol\theta) = \Phi(\boldsymbol\theta'\mathbf{x}_i) = \mathbb{P}(-\varepsilon_{i}&lt;\boldsymbol\theta'\mathbf{x}_i),
\]</span>
where <span class="math inline">\(\varepsilon_{i} \sim \mathcal{N}(0,1)\)</span>. That is:
<span class="math display">\[
\mathbb{P}(y_i=1|\mathbf{x}_i;\boldsymbol\theta) = \mathbb{P}(0&lt; y_i^*),
\]</span>
where <span class="math inline">\(y_i^* = \boldsymbol\theta'\mathbf{x}_i + \varepsilon_i\)</span>, with <span class="math inline">\(\varepsilon_{i} \sim \mathcal{N}(0,1)\)</span>. Variable <span class="math inline">\(y_i^*\)</span> can be interpreted as a (latent) variable that determines <span class="math inline">\(y_i\)</span> since <span class="math inline">\(y_i = \mathbb{I}_{\{y_i^*&gt;0\}}\)</span>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:Latent"></span>
<img src="AdvECTS_files/figure-html/Latent-1.png" alt="Distribution of $y_i^*$ conditional on $\bv{x}_i$." width="90%"><p class="caption">
Figure 3.4: Distribution of <span class="math inline">\(y_i^*\)</span> conditional on <span class="math inline">\(\mathbf{x}_i\)</span>.
</p>
</div>
<p><strong>Random Utility Models (RUM)</strong> are based on such a view of probit models. Assume that agent (<span class="math inline">\(i\)</span>) chooses <span class="math inline">\(y_i=1\)</span> if the utility associated with this choice (<span class="math inline">\(U_{i,1}\)</span>) is higher than the one associated with <span class="math inline">\(y_i=0\)</span> (<span class="math inline">\(U_{i,0}\)</span>). Assume further that the utility of agent <span class="math inline">\(i\)</span>, if she chooses outcome <span class="math inline">\(j\)</span> (<span class="math inline">\(\in \{0,1\}\)</span>), is given by
<span class="math display">\[
U_{i,j} = V_{i,j} + \varepsilon_{i,j},
\]</span>
where <span class="math inline">\(V_{i,j}\)</span> is the deterministic component of the utility associated with choice and <span class="math inline">\(\varepsilon_{i,j}\)</span> is a random (agent-specific) component.</p>
<p>Moreover, posit <span class="math inline">\(V_{i,j} = \boldsymbol\theta_j'\mathbf{x}_i\)</span>. We then have:
<span class="math display" id="eq:utility">\[\begin{eqnarray}
\mathbb{P}(y_i = 1|\mathbf{x}_i;\boldsymbol\theta) &amp;=&amp; \mathbb{P}(\boldsymbol\theta_1'\mathbf{x}_i+\varepsilon_{i,1}&gt;\boldsymbol\theta_0'\mathbf{x}_i+\varepsilon_{i,0}) \nonumber\\
&amp;=&amp; F(\boldsymbol\theta_1'\mathbf{x}_i-\boldsymbol\theta_0'\mathbf{x}_i) = F([\boldsymbol\theta_1-\boldsymbol\theta_0]'\mathbf{x}_i),\tag{3.3}
\end{eqnarray}\]</span>
where <span class="math inline">\(F\)</span> is the c.d.f. of <span class="math inline">\(\varepsilon_{i,0}-\varepsilon_{i,1}\)</span>.</p>
<p>Note that only the difference <span class="math inline">\(\boldsymbol\theta_1-\boldsymbol\theta_0\)</span> is identifiable (as opposed to <span class="math inline">\(\boldsymbol\theta_1\)</span> AND <span class="math inline">\(\boldsymbol\theta_0\)</span>). Indeed, replacing <span class="math inline">\(U\)</span> with <span class="math inline">\(aU\)</span> (<span class="math inline">\(a&gt;0\)</span>) gives the same model <span class="math inline">\(\Leftrightarrow\)</span> scaling issue, solved by fixing the variance of <span class="math inline">\(\varepsilon_{i,0}-\varepsilon_{i,1}\)</span>.</p>
<p>Other types of structural models –based on the comparison of marginal costs and benefits– give rise to the existence of latent variable and to probit models. An example is <span class="citation">Nakosteen and Zimmer (<a href="references.html#ref-Nakosteen_Zimmer_1980" role="doc-biblioref">1980</a>)</span>. The main ingredients of their approach are as follows:</p>
<ul>
<li><p>Wage that can be earned at the present location: <span class="math inline">\(y_p^* = \boldsymbol\theta_p'\mathbf{x}_p + \varepsilon_p\)</span>.</p></li>
<li><p>Migration cost: <span class="math inline">\(C^*= \boldsymbol\theta_c'\mathbf{x}_c + \varepsilon_c\)</span>.</p></li>
<li><p>Wage earned elsewhere: <span class="math inline">\(y_m^* = \boldsymbol\theta_m'\mathbf{x}_m + \varepsilon_m\)</span>.</p></li>
</ul>
<p>In this context, agents decision to migrate if <span class="math inline">\(y_m^* &gt; y_p^* + C^*\)</span>, i.e. if
<span class="math display">\[
y^* = y_m^* -  y_p^* - C^* =  \boldsymbol\theta'\mathbf{x} + \underbrace{\varepsilon}_{=\varepsilon_m - \varepsilon_c - \varepsilon_p}&gt;0,
\]</span>
where <span class="math inline">\(\mathbf{x}\)</span> is the union of the <span class="math inline">\(\mathbf{x}_i\)</span>s, for <span class="math inline">\(i \in \{p,m,c\}\)</span>.</p>
</div>
<div id="Avregressors" class="section level3" number="3.1.2">
<h3>
<span class="header-section-number">3.1.2</span> Alternative-Varying Regressors<a class="anchor" aria-label="anchor" href="#Avregressors"><i class="fas fa-link"></i></a>
</h3>
<p>In some cases, the regressors may depend on the considered alternative (<span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span>). For instance:</p>
<ul>
<li><p>When modeling the decision to participate in the labour force (or not), the wage depends on the alternative. It cannot be included among the regressors given it is not observed if the considered agent has decided not to work.</p></li>
<li><p>In the context of the choice of transportation mode, the <em>time cost</em> depends on the considered transportation mode.</p></li>
</ul>
<p>In terms of utility, we then have:
<span class="math display">\[
V_{i,j} = {\theta^{(u)}_{j}}'\mathbf{u}_{i,j} + {\theta^{(v)}_{j}}'\mathbf{v}_{i},
\]</span>
where the <span class="math inline">\(\mathbf{u}_{i,j}\)</span>s are regressors associated with agent <span class="math inline">\(i\)</span>, but taking different values for the different choices (<span class="math inline">\(j=0\)</span> or <span class="math inline">\(j=1\)</span>).</p>
<p>In that case, Eq. <a href="microeconometrics.html#eq:utility">(3.3)</a> becomes:
<span class="math display" id="eq:utility2">\[\begin{equation}
\mathbb{P}(y_i = 1|\mathbf{x}_i;\boldsymbol\theta)  = F\left({\theta^{(u)}_{1}}'\mathbf{u}_{i,1}-{\theta^{(u)}_{0}}'\mathbf{u}_{i,0}+[\boldsymbol\theta_1^{(v)}-\boldsymbol\theta_0^{(v)}]'\mathbf{v}_i\right),\tag{3.4}
\end{equation}\]</span>
and, if <span class="math inline">\(\theta^{(u)}_{1}=\theta^{(u)}_{0}=\theta^{(u)}\)</span> –as is customary– we get:
<span class="math display" id="eq:utility3">\[\begin{equation}
\mathbb{P}(y_i = 1|\mathbf{x}_i;\boldsymbol\theta)  = F\left({\theta^{(u)}_{1}}'(\mathbf{u}_{i,1}-\mathbf{u}_{i,0})+[\boldsymbol\theta_1^{(v)}-\boldsymbol\theta_0^{(v)}]'\mathbf{v}_i\right).\tag{3.5}
\end{equation}\]</span></p>
<p>The fishing-mode dataset used in <span class="citation">Cameron and Trivedi (<a href="references.html#ref-Cameron_Trivedi_2005" role="doc-biblioref">2005</a>)</span> (Chapter 14 and 15) contains alternative-specific variables. Specifically, for each individual, the price and catch rate depend on the fishing model. In the table reported below, lines <code>price</code> and <code>catch</code> correspond to the prices and catch rates associated with the chosen alternative.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://www.r-project.org">Ecdat</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">Fishing</span><span class="op">)</span></span>
<span><span class="fu">stargazer</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/stargazer/man/stargazer.html">stargazer</a></span><span class="op">(</span><span class="va">Fishing</span>,type<span class="op">=</span><span class="st">"text"</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## ======================================================
## Statistic   N     Mean    St. Dev.    Min      Max    
## ------------------------------------------------------
## price     1,182  52.082    53.830    1.290   666.110  
## catch     1,182   0.389     0.561   0.0002    2.310   
## pbeach    1,182  103.422   103.641   1.290   843.186  
## ppier     1,182  103.422   103.641   1.290   843.186  
## pboat     1,182  55.257    62.713    2.290   666.110  
## pcharter  1,182  84.379    63.545   27.290   691.110  
## cbeach    1,182   0.241     0.191    0.068    0.533   
## cpier     1,182   0.162     0.160    0.001    0.452   
## cboat     1,182   0.171     0.210   0.0002    0.737   
## ccharter  1,182   0.629     0.706    0.002    2.310   
## income    1,182 4,099.337 2,461.964 416.667 12,500.000
## ------------------------------------------------------</code></pre>
</div>
<div id="estimation" class="section level3" number="3.1.3">
<h3>
<span class="header-section-number">3.1.3</span> Estimation<a class="anchor" aria-label="anchor" href="#estimation"><i class="fas fa-link"></i></a>
</h3>
<p>These models can be estimated by Maximum Likelihood approaches (see Section <a href="#secMLE"><strong>??</strong></a>).</p>
<p>To simplify the exposition, we consider the <span class="math inline">\(\mathbf{x}_i\)</span> to be deterministic. Also, we assume that the r.v. are independent across entities <span class="math inline">\(i\)</span>. How to write the likelihood here? It can be seen that:
<span class="math display">\[\begin{eqnarray}
f(y_i|\mathbf{x}_i;\boldsymbol\theta) &amp;=&amp; y_i g(\boldsymbol\theta'\mathbf{x}_i) + (1-y_i) (1-g(\boldsymbol\theta'\mathbf{x}_i)) \nonumber \\
&amp;=&amp;  g(\boldsymbol\theta'\mathbf{x}_i)^{y_i}(1-g(\boldsymbol\theta'\mathbf{x}_i))^{1-y_i}.
\end{eqnarray}\]</span></p>
<p>Therefore, if the observations <span class="math inline">\((\mathbf{x}_i,y_i)\)</span> are independent across entities <span class="math inline">\(i\)</span>, then:
<span class="math display">\[
\log \mathcal{L}(\boldsymbol\theta;\mathbf{y},\mathbf{X}) = \sum_{i=1}^{n}y_i \log[g(\boldsymbol\theta'\mathbf{x}_i)] + (1-y_i)\log[1-g(\boldsymbol\theta'\mathbf{x}_i)].
\]</span></p>
<p>The likelihood equation reads (FOC of the optimization program, see Def. <a href="#def:likFunction"><strong>??</strong></a>):
<span class="math display">\[
\dfrac{\partial \log \mathcal{L}(\boldsymbol\theta;\mathbf{y},\mathbf{X})}{\partial \boldsymbol\theta} = \mathbf{0},
\]</span>
that is:
<span class="math display">\[
\sum_{i=1}^{n} y_i \mathbf{x}_i\frac{g'(\boldsymbol\theta'\mathbf{x}_i)}{g(\boldsymbol\theta'\mathbf{x}_i)} - (1-y_i) \mathbf{x}_i \frac{g'(\boldsymbol\theta'\mathbf{x}_i)}{1-g(\boldsymbol\theta'\mathbf{x}_i)} = \mathbf{0}.
\]</span></p>
<p>This is a nonlinear equation that generally has to be numerically solved. Under regularity conditions (Hypotheses <a href="#hyp:MLEregularity"><strong>??</strong></a>), we have (Prop. <a href="#prp:MLEproperties"><strong>??</strong></a>):
<span class="math display">\[
\boldsymbol\theta_{MLE} \sim \mathcal{N}(\boldsymbol\theta_0,\mathbf{I}(\boldsymbol\theta_0)^{-1}),
\]</span>
where
<span class="math display">\[
\mathbf{I}(\boldsymbol\theta_0) = - \mathbb{E}_0 \left( \frac{\partial^2 \log \mathcal{L}(\theta;\mathbf{y},\mathbf{X})}{\partial \boldsymbol\theta \partial \boldsymbol\theta'}\right) = n \mathcal{I}_Y(\boldsymbol\theta_0).
\]</span></p>
<p>For finite samples, we can e.g. approximate <span class="math inline">\(\mathbf{I}(\boldsymbol\theta_0)^{-1}\)</span> by (Eq. <a href="#eq:III1">(<strong>??</strong>)</a>):
<span class="math display">\[
\mathbf{I}(\boldsymbol\theta_0)^{-1} \approx -\left(\frac{\partial^2 \log \mathcal{L}(\boldsymbol\theta_{MLE};\mathbf{y},\mathbf{X})}{\partial \boldsymbol\theta \partial \boldsymbol\theta'}\right)^{-1}.
\]</span></p>
<p>In the Probit case (see Table <a href="microeconometrics.html#tab:foo">3.1</a>), it can be shown that we have:
<span class="math display">\[\begin{eqnarray*}
&amp;&amp;\frac{\partial^2 \log \mathcal{L}(\boldsymbol\theta;\mathbf{y},\mathbf{X})}{\partial \boldsymbol\theta \partial \boldsymbol\theta'} = - \sum_{i=1}^{n} g'(\boldsymbol\theta'\mathbf{x}_i) [\mathbf{x}_i \mathbf{x}_i'] \times \\
&amp;&amp;\left[y_i \frac{g'(\boldsymbol\theta'\mathbf{x}_i) + \boldsymbol\theta'\mathbf{x}_ig(\boldsymbol\theta'\mathbf{x}_i)}{g(\boldsymbol\theta'\mathbf{x}_i)^2} + (1-y_i) \frac{g'(\boldsymbol\theta'\mathbf{x}_i) - \boldsymbol\theta'\mathbf{x}_i (1 - g(\boldsymbol\theta'\mathbf{x}_i))}{(1-g(\boldsymbol\theta'\mathbf{x}_i))^2}\right].
\end{eqnarray*}\]</span></p>
<p>In the Logit case (see Table <a href="microeconometrics.html#tab:foo">3.1</a>), it can be shown that we have:
<span class="math display">\[
\frac{\partial^2 \log \mathcal{L}(\boldsymbol\theta;\mathbf{y},\mathbf{X})}{\partial \boldsymbol\theta \partial \boldsymbol\theta'} = - \sum_{i=1}^{n} g'(\boldsymbol\theta'\mathbf{x}_i) \mathbf{x}_i\mathbf{x}_i',
\]</span>
where <span class="math inline">\(g'(x)=\dfrac{\exp(-x)}{(1 + \exp(-x))^2}\)</span>.</p>
<p>Since <span class="math inline">\(g'(x)&gt;0\)</span>, it can be checked that <span class="math inline">\(-\partial^2 \log \mathcal{L}(\boldsymbol\theta;\mathbf{y},\mathbf{X})/\partial \boldsymbol\theta \partial \boldsymbol\theta'\)</span> is positive definite.</p>
</div>
<div id="marginal-effectss" class="section level3" number="3.1.4">
<h3>
<span class="header-section-number">3.1.4</span> Marginal effectss<a class="anchor" aria-label="anchor" href="#marginal-effectss"><i class="fas fa-link"></i></a>
</h3>
<p>How to measure marginal effects, i.e. the effect on the probability that <span class="math inline">\(y_i=1\)</span> of a marginal increase of <span class="math inline">\(x_{i,k}\)</span>? This object is given by:
<span class="math display">\[
\frac{\partial \mathbb{P}(y_i=1|\mathbf{x_i};\boldsymbol\theta)}{\partial x_{i,k}} = \underbrace{g'(\boldsymbol\theta'\mathbf{x}_i)}_{&gt;0}\theta_k,
\]</span>
which is of the same sign as <span class="math inline">\(\theta_k\)</span>.</p>
<p>It can be estimated by <span class="math inline">\(g'(\boldsymbol\theta_{MLE}'\mathbf{x}_i)\theta_{MLE,k}\)</span>. It is important to see that the marginal effect depends on <span class="math inline">\(\mathbf{x}_i\)</span>: increases by 1 unit of <span class="math inline">\(x_{i,k}\)</span> (entity <span class="math inline">\(i\)</span>) and of <span class="math inline">\(x_{j,k}\)</span> (entity <span class="math inline">\(j\)</span>) do not necessarily have the same effects on <span class="math inline">\(\mathbb{P}(y_i=1|\mathbf{x_i};\boldsymbol\theta)\)</span> and on <span class="math inline">\(\mathbb{P}(y_j=1|\mathbf{x_j};\boldsymbol\theta)\)</span>, respectively.</p>
<p>To address this issue, one can compute some measures of “average” marginal effect. There are two main solutions. For each explanatory variable <span class="math inline">\(k\)</span>:</p>
<ol style="list-style-type: lower-roman">
<li><p>Denoting by <span class="math inline">\(\hat{\mathbf{x}}\)</span> the sample average of the <span class="math inline">\(\mathbf{x}_i\)</span>s, compute <span class="math inline">\(g'(\boldsymbol\theta_{MLE}'\hat{\mathbf{x}})\theta_{MLE,k}\)</span>.</p></li>
<li><p>Compute the average (across <span class="math inline">\(i\)</span>) of <span class="math inline">\(g'(\boldsymbol\theta_{MLE}'\mathbf{x}_i)\theta_{MLE,k}\)</span>.</p></li>
</ol>
</div>
<div id="goodness-of-fit" class="section level3" number="3.1.5">
<h3>
<span class="header-section-number">3.1.5</span> Goodness of fit<a class="anchor" aria-label="anchor" href="#goodness-of-fit"><i class="fas fa-link"></i></a>
</h3>
<p>There is no obvious version of “<span class="math inline">\(R^2\)</span>” for binary-choice models. Existing measures are called <strong>pseudo-<span class="math inline">\(R^2\)</span>} measures</strong>.</p>
<p>Denoting by <span class="math inline">\(\log \mathcal{L}_0(\mathbf{y})\)</span> the (maximum) log-likelihood that would be obtained for a model containing only a constant term (i.e. with <span class="math inline">\(\mathbf{x}_i = 1\)</span> for all <span class="math inline">\(i\)</span>), the <strong>McFadden’s pseudo-<span class="math inline">\(R^2\)</span></strong> is given by:
<span class="math display">\[
R^2_{MF} = 1 - \frac{\log \mathcal{L}(\boldsymbol\theta;\mathbf{y})}{\log \mathcal{L}_0(\mathbf{y})}.
\]</span>
Intuitively, <span class="math inline">\(R^2_{MF}=0\)</span> if the explanatory variables do not allow to predict the decision (<span class="math inline">\(y\)</span>).</p>
</div>
<div id="example-credit-data" class="section level3" number="3.1.6">
<h3>
<span class="header-section-number">3.1.6</span> Example: Credit data<a class="anchor" aria-label="anchor" href="#example-credit-data"><i class="fas fa-link"></i></a>
</h3>
<p>This example makes use of the <code>credit</code> data of package <code>AEC</code>. The objective is to model the default probabilities of lenders.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">AEC</span><span class="op">)</span></span>
<span><span class="va">credit</span><span class="op">$</span><span class="va">Default</span> <span class="op">&lt;-</span> <span class="fl">0</span></span>
<span><span class="va">credit</span><span class="op">$</span><span class="va">Default</span><span class="op">[</span><span class="va">credit</span><span class="op">$</span><span class="va">loan_status</span> <span class="op">==</span> <span class="st">"Charged Off"</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fl">1</span></span>
<span><span class="va">credit</span><span class="op">$</span><span class="va">Default</span><span class="op">[</span><span class="va">credit</span><span class="op">$</span><span class="va">loan_status</span> <span class="op">==</span> <span class="st">"Does not meet the credit policy. Status:Charged Off"</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fl">1</span></span>
<span><span class="va">credit</span><span class="op">$</span><span class="va">amt2income</span> <span class="op">&lt;-</span> <span class="va">credit</span><span class="op">$</span><span class="va">loan_amnt</span><span class="op">/</span><span class="va">credit</span><span class="op">$</span><span class="va">annual_inc</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">credit</span><span class="op">$</span><span class="va">Default</span><span class="op">)</span><span class="op">~</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">credit</span><span class="op">$</span><span class="va">annual_inc</span><span class="op">)</span>,</span>
<span>     ylevels<span class="op">=</span><span class="fl">2</span><span class="op">:</span><span class="fl">1</span>,ylab<span class="op">=</span><span class="st">"Default status"</span>,xlab<span class="op">=</span><span class="st">"log(annual income)"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="AdvECTS_files/figure-html/Probitlending-1.png" width="672"></div>
<p>We consider three specifications. The first one, with no explanatory variables, is trivial. It will just be used to compute the pseudo-<span class="math inline">\(R^2\)</span>.</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">eq0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">Default</span> <span class="op">~</span> <span class="fl">1</span>,data<span class="op">=</span><span class="va">credit</span>,family<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span>link<span class="op">=</span><span class="st">"probit"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">eq1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">Default</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">loan_amnt</span><span class="op">)</span> <span class="op">+</span> <span class="va">amt2income</span> <span class="op">+</span> <span class="va">delinq_2yrs</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">annual_inc</span><span class="op">)</span><span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">annual_inc</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>,</span>
<span>                 data<span class="op">=</span><span class="va">credit</span>,family<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span>link<span class="op">=</span><span class="st">"probit"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">eq2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">Default</span> <span class="op">~</span> <span class="va">grade</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">loan_amnt</span><span class="op">)</span> <span class="op">+</span> <span class="va">amt2income</span> <span class="op">+</span> <span class="va">delinq_2yrs</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">annual_inc</span><span class="op">)</span><span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">annual_inc</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>,</span>
<span>                 data<span class="op">=</span><span class="va">credit</span>,family<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span>link<span class="op">=</span><span class="st">"probit"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">logL0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/logLik.html">logLik</a></span><span class="op">(</span><span class="va">eq0</span><span class="op">)</span></span>
<span><span class="va">logL1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/logLik.html">logLik</a></span><span class="op">(</span><span class="va">eq1</span><span class="op">)</span></span>
<span><span class="va">logL2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/logLik.html">logLik</a></span><span class="op">(</span><span class="va">eq2</span><span class="op">)</span></span>
<span><span class="fl">1</span> <span class="op">-</span> <span class="va">logL1</span><span class="op">/</span><span class="va">logL0</span> <span class="co"># pseudo R2</span></span></code></pre></div>
<pre><code>## 'log Lik.' 0.01173993 (df=6)</code></pre>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fl">1</span> <span class="op">-</span> <span class="va">logL2</span><span class="op">/</span><span class="va">logL0</span> <span class="co"># pseudo R2</span></span></code></pre></div>
<pre><code>## 'log Lik.' 0.0558487 (df=12)</code></pre>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">stargazer</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/stargazer/man/stargazer.html">stargazer</a></span><span class="op">(</span><span class="va">eq0</span>,<span class="va">eq1</span>,<span class="va">eq2</span>,type<span class="op">=</span><span class="st">"text"</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## ====================================================
##                           Dependent variable:       
##                     --------------------------------
##                                 Default             
##                        (1)        (2)        (3)    
## ----------------------------------------------------
## gradeB                                     0.400*** 
##                                            (0.055)  
##                                                     
## gradeC                                     0.587*** 
##                                            (0.057)  
##                                                     
## gradeD                                     0.820*** 
##                                            (0.061)  
##                                                     
## gradeE                                     0.874*** 
##                                            (0.091)  
##                                                     
## gradeF                                     1.230*** 
##                                            (0.147)  
##                                                     
## gradeG                                     1.439*** 
##                                            (0.227)  
##                                                     
## log(loan_amnt)                  -0.149**  -0.194*** 
##                                 (0.060)    (0.061)  
##                                                     
## amt2income                      1.266***   1.222*** 
##                                 (0.383)    (0.393)  
##                                                     
## delinq_2yrs                     0.096***    0.009   
##                                 (0.034)    (0.035)  
##                                                     
## log(annual_inc)                 -1.444**    -0.874  
##                                 (0.569)    (0.586)  
##                                                     
## I(log(annual_inc)2)             0.064**     0.038   
##                                 (0.025)    (0.026)  
##                                                     
## Constant            -1.231***   7.937***    4.749   
##                      (0.017)    (3.060)    (3.154)  
##                                                     
## ----------------------------------------------------
## Observations          9,156      9,156      9,156   
## Log Likelihood      -3,157.696 -3,120.625 -2,981.343
## Akaike Inf. Crit.   6,317.392  6,253.250  5,986.686 
## ====================================================
## Note:                    *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
<p>Let us now compute marginal effects.</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">eq2</span><span class="op">)</span><span class="op">)</span>,na.rm<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span><span class="op">*</span><span class="va">eq2</span><span class="op">$</span><span class="va">coefficients</span></span></code></pre></div>
<pre><code>##          (Intercept)               gradeB               gradeC 
##          0.840731198          0.070747353          0.103944305 
##               gradeD               gradeE               gradeF 
##          0.145089219          0.154773742          0.217702041 
##               gradeG       log(loan_amnt)           amt2income 
##          0.254722161         -0.034289921          0.216251992 
##          delinq_2yrs      log(annual_inc) I(log(annual_inc)^2) 
##          0.001574178         -0.154701321          0.006813694</code></pre>
<p>There is, however, an issue for the <code>annual_inc</code> variable. Indeed, the previous computation does not realize that this variable appears twice among the explanatory variables. To address this, one can proceed as follows.</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">new_credit</span> <span class="op">&lt;-</span> <span class="va">credit</span></span>
<span><span class="va">new_credit</span><span class="op">$</span><span class="va">annual_inc</span> <span class="op">&lt;-</span> <span class="fl">1.01</span> <span class="op">*</span> <span class="va">new_credit</span><span class="op">$</span><span class="va">annual_inc</span> <span class="co"># increase of income by 1%</span></span>
<span><span class="va">bas_predict_eq2</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">eq2</span>, newdata <span class="op">=</span> <span class="va">credit</span>, type <span class="op">=</span> <span class="st">"response"</span><span class="op">)</span></span>
<span><span class="co"># This is equivalent to pnorm(predict(eq2, newdata = credit))</span></span>
<span><span class="va">new_predict_eq2</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">eq2</span>, newdata <span class="op">=</span> <span class="va">new_credit</span>, type <span class="op">=</span> <span class="st">"response"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">new_predict_eq2</span> <span class="op">-</span> <span class="va">bas_predict_eq2</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] -6.562126e-05</code></pre>
<p>This average effect is pretty low. To compare, let us compute the average effect associated with a unit increase in the number of delinquencies:</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">new_credit</span> <span class="op">&lt;-</span> <span class="va">credit</span></span>
<span><span class="va">new_credit</span><span class="op">$</span><span class="va">delinq_2yrs</span> <span class="op">&lt;-</span> <span class="va">credit</span><span class="op">$</span><span class="va">delinq_2yrs</span> <span class="op">+</span> <span class="fl">1</span></span>
<span><span class="va">new_predict_eq2</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">eq2</span>, newdata <span class="op">=</span> <span class="va">new_credit</span>, type <span class="op">=</span> <span class="st">"response"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">new_predict_eq2</span> <span class="op">-</span> <span class="va">bas_predict_eq2</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 0.001582332</code></pre>
<p>We can employ a likelihood ratio test (see Def. <a href="#def:LR"><strong>??</strong></a>) to see if the two variables associated with annual income are jointly statistically significant (in the context of <code>eq1</code>):</p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">eq1restr</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">Default</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">loan_amnt</span><span class="op">)</span> <span class="op">+</span> <span class="va">amt2income</span> <span class="op">+</span> <span class="va">delinq_2yrs</span>,</span>
<span>                 data<span class="op">=</span><span class="va">credit</span>,family<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span>link<span class="op">=</span><span class="st">"probit"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">LRstat</span> <span class="op">&lt;-</span> <span class="fl">2</span><span class="op">*</span><span class="op">(</span><span class="va">logL1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/logLik.html">logLik</a></span><span class="op">(</span><span class="va">eq1restr</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">pvalue</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">pchisq</a></span><span class="op">(</span><span class="va">LRstat</span>,df<span class="op">=</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>The computation gives a p-value of 0.0436.</p>
<!-- \begin{frame} -->
<!-- \begin{scriptsize} -->
<!-- \begin{exmpl}[Labor market participation] -->
<!-- \input{../../../../../Google Drive/Teaching/UNIL/Rcode/tables/outfile_SwissLabor.txt} -->
<!-- \begin{center} -->
<!-- \begin{tiny} -->
<!-- Source: \href{http://onlinelibrary.wiley.com/doi/10.1002/(SICI)1099-1255(199605)11:3\%3C321::AID-JAE391\%3E3.0.CO;2-K/abstract}{Gerfin (1996)}. -->
<!-- \end{tiny} -->
<!-- \end{center} -->
<!-- Marginal effects: -->
<!-- income: $-0.22$, age: $0.69$, education: $0.006$, youngkids: $-0.24$, oldkids: $-0.05$, foreignyes: $0.24$, age2: $-0.10$. -->
<!-- \end{exmpl} -->
<!-- \end{scriptsize} -->
<!-- \end{frame} -->
<!-- \begin{frame} -->
<!-- \begin{scriptsize} -->
<!-- \addtocounter{exmpl}{-1} -->
<!-- \begin{exmpl}[Labor market participation (cont'd)] -->
<!--        \begin{figure} -->
<!--        \caption{Labor market participation vs. age and education} -->
<!--            \includegraphics[width=1\linewidth]{../../../../../Google Drive/Teaching/UNIL/Figures/Figure_Probit4.pdf} -->
<!--        \begin{tiny} -->
<!--        \end{tiny} -->
<!--        \end{figure} -->
<!-- \end{exmpl} -->
<!-- \end{scriptsize} -->
<!-- \end{frame} -->
<!-- \begin{frame} -->
<!-- \begin{scriptsize} -->
<!-- \addtocounter{exmpl}{-1} -->
<!-- \begin{exmpl}[Leverage Bubbles] -->
<!-- \begin{figure} -->
<!--        \caption{Logit estimations} -->
<!--            \includegraphics[width=.75\linewidth]{../figures/Figure_Table_JordaSchularickTaylor.pdf} -->
<!-- \begin{center} -->
<!-- \begin{tiny} -->
<!-- Source: \href{https://www.sciencedirect.com/science/article/abs/pii/S0304393215000987}{J\'orda, Schularick and Taylor (2015)}/ \href{https://www.frbsf.org/economic-research/files/wp2015-10.pdf}{Working paper version}/ \href{http://www.macrohistory.net/data/}{Dataset}. -->
<!-- \end{tiny} -->
<!-- \end{center} -->
<!-- \end{figure} -->
<!-- \end{exmpl} -->
<!-- \end{scriptsize} -->
<!-- \end{frame} -->
</div>
<div id="replicating-table-14.2-of-cameron-and-trivedi-2005" class="section level3" number="3.1.7">
<h3>
<span class="header-section-number">3.1.7</span> Replicating Table 14.2 of Cameron and Trivedi (2005)<a class="anchor" aria-label="anchor" href="#replicating-table-14.2-of-cameron-and-trivedi-2005"><i class="fas fa-link"></i></a>
</h3>
<p>The following lines of codes replicate Table 14.2 of <span class="citation">Cameron and Trivedi (<a href="references.html#ref-Cameron_Trivedi_2005" role="doc-biblioref">2005</a>)</span>.</p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">data.reduced</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/subset.html">subset</a></span><span class="op">(</span><span class="va">Fishing</span>,<span class="va">mode</span> <span class="op"><a href="https://rdrr.io/r/base/match.html">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"charter"</span>,<span class="st">"pier"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">data.reduced</span><span class="op">$</span><span class="va">lnrelp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">data.reduced</span><span class="op">$</span><span class="va">pcharter</span><span class="op">/</span><span class="va">data.reduced</span><span class="op">$</span><span class="va">ppier</span><span class="op">)</span></span>
<span><span class="va">data.reduced</span><span class="op">$</span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">*</span><span class="op">(</span><span class="va">data.reduced</span><span class="op">$</span><span class="va">mode</span><span class="op">==</span><span class="st">"charter"</span><span class="op">)</span></span>
<span><span class="co"># check first line of Table 14.1:</span></span>
<span><span class="va">price.charter.y0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">data.reduced</span><span class="op">$</span><span class="va">pcharter</span><span class="op">[</span><span class="va">data.reduced</span><span class="op">$</span><span class="va">y</span><span class="op">==</span><span class="fl">0</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="va">price.charter.y1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">data.reduced</span><span class="op">$</span><span class="va">pcharter</span><span class="op">[</span><span class="va">data.reduced</span><span class="op">$</span><span class="va">y</span><span class="op">==</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="va">price.charter</span>    <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">data.reduced</span><span class="op">$</span><span class="va">pcharter</span><span class="op">)</span></span>
<span><span class="co"># Run probit regression:</span></span>
<span><span class="va">reg.probit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">lnrelp</span>,</span>
<span>                  data<span class="op">=</span><span class="va">data.reduced</span>,</span>
<span>                  family<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span>link<span class="op">=</span><span class="st">"probit"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># Run Logit regression:</span></span>
<span><span class="va">reg.logit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">lnrelp</span>,</span>
<span>                 data<span class="op">=</span><span class="va">data.reduced</span>,</span>
<span>                 family<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span>link<span class="op">=</span><span class="st">"logit"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># Run OLS regression:</span></span>
<span><span class="va">reg.OLS</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">lnrelp</span>,</span>
<span>              data<span class="op">=</span><span class="va">data.reduced</span><span class="op">)</span></span>
<span><span class="co"># Replicates Table 14.2 of Cameron and Trivedi:</span></span>
<span><span class="fu">stargazer</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/stargazer/man/stargazer.html">stargazer</a></span><span class="op">(</span><span class="va">reg.logit</span>, <span class="va">reg.probit</span>, <span class="va">reg.OLS</span>,</span>
<span>                     type<span class="op">=</span><span class="st">"text"</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## ================================================================
##                                 Dependent variable:             
##                     --------------------------------------------
##                                          y                      
##                     logistic   probit             OLS           
##                        (1)       (2)              (3)           
## ----------------------------------------------------------------
## lnrelp              -1.823*** -1.056***        -0.243***        
##                      (0.145)   (0.075)          (0.010)         
##                                                                 
## Constant            2.053***  1.194***          0.784***        
##                      (0.169)   (0.088)          (0.013)         
##                                                                 
## ----------------------------------------------------------------
## Observations           630       630              630           
## R2                                               0.463          
## Adjusted R2                                      0.462          
## Log Likelihood      -206.827  -204.411                          
## Akaike Inf. Crit.    417.654   412.822                          
## Residual Std. Error                         0.330 (df = 628)    
## F Statistic                             542.123*** (df = 1; 628)
## ================================================================
## Note:                                *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
</div>
<div id="predictions" class="section level3" number="3.1.8">
<h3>
<span class="header-section-number">3.1.8</span> Predictions<a class="anchor" aria-label="anchor" href="#predictions"><i class="fas fa-link"></i></a>
</h3>
<p>How to define predicted outcomes? As is the case for <span class="math inline">\(y_i\)</span>, predicted outcomes <span class="math inline">\(\hat{y}_i\)</span> need to be valued in <span class="math inline">\(\{0,1\}\)</span>. A natural choice consists in considering that <span class="math inline">\(\hat{y}_i=1\)</span> if <span class="math inline">\(\mathbb{P}(y_i=1|\mathbf{x}_i;\boldsymbol\theta) &gt; 0.5\)</span>, i.e., in taking a cutoff of <span class="math inline">\(c=0.5\)</span>.However, we may have some models where all predicted probabilities are small, but some less than others. In this context, a model-implied probability of 10% (say) could characterize a “high-risk” entity. However, using a cutoff of 50% would not identify this level of riskiness.</p>
<p>The <strong>receiver operating characteristics (ROC)</strong> curve consitutes a more general approach. It works as follows:</p>
<p>For each potential cutoff <span class="math inline">\(c \in [0,1]\)</span>, compute (and plot):</p>
<ul>
<li>The fraction of <span class="math inline">\(y = 1\)</span> values correctly classified (<em>True Positive Rate</em>) against</li>
<li>The fraction of <span class="math inline">\(y = 0\)</span> values incorrectly specified (<em>False Positive Rate</em>).</li>
</ul>
<p>Such a curve mechanically starts at (0,0) [situation when <span class="math inline">\(c=1\)</span>] and terminates at (1,1) [situation when <span class="math inline">\(c=0\)</span>].</p>
<p>In the case of no predictive ability (worst situation), the ROC curve is a straight line between (0,0) and (1,1).</p>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://expasy.org/tools/pROC/">pROC</a></span><span class="op">)</span></span>
<span><span class="va">predict_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.glm.html">predict.glm</a></span><span class="op">(</span><span class="va">reg.probit</span>,type <span class="op">=</span> <span class="st">"response"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/pROC/man/roc.html">roc</a></span><span class="op">(</span><span class="va">data.reduced</span><span class="op">$</span><span class="va">y</span>, <span class="va">predict_model</span>, percent<span class="op">=</span><span class="cn">T</span>,</span>
<span>    boot.n<span class="op">=</span><span class="fl">1000</span>, ci.alpha<span class="op">=</span><span class="fl">0.9</span>, stratified<span class="op">=</span><span class="cn">T</span>, plot<span class="op">=</span><span class="cn">TRUE</span>, grid<span class="op">=</span><span class="cn">TRUE</span>,</span>
<span>    show.thres<span class="op">=</span><span class="cn">TRUE</span>, legacy.axes <span class="op">=</span> <span class="cn">TRUE</span>, reuse.auc <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>    print.auc <span class="op">=</span> <span class="cn">TRUE</span>, print.thres.col <span class="op">=</span> <span class="st">"blue"</span>, ci<span class="op">=</span><span class="cn">TRUE</span>,</span>
<span>    ci.type<span class="op">=</span><span class="st">"bars"</span>, print.thres.cex <span class="op">=</span> <span class="fl">0.7</span>, col <span class="op">=</span> <span class="st">'red'</span>,</span>
<span>    main <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"ROC curve using"</span>,<span class="st">"(N = "</span>,<span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">data.reduced</span><span class="op">)</span>,<span class="st">")"</span><span class="op">)</span> <span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="AdvECTS_files/figure-html/fishing3-1.png" width="672"></div>
<pre><code>## 
## Call:
## roc.default(response = data.reduced$y, predictor = predict_model,     percent = T, ci = TRUE, plot = TRUE, boot.n = 1000, ci.alpha = 0.9,     stratified = T, grid = TRUE, show.thres = TRUE, legacy.axes = TRUE,     reuse.auc = TRUE, print.auc = TRUE, print.thres.col = "blue",     ci.type = "bars", print.thres.cex = 0.7, col = "red", main = paste("ROC curve using",         "(N = ", nrow(data.reduced), ")"))
## 
## Data: predict_model in 178 controls (data.reduced$y 0) &lt; 452 cases (data.reduced$y 1).
## Area under the curve: 91.69%
## 95% CI: 89.5%-93.87% (DeLong)</code></pre>
<!-- \begin{frame} -->
<!-- \begin{Large} -->
<!-- \begin{center} -->
<!-- -- Section \ref{section:Multiple} -- -->
<!-- \vspace{1cm} -->
<!-- Multiple Choice Models -->
<!-- \end{center} -->
<!-- \end{Large} -->
<!-- \end{frame} -->
<!-- \subsection{Context} -->
<!-- \begin{frame}\label{slide:IntroMNL} -->
<!-- \begin{scriptsize} -->
<!-- \begin{alertblock}{Context and Objectives} -->
<!-- \begin{itemize} -->
<!--    \item \textbf{Context}: -->
<!--    \begin{itemize} -->
<!--    \item The variables to be explained ($y_i$s) have a finite set of possible values (from $1$ to $J$, say). -->
<!--    \item Some variables $\bv{x}_i$ ($K \times 1$) are suspected to account for the probabilities that $y_i=j$, $j \in \{1,\dots,J\}$. -->
<!--    \item The $y_i$s are assumed to be independently distributed, with: -->
<!--    $$ -->
<!--    y_i = \left\{ -->
<!--    \begin{array}{cl} -->
<!--    1 & \mbox{ with probability } g_1(\bv{x}_i;\boldsymbol\theta)\\ -->
<!--    \vdots \\ -->
<!--    J & \mbox{ with probability } g_J(\bv{x}_i;\boldsymbol\theta), -->
<!--    \end{array} -->
<!--    \right. -->
<!--    $$ -->
<!--    where $\boldsymbol\theta$ is a vector of parameters to be estimated. -->
<!--    \item Note: For all entities ($i$), we must have: -->
<!--    $$ -->
<!--    \sum_{j=1}^J g_j(\bv{x}_i;\boldsymbol\theta)=1. -->
<!--    $$ -->
<!--    \end{itemize} -->
<!--    \item \textbf{Objective}: -->
<!--    \begin{itemize} -->
<!--    \item To estimate the vector of population parameters $\boldsymbol\theta$ given functional forms for the $g_j$s. -->
<!--    \end{itemize} -->
<!-- \end{itemize} -->
<!-- \end{alertblock} -->
<!-- \end{scriptsize} -->
<!-- \end{frame} -->
<!-- \begin{frame} -->
<!-- \begin{scriptsize} -->
<!-- \begin{exmpl} -->
<!-- Multiple-choice models can be used to account for... -->
<!-- \begin{itemize} -->
<!--    \item Opinions: strongly opposed / opposed / neutral / support (ranked choices, see Slide\,\ref{slide:ordered}), -->
<!--    \item Occupational field: lawyer / farmer / engineer / doctor / ..., -->
<!--    \item Alternative shopping areas, -->
<!--    \item Transportation types. -->
<!-- \end{itemize} -->
<!-- In a few cases, the values associated with the choices will themselves be meaningful, for example, number of accidents per day: $y = 0, 1,2, \dots$ (count data). In most cases, the values are meaningless. -->
<!-- \end{exmpl} -->
<!-- \end{scriptsize} -->
<!-- \end{frame} -->
<!-- \subsection{Ordered case} -->
<!-- \begin{frame}{The Ordered Case}\label{slide:ordered} -->
<!-- \begin{scriptsize} -->
<!-- \begin{itemize} -->
<!--    \item The {\color{blue} ordered case} is a direct extension of the binary case (Section\,\ref{section:Binary}). -->
<!--    \item In the {\color{blue} ordered multinomial case}, the dependent variable can take $J$ different values that feature a natural ordering. -->
<!--    \item Examples: income buckets, opinions ($-2$, $-1$, $0$, $+1$, $+2$, say), (credit) ratings. -->
<!-- %  \item We have: -->
<!-- %  $$ -->
<!-- %  y_{i} \in \{1,\dots,J\}. -->
<!-- %  $$ -->
<!--    \item A convenient approach consists in considering a latent variable $y_i^*$ as in Slide\,\ref{slide:latentfactor}: -->
<!--    $$ -->
<!--    y_{i}^* = \boldsymbol\theta'\bv{x}_i + \varepsilon_i, -->
<!--    $$ -->
<!--    and to assume that $\exists\, \alpha_j$, $j \in \{1,\dots,J-1\}$, s.t. $\forall (i,j) \in \mathbb{N}^+ \times \{1,\dots,J\}$: -->
<!--    \begin{eqnarray*} -->
<!--    \mathbb{P}(y_i = j | \bv{x}_i) &=& \mathbb{P}(\alpha_{j-1} <y^*_i < \alpha_{j} |\bv{x}_i) \\ -->
<!--    &=& \mathbb{P}(\alpha_{j-1} - \boldsymbol\theta'\bv{x}_i  <\varepsilon_i < \alpha_{j} - \boldsymbol\theta'\bv{x}_i) \\ -->
<!--    &=& F(\alpha_{j} - \boldsymbol\theta'\bv{x}_i) - F(\alpha_{j-1} - \boldsymbol\theta'\bv{x}_i), -->
<!--    \end{eqnarray*} -->
<!--    where $F$ is the c.d.f. of $\varepsilon_i$, $\alpha_0 = - \infty$ and $\alpha_J = + \infty$. -->
<!-- \end{itemize} -->
<!-- \end{scriptsize} -->
<!-- \end{frame} -->
<!-- \begin{frame}{The Ordered Case} -->
<!-- \begin{scriptsize} -->
<!-- \begin{itemize} -->
<!--    \item If one component of $\bv{x}_i$ ($\forall i$) is 1 (intercept), then one of the $\alpha_j$ ($j\in\{1,\dots,J-1\}$) is not identified. (One can then arbitrarily set $\alpha_1=0$, which is done in the binary logit/probit cases.) -->
<!--    \item The log-likelihood is given by Eq.\,(\ref{eq:multipleLogLik}). -->
<!--    \item We have: -->
<!--    $$ -->
<!--    \mathbb{P}(y_i \le j | \bv{x}_i) = F(\alpha_{j} - \boldsymbol\theta'\bv{x}_i) \Rightarrow \frac{\partial \mathbb{P}(y_i \le j | \bv{x}_i)}{\bv{x}_i} =- \underbrace{F'(\alpha_{j} - \boldsymbol\theta'\bv{x}_i)}_{>0}\boldsymbol\theta. -->
<!--    $$ -->
<!--    Hence the sign of $\theta_k$ indicates whether $\mathbb{P}(y_i \le j | \bv{x}_i)$ increases or decreases w.r.t. $x_{i,k}$ (the $k^{th}$ component of $\bv{x}_i$). -->
<!--    \item By contrast: -->
<!--    $$ -->
<!--    \frac{\partial \mathbb{P}(y_i = j | \bv{x}_i)}{\bv{x}_i} = \underbrace{\left(-F'(\alpha_{j} + \boldsymbol\theta'\bv{x}_i)+F'(\alpha_{j-1} + \boldsymbol\theta'\bv{x}_i)\right)}_{A}\boldsymbol\theta, -->
<!--    $$ -->
<!--    therefore the signs of the components of $\boldsymbol\theta$ are not necessarily those of the marginal effects. (For the sign of $A$ is a priori unknown.) -->
<!-- \end{itemize} -->
<!-- \end{scriptsize} -->
<!-- \end{frame} -->
<!-- \begin{specialframe} -->
<!-- \begin{tiny} -->
<!-- \begin{table}[!htbp] \centering  -->
<!--   \caption{Lending Club dataset (see Example\,\ref{exmpl:lendingclub})}  -->
<!--   \label{}  -->
<!-- \begin{tabular}{@{\extracolsep{5pt}}lccc}  -->
<!-- \\[-1.8ex]\hline  -->
<!-- \hline \\[-1.8ex]  -->
<!--  & \multicolumn{3}{c}{\textit{Dependent variable:}} \\  -->
<!-- \cline{2-4}  -->
<!-- \\[-1.8ex] & \multicolumn{3}{c}{grade.ordered} \\  -->
<!-- \\[-1.8ex] & (1) & (2) & (3)\\  -->
<!-- \hline \\[-1.8ex]  -->
<!--  y\textgreater =B & 1.042$^{***}$ & 1.032$^{***}$ & 1.037$^{***}$ \\  -->
<!--   & (0.040) & (0.038) & (0.031) \\  -->
<!--   y\textgreater =C & $-$0.228$^{***}$ & $-$0.237$^{***}$ & $-$0.227$^{***}$ \\  -->
<!--   & (0.039) & (0.037) & (0.029) \\  -->
<!--   y\textgreater =D & $-$1.497$^{***}$ & $-$1.507$^{***}$ & $-$1.490$^{***}$ \\  -->
<!--   & (0.040) & (0.039) & (0.031) \\  -->
<!--   y\textgreater =E & $-$3.155$^{***}$ & $-$3.164$^{***}$ & $-$3.139$^{***}$ \\  -->
<!--   & (0.047) & (0.046) & (0.039) \\  -->
<!--   loan\_amnt & $-$7.963$^{***}$ & $-$7.950$^{***}$ &  \\  -->
<!--   & (1.727) & (1.727) &  \\  -->
<!--   income.2.loan & 0.013$^{***}$ & 0.013$^{***}$ &  \\  -->
<!--   & (0.002) & (0.002) &  \\  -->
<!--   emp\_length\_high10y & $-$0.023 &  &  \\  -->
<!--   & (0.027) &  &  \\  -->
<!--   home\_ownership=OWN & 0.215$^{***}$ & 0.215$^{***}$ & 0.211$^{***}$ \\  -->
<!--   & (0.041) & (0.041) & (0.041) \\  -->
<!--   home\_ownership=RENT & 0.402$^{***}$ & 0.406$^{***}$ & 0.409$^{***}$ \\  -->
<!--   & (0.029) & (0.028) & (0.028) \\  -->
<!--   annual\_inc & $-$2.093$^{***}$ & $-$2.099$^{***}$ & $-$1.816$^{***}$ \\  -->
<!--   & (0.259) & (0.259) & (0.218) \\  -->
<!--   term= 60 months & 1.432$^{***}$ & 1.431$^{***}$ & 1.267$^{***}$ \\  -->
<!--   & (0.033) & (0.033) & (0.029) \\  -->
<!--  \hline \\[-1.8ex]  -->
<!-- Observations & 19,596 & 19,596 & 19,596 \\  -->
<!-- R$^{2}$ & 0.116 & 0.116 & 0.108 \\  -->
<!-- $\chi^{2}$ & 2,307.324$^{***}$ (df = 7) & 2,306.576$^{***}$ (df = 6) & 2,125.180$^{***}$ (df = 4) \\  -->
<!-- \hline  -->
<!-- \hline \\[-1.8ex]  -->
<!-- \textit{Note:}  & \multicolumn{3}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\  -->
<!-- \end{tabular}  -->
<!-- \end{table} -->
<!-- \end{tiny} -->
<!-- \end{specialframe} -->
<!-- \begin{frame} -->
<!-- \begin{scriptsize} -->
<!-- %\addtocounter{exmpl}{-1} -->
<!-- \begin{exerc}[Political information] -->
<!-- Using the data available \href{https://vincentarelbundock.github.io/Rdatasets/csv/pscl/politicalInformation.csv}{here} and documented \href{https://vincentarelbundock.github.io/Rdatasets/doc/pscl/politicalInformation.html}{here}, propose a model for the political information level. -->
<!-- \end{exerc} -->
<!-- \vspace{.5cm} -->
<!-- \begin{exerc}[Wine quality] -->
<!-- Using the data available \href{https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv}{here} and documented \href{https://archive.ics.uci.edu/ml/datasets/Wine+Quality}{here}, propose a model for wine quality. -->
<!-- \end{exerc} -->
<!-- \end{scriptsize} -->
<!-- \end{frame} -->
<!-- \subsection{General multinomial model} -->
<!-- \begin{frame}{The Different Types of Regressors}\label{slide:typeregressors} -->
<!-- \begin{scriptsize} -->
<!-- \begin{itemize} -->
<!--    \item Regressors may be {\color{blue}alternative-specific} or {\color{blue}alternative invariant} (see also Slide\,\ref{slide:Avregressors}). -->
<!--    \item Fishing data: prices and catch rates are alternative-specific, income is alternative-invariant. -->
<!--     \item Notations: as in Slide\,\ref{slide:Avregressors}, that is ... -->
<!--     \begin{itemize} -->
<!--        \item $\bv{u}_{i,j}$: vector of variables associated with agent $i$ and alternative $j$ (alternative-specific regressors). -->
<!--        \vspace{.1cm} -->
<!--        Example: Travel time per type of transportation (transportation choice), wage per type of work, cost per type of car. -->
<!--        \item $\bv{v}_{i}$: vector of variables associated with agent $i$ but alternative-invariant. -->
<!--        \vspace{.1cm} -->
<!--        Example: age or gender of agent $i$,  -->
<!--     \end{itemize} -->
<!--     \item We may e.g. organize $\bv{x}_i$ as follows: -->
<!--     \begin{equation}\label{eq:x_organiz} -->
<!--     \bv{x}_i = [\bv{u}_{i,1}',\dots,\bv{u}_{i,J}',\bv{v}_{i}']'. -->
<!--     \end{equation} -->
<!-- \end{itemize} -->
<!-- \end{scriptsize} -->
<!-- \end{frame} -->
<!-- \begin{frame}{``General'' Multinomial Logit} -->
<!-- \begin{scriptsize} -->
<!-- \begin{itemize} -->
<!--    \item General formulation of a multinomial logit: -->
<!--    \begin{equation}\label{eq:GeneralMNL} -->
<!--    g_j(\bv{x}_i;\boldsymbol\theta) = \frac{\exp(\theta_j'\bv{x}_i)}{\sum_{k=1}^J \exp(\theta_k'\bv{x}_i)}. -->
<!--    \end{equation} -->
<!--    (natural extension of the binary logit model, see Table\,\ref{table:differentspecif}.) -->
<!--    \item Note: By construction, $g_j(\bv{x}_i;\boldsymbol\theta) \in [0,1]$ and $\sum_{j}g_j(\bv{x}_i;\boldsymbol\theta)=1$. -->
<!--    \item If $\bv{x}_i$ organized as in Eq.\,(\ref{eq:x_organiz}), then, with obvious notations, $\theta_j$ is of the form: -->
<!--    \begin{equation}\label{eq:theta_organiz} -->
<!--     \theta_j = [{\theta^{(u)}_{1,j}}',\dots,{\theta^{(u)}_{J,j}}',{\theta_j^{(v)}}']', -->
<!--     \end{equation} -->
<!--     (and $\boldsymbol\theta=[\theta_1',\dots,\theta_J']'$). -->
<!-- \end{itemize} -->
<!-- \end{scriptsize} -->
<!-- \end{frame} -->
<!-- \begin{frame}{Classical specifications}\label{slide:differentLogitspecif} -->
<!-- \begin{scriptsize} -->
<!-- \begin{itemize} -->
<!--    \item {\color{blue}Conditional logit (CL)} with alternative-varying regressors: -->
<!--    \begin{equation}\label{eq:theta_organizCL} -->
<!--     \theta_j = [\bv{0}',\dots,\bv{0}',\underbrace{\boldsymbol\beta'}_{\mbox{j$^{th}$ position}},\bv{0}',\dots]', -->
<!--     \end{equation} -->
<!--     i.e. we have $\boldsymbol\beta=\theta^{(u)}_{1,1}=\dots=\theta^{(u)}_{J,J}$ and $\theta^{(u)}_{i,j}=0$ for $i \ne j$. -->
<!--     \item {\color{blue}Multinomial logit (MNL)} with alternative-invariant regressors: -->
<!--    \begin{equation}\label{eq:theta_organizML} -->
<!--     \theta_j = \left[\bv{0}',\dots,\bv{0}',{\theta_j^{(v)}}'\right]', -->
<!--     \end{equation} -->
<!--     (can embed intercepts.) -->
<!--     \item {\color{blue}Mixed logit}: -->
<!--    \begin{equation}\label{eq:theta_organizCL} -->
<!--     \theta_j = \left[\bv{0}',\dots,\bv{0}',\boldsymbol\beta',\bv{0}',\dots,\bv{0}',{\theta_j^{(v)}}'\right]'. -->
<!--     \end{equation} -->
<!--     \item Remark: The labelling ``CL'' and ``MNL'' -- used in the literature -- are relatively \textit{ad hoc} (see 15.4.1 in \href{http://cameron.econ.ucdavis.edu/mmabook/mma.html}{Cameron and Trivedi}). -->
<!-- \end{itemize} -->
<!-- \end{scriptsize} -->
<!-- \end{frame} -->
<!-- % ================================= -->
<!-- % ================================= -->
<!-- % ================================= -->
<!-- % \setlength\extrarowheight{-2pt}  -->
<!-- % ================================= -->
<!-- % ================================= -->
<!-- % ================================= -->
<!-- \begin{specialframe} -->
<!-- \begin{tiny} -->
<!-- % Table created by stargazer v.5.2.2 by Marek Hlavac, Harvard University. E-mail: hlavac at fas.harvard.edu -->
<!-- % Date and time: Fri, Dec 27, 2019 - 18:04:51 -->
<!-- \begin{table}[!htbp] \centering  -->
<!-- % ================================= -->
<!-- % ================================= -->
<!-- % ================================= -->
<!-- \setlength\extrarowheight{-1.5pt}  -->
<!-- % ================================= -->
<!-- % ================================= -->
<!-- % ================================= -->
<!--   \caption{Fishing Mode Multinomial Choice (replicates Table\,15.2 of \href{http://cameron.econ.ucdavis.edu/mmabook/mma.html}{Cameron and Trivedi})} -->
<!--   \label{}  -->
<!-- \begin{tabular}{@{\extracolsep{5pt}}lcccc}  -->
<!-- \\[-1.8ex]\hline  -->
<!-- \hline \\[-1.8ex]  -->
<!--  & \multicolumn{4}{c}{\textit{Dependent variable:}} \\  -->
<!-- \cline{2-5}  -->
<!-- \\[-1.8ex] & \multicolumn{4}{c}{mode} \\  -->
<!-- \\[-1.8ex] & (1) & (2) & (3) & (4)\\  -->
<!-- \hline \\[-1.8ex]  -->
<!--  boat:(intercept) & 0.871$^{***}$ &  & 0.739$^{***}$ & 0.527$^{**}$ \\  -->
<!--   & (0.114) &  & (0.197) & (0.223) \\  -->
<!--   & & & & \\  -->
<!--  charter:(intercept) & 1.499$^{***}$ &  & 1.341$^{***}$ & 1.694$^{***}$ \\  -->
<!--   & (0.133) &  & (0.195) & (0.224) \\  -->
<!--   & & & & \\  -->
<!--  pier:(intercept) & 0.307$^{***}$ &  & 0.814$^{***}$ & 0.778$^{***}$ \\  -->
<!--   & (0.115) &  & (0.229) & (0.220) \\  -->
<!--   & & & & \\  -->
<!--  price & $-$0.025$^{***}$ & $-$0.020$^{***}$ &  & $-$0.025$^{***}$ \\  -->
<!--   & (0.002) & (0.001) &  & (0.002) \\  -->
<!--   & & & & \\  -->
<!--  catch & 0.377$^{***}$ & 0.953$^{***}$ &  & 0.358$^{***}$ \\  -->
<!--   & (0.110) & (0.089) &  & (0.110) \\  -->
<!--   & & & & \\  -->
<!--  boat:income &  &  & 0.0001$^{**}$ & 0.0001$^{*}$ \\  -->
<!--   &  &  & (0.00004) & (0.0001) \\  -->
<!--   & & & & \\  -->
<!--  charter:income &  &  & $-$0.00003 & $-$0.00003 \\  -->
<!--   &  &  & (0.00004) & (0.0001) \\  -->
<!--   & & & & \\  -->
<!--  pier:income &  &  & $-$0.0001$^{***}$ & $-$0.0001$^{**}$ \\  -->
<!--   &  &  & (0.0001) & (0.0001) \\  -->
<!--   & & & & \\  -->
<!-- \hline \\[-1.8ex]  -->
<!-- Observations & 1,182 & 1,182 & 1,182 & 1,182 \\  -->
<!-- R$^{2}$ & 0.178 & 0.014 & 0.189 &  \\  -->
<!-- Log Likelihood & $-$1,230.784 & $-$1,311.980 & $-$1,477.151 & $-$1,215.138 \\  -->
<!-- LR Test & 533.878$^{***}$ (df = 5) &  & 41.145$^{***}$ (df = 6) & 565.171$^{***}$ (df = 8) \\  -->
<!-- \hline  -->
<!-- \hline \\[-1.8ex]  -->
<!-- \textit{Note:}  & \multicolumn{4}{l}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\  -->
<!-- & \multicolumn{4}{l}{Data description: see Slide\,\ref{slide:fishingdata}.} -->
<!-- \end{tabular}  -->
<!-- \end{table} -->
<!-- \end{tiny} -->
<!-- \end{specialframe} -->
<!-- \subsection{ML estimation} -->
<!-- \begin{frame}{Maximum Likelihood Estimation (MLE)} -->
<!-- \begin{scriptsize} -->
<!-- \begin{itemize} -->
<!--    \item Consider the general model described in Slide\,\ref{slide:IntroMNL}. -->
<!--    \item It can be noted that: -->
<!--    $$ -->
<!--    f(y_i|\bv{x}_i;\boldsymbol\theta) = \prod_{j=1}^J g_j(\bv{x}_i;\boldsymbol\theta)^{\mathds{1}_{\{y_i=j\}}}, -->
<!--    $$ -->
<!--    or that -->
<!--    $$ -->
<!--    \log f(y_i|\bv{x}_i;\boldsymbol\theta) = \sum_{j=1}^J \mathds{1}_{\{y_i=j\}} \log \left(g_j(\bv{x}_i;\boldsymbol\theta)\right). -->
<!--    $$ -->
<!--    \item The log-likelihood function is therefore given by: -->
<!--    \begin{equation}\label{eq:multipleLogLik} -->
<!--    \log \mathcal{L}(\boldsymbol\theta;\bv{y},\bv{X}) = \sum_{i=1}^n  \sum_{j=1}^J \mathds{1}_{\{y_i=j\}} \log \left(g_j(\bv{x}_i;\boldsymbol\theta)\right). -->
<!--    \end{equation} -->
<!--    \item Numerical maximization. -->
<!-- \end{itemize} -->
<!-- \end{scriptsize} -->
<!-- \end{frame} -->
<!-- \begin{frame}{Marginal Effects} -->
<!-- \begin{scriptsize} -->
<!-- \begin{itemize} -->
<!--    \item Let's use the notation $p_{i,j} \equiv \mathbb{P}(y_i=j|\bv{x}_i;\boldsymbol\theta)$. -->
<!--    \item According to the general logit formulation of Eq.\,(\ref{eq:GeneralMNL}), we have: -->
<!--    \begin{eqnarray*} -->
<!--    \frac{\partial p_{i,j}}{\partial x_{i,s}} &=& \frac{\theta_{j,s}\exp(\theta_j'\bv{x}_i)\sum_{k=1}^J \exp(\theta_k'\bv{x}_i)}{(\sum_{k=1}^J \exp(\theta_k'\bv{x}_i))^2} \\ -->
<!--    && - \frac{\exp(\theta_j'\bv{x}_i)\sum_{k=1}^J \theta_{k,s} \exp(\theta_k'\bv{x}_i)}{(\sum_{k=1}^J \exp(\theta_k'\bv{x}_i))^2}\\ -->
<!--    &=& \theta_{j,s} p_{i,j} - \sum_{k=1}^J \theta_{k,s} p_{i,j}p_{i,k}\\ -->
<!--    &=&  p_{i,j} \times \Big(\theta_{j,s} - \underbrace{\sum_{k=1}^J \theta_{k,s} p_{i,k}}_{=\overline{\boldsymbol{\theta}}^{(i)}_{s}}\Big), -->
<!--    \end{eqnarray*} -->
<!--    where $\overline{\boldsymbol\theta}^{(i)}_{s}$ does not depend on $j$. -->
<!--    \item[$\Rightarrow$] The sign of the marginal effect is not necessarily that of $\theta_{j,s}$. -->
<!-- \end{itemize} -->
<!-- \end{scriptsize} -->
<!-- \end{frame} -->
<!-- \subsection{Utility models} -->
<!-- \begin{frame}{Relationship with Utility Models}\label{slide:UMmulti} -->
<!-- \begin{scriptsize} -->
<!-- \begin{itemize} -->
<!--    \item More general models can be defined. Notably by resorting to {\color{blue} Additive Random Utility Models, ARUM} (see Slide\,\ref{slide:ARUM_Binary}). -->
<!--    \item Let's drop the $i$ subscript for simplicity. -->
<!--    \item Utility derived form choosing $j$: $U_j = V_j + \varepsilon_j$. -->
<!--    \item We have (with obvious notations): -->
<!--    \begin{eqnarray*} -->
<!--    \mathbb{P}(y=j) &=& \mathbb{P}(U_j>U_k,\,\forall k \ne j)\\ -->
<!--    \mathbb{P}(y=j) &=& \mathbb{P}(U_k-U_j<0,\,\forall k \ne j)\\ -->
<!--    \mathbb{P}(y=j) &=& \mathbb{P}(\underbrace{\varepsilon_k-\varepsilon_j}_{=:\tilde\varepsilon_{k,j}}<\underbrace{V_j - V_k}_{=:-\tilde{V}_{k,j}},\,\forall k \ne j). -->
<!--    \end{eqnarray*} -->
<!--    \item The last expression is an $(J-1)$-variate integral. It has, in general, no analytical solution.  -->
<!-- \end{itemize} -->
<!-- \end{scriptsize} -->
<!-- \end{frame} -->
<!-- \begin{frame}{Utility Models and the Multinomial Logit} -->
<!-- \begin{scriptsize} -->
<!-- \begin{itemize} -->
<!--    \item Gumbel distribution ($\mathcal{W}$), support: $\mathbb{R}$ (see Theorem\,\ref{thm:Extreme}): -->
<!--    $$ -->
<!--    F(u) = \exp(-\exp(-u)), \qquad f(u)=\exp(-u-\exp(u)). -->
<!--    $$ -->
<!--    \item If $X\sim\mathcal{W}$, then $\mathbb{E}(X)=0.577$ (Euler constant, see box below) and $\mathbb{V}ar(X)=\pi^2/6$. -->
<!--    \end{itemize} -->
<!-- \begin{prop}[Utility Model with a Gumbel distribution]\label{prop:Weibull} -->
<!-- In the context of the utility model described in Slide\,\ref{slide:UMmulti}, if $\varepsilon_j \sim \,i.i.d.\,\mathcal{W}$, then  -->
<!--    $$ -->
<!--    \mathbb{P}(y=j) = \frac{\exp(V_j)}{\sum_{k=1}^J \exp(V_k)}. -->
<!--    $$ -->
<!-- \end{prop} -->
<!-- \begin{tiny} -->
<!-- {\color{blue} Proof:} Slide\,\ref{slide:proofWeibull}. -->
<!-- \end{tiny} -->
<!-- \vspace{.2cm} -->
<!-- \begin{block}{Euler constant} -->
<!-- $$ -->
<!-- \gamma = \lim_{n\rightarrow \infty} \left(- \ln(n) + \sum_{k=1}^n \frac{1}{k}\right) -->
<!-- $$ -->
<!-- \end{block} -->
<!-- \end{scriptsize} -->
<!-- \end{frame} -->
<!-- \begin{frame}\label{slide:proofWeibull} -->
<!-- \begin{tiny} {\color{blue} Proof. of Prop.\,\ref{prop:Weibull}} We have: -->
<!-- \begin{eqnarray*} -->
<!-- \mathbb{P}(y=j) &=& \mathbb{P}(\forall\,k \ne j,\,U_k < U_j) =  \mathbb{P}(\forall\,k \ne j,\,\varepsilon_k < V_j - V_k + \varepsilon_j) \\ -->
<!--  &=& \int \prod_{k \ne j} F(V_j - V_k + \varepsilon) f(\varepsilon)d\varepsilon. -->
<!-- \end{eqnarray*} -->
<!-- After computation, it comes that -->
<!-- $$ -->
<!-- \prod_{k \ne j} F(V_j - V_k + \varepsilon) f(\varepsilon) = \exp\left[-\varepsilon-\exp(-\varepsilon+\lambda_j)\right], -->
<!-- $$ -->
<!-- where $\lambda_j = \log\left(1 + \frac{\sum_{k \ne j} \exp(V_k)}{\exp(V_j)}\right)$. We then have: -->
<!-- \begin{eqnarray*} -->
<!-- \mathbb{P}(y=j) &=& \int  \exp\left[-\varepsilon-\exp(-\varepsilon+\lambda_j)\right] d\varepsilon\\ -->
<!-- &=& \int  \exp\left[-t - \lambda_j-\exp(-t)\right] d\varepsilon = \exp(- \lambda_j).\qed -->
<!-- \end{eqnarray*} -->
<!-- \end{tiny} -->
<!-- \end{frame} -->
<!-- \begin{frame} -->
<!-- \begin{scriptsize} -->
<!-- \begin{block}{Gumbel distribution} -->
<!--        \begin{figure} -->
<!--        \caption{C.d.f. of Gumbel distribution} -->
<!--            \includegraphics[width=.8\linewidth]{../figures/Figure_Weibull.pdf} -->
<!--            \begin{tiny} -->
<!--            \begin{center} -->
<!--            See Theorem\,\ref{thm:Extreme}. The C.d.f. is: $x \rightarrow \exp(-\exp(x))$. -->
<!--            \end{center} -->
<!--            \end{tiny} -->
<!--        \end{figure} -->
<!-- \end{block} -->
<!-- \end{scriptsize} -->
<!-- \end{frame} -->
<!-- \begin{frame}{Remarks on identification} -->
<!-- \begin{scriptsize} -->
<!-- \begin{itemize} -->
<!--    \item We have: -->
<!--    \begin{eqnarray*} -->
<!--    \mathbb{P}(y=j) &=& \frac{\exp(V_j)}{\sum_{k=1}^J \exp(V_k)}\\ -->
<!--    &=& \frac{\exp(V^*_j)}{1 + \sum_{k=2}^J \exp(V^*_k)}, -->
<!--    \end{eqnarray*} -->
<!--    where $V^*_j = V_j - V_1$. -->
<!--    \item[$\Rightarrow$] We can always assume that $V_{1}=0$. -->
<!--    \item Case where $V_{i,j} = \theta_j'\bv{x}_i = \boldsymbol\beta'\bv{u}_{i,j}+{\theta_j^{(v)}}'\bv{v}_i$ (see Eqs.\,\ref{eq:x_organiz} and \ref{eq:theta_organizCL}): we can assume that  -->
<!--    $$ -->
<!--    \begin{array}{clll} -->
<!--    (A) & \bv{u}_{i,1}&=&0,\\ -->
<!--    (B) & \theta_1^{(v)} &=& 0. -->
<!--    \end{array} -->
<!--    $$ -->
<!--    If (A) does not hold, we can replace $\bv{u}_{i,j}$ by $\bv{u}_{i,j}-\bv{u}_{i,1}$. -->
<!--    \item If $J=2$ and $j \in \{0,1\}$ (shift by one unit), we have $\mathbb{P}(y=1|\bv{x})=\dfrac{\exp(\boldsymbol\theta'\bv{x})}{1+\exp(\boldsymbol\theta'\bv{x})}$, this is the logit model (Table\,\ref{table:differentspecif}). -->
<!-- \end{itemize} -->
<!-- \end{scriptsize} -->
<!-- \end{frame} -->
<!-- \subsection{Limitations} -->
<!-- \begin{frame}{Limitation of Logit Models}\label{slide:limitLogit} -->
<!-- \begin{scriptsize} -->
<!-- \begin{itemize} -->
<!--    \item In a Logit model: -->
<!--    \begin{equation}\label{eq:condiProba} -->
<!--    \mathbb{P}(y=j|y \in \{k,j\}) = \frac{\exp(\theta_j'\bv{x})}{\exp(\theta_j'\bv{x}) + \exp(\theta_k'\bv{x})}. -->
<!--    \end{equation} -->
<!--    \item This conditional proba does not depend on other alternatives (i.e. does not depend on $\theta_m$, $m \ne j,k$). -->
<!--    \item In particular, if $\bv{x} = [\bv{u}_1',\dots,\bv{u}_J',\bv{v}']'$ (see Slide\,\ref{slide:typeregressors}), then changes in $\bv{u}_m$ ($m \ne j,\,k$) have no impact on (\ref{eq:condiProba}). -->
<!--    \item[$\Rightarrow$] A Multinomial Logit  = series of pairwise comparisons that are unaffected by the characteristics of alternatives. -->
<!--    \item Important properties of multinomial logit model is {\color{blue}independence from irrelevant alternatives (IIA)}. -->
<!--    IIA property: for any individual, the ratio of probabilities of choosing two alternatives is independent of the availability or attributes of any other alternatives. -->
<!--    \item In this model, the choice of commuting by car or (red) bus is independent of whether commuting using a blue bus is an option. -->
<!-- \end{itemize} -->
<!-- \end{scriptsize} -->
<!-- \end{frame} -->
<!-- \begin{frame} -->
<!-- \begin{scriptsize} -->
<!-- \begin{remark}[Red-Blue Buses]\label{remark:redblue} -->
<!-- \begin{itemize} -->
<!--    \item Assume one has a logit modelling the ``car ($y=1$) vs red bus ($y=2$)'' choice. -->
<!--    \item If a blue bus ($y=3$) is exactly as a red bus, except for the color, then one would expect to have: -->
<!--    $$ -->
<!--    \mathbb{P}(y=3|y \in \{2,3\}) = 0.5, -->
<!--    $$ -->
<!--    i.e. $\theta_2 = \theta_3$. -->
<!--        %\item Introducing a blue bus should not affect $\mathbb{P}(y=1)$, and we would expect to have an increase of $\mathbb{P}(y=1|y \in \{1,2\})$ by $100\%$. This cannot be obtained with this parameterization. ADDRESSED BY OTHER MODELS? -->
<!--    \item Assume we had $V_1=V_2$. We expect to have $V_2=V_3$ (hence $p_2=p_3$). The model will then  imply $p_1=p_2=p_3=0.33$. -->
<!--    It would seem more reasonable to have $p_1 = p_2 + p_3 = 0.5$ and $p_2=p_3=0.25$. -->
<!-- \end{itemize} -->
<!-- \end{remark} -->
<!-- \end{scriptsize} -->
<!-- \end{frame} -->
<!-- \subsection{Sequential models} -->
<!-- \begin{frame}{Sequential Models} -->
<!-- \begin{scriptsize} -->
<!-- \begin{itemize} -->
<!--    \item Naturally, other possible (\textit{ad hoc}) modelling strategy, e.g. sequential modelling: -->
<!--    \begin{eqnarray*} -->
<!--    \mathbb{P}(y=1|\bv{x}) &=& F(\theta_1'\bv{x}) \\ -->
<!--    \mathbb{P}(y=2|\bv{x}) &=& (1-F(\theta_1'\bv{x})) \times F(\theta_2'\bv{x}) \\ -->
<!--    \mathbb{P}(y=3|\bv{x}) &=& (1-F(\theta_1'\bv{x})) \times (1 - F(\theta_2'\bv{x})). -->
<!--    \end{eqnarray*} -->
<!--    \item Easily checked that $\sum_j \mathbb{P}(y=j|\bv{x})=1$. -->
<!--    \item Example: car purchase; 1st choice = brand, 2nd choice = color. -->
<!--    \item Likelihood function: -->
<!--    \begin{eqnarray*} -->
<!--        \mathcal{L}(\theta_1,\theta_2;\bv{y},\bv{X}) &=& \prod_{j \in \{1,2,3\}} \left( \prod_{i\,s.t.\,y_i=j} \mathbb{P}(y_i=j|\bv{x}_i)\right). -->
<!--    \end{eqnarray*} -->
<!--    \item The maximization of the log-likelihood can be performed sequentially (w.r.t. to $\theta_1$ first, and next w.r.t. $\theta_2$). -->
<!--    \item Weaknesses: results may depend on the chosen sequence + no clear mapping with utility framework. -->
<!--    \item Alternative: nested logit model (Slide\,\ref{slide:nested}) where utilities of alternatives 2 and 3 are affected by correlated shocks. -->
<!-- \end{itemize} -->
<!-- \end{scriptsize} -->
<!-- \end{frame} -->
<!-- \subsection{Nested logits} -->
<!-- \begin{frame}{Nested Logits}\label{slide:nested} -->
<!-- \begin{scriptsize} -->
<!-- \begin{itemize} -->
<!--    \item Nested Logits are natural extensions of logit models when choices feature a nesting structure. -->
<!--    \item Important assumption: $\exists$ different alternatives that individuals choose sequentially. -->
<!--    \item Clustering of choices in ``nests'', defined by the specification. -->
<!--    \item Idea of unobserved agent-specific and nest-specific variable. -->
<!-- %  \item Choice of selecting $j_1 \in \{1,\dots,J_1\}$ and then $j_2 \in \{1,\dots,J_2\}$ is given by: -->
<!-- %  $$ -->
<!-- %  \mathbb{P}(y_1 = j_1,y_2=j_2) = \underbrace{\mathbb{P}(y_2=j_2|y_1 = j_1)}_{\mbox{2$^{nd}$ logit}}\underbrace{\mathbb{P}(y_1 = j_1)}_{\mbox{1$^{st}$ logit}}. -->
<!-- %  $$ -->
<!--    \item Common vocabulary: $J$ ``limbs''. For each limb $j$, $K_j$ ``branches''. -->
<!--    \item Utility interpretation: -->
<!--    \begin{center} -->
<!--    \{Limb $j$ (choice = $y_1$) and branch $k$ (choice = $y_2$) \} -->
<!--    $\rightarrow$ -->
<!--    Utility $U_{j,k} = V_{j,k} + \varepsilon_{j,k}$ -->
<!--    \end{center} -->
<!--    and: -->
<!--    $$ -->
<!--    \mathbb{P}[(y_1,y_2) = (j,k)|\bv{x}] = \mathbb{P}(U_{j,k}>U_{l,m},\,(l,m) \ne (j,k)|\bv{x}). -->
<!--    $$ -->
<!-- \end{itemize} -->
<!-- \end{scriptsize} -->
<!-- \end{frame} -->
<!-- \begin{frame}{Nested Logits} -->
<!-- \begin{scriptsize} -->
<!-- \begin{itemize} -->
<!--    \item[(i)] Specification of the deterministic part of utility: -->
<!--    $$ -->
<!--    V_{j,k} = \bv{u}_j'\boldsymbol\alpha + \bv{v}_{j,k}'\boldsymbol\beta_j, -->
<!--    $$ -->
<!--    where $\boldsymbol\alpha$ is common to all nests and $\boldsymbol\beta_j$'s are nest-specific. -->
<!--    \item[(ii)] Disturbances $\boldsymbol\varepsilon$ follows the Generalized Extreme Value (GEV) distribution (see Def.\,\ref{defn:GEVdistri}). -->
<!--    \item Under (i) and (ii): -->
<!--    \begin{eqnarray}\label{eq:Nested} -->
<!--    \mathbb{P}[(y_1,y_2) = (j,k)|\bv{x}] &=& \underbrace{\frac{\exp(\bv{u}_j'\boldsymbol\alpha + \rho_j I_j)}{\sum_{m=1}^J \exp(\bv{u}_m'\boldsymbol\alpha + \rho_m I_m)}}_{= \mathbb{P}[y_1 = j|\bv{x}]} \times \nonumber\\ -->
<!--    && \underbrace{\frac{\exp(\bv{v}_{j,k}'\boldsymbol\beta_j/\rho_j)}{\sum_{l=1}^{K_j} \exp(\bv{v}_{j,l}'\boldsymbol\beta_j/\rho_j)}}_{= \mathbb{P}[y_2 = k|y_1=j,\bv{x}]}, -->
<!--    \end{eqnarray} -->
<!--    where $I_j$'s are {\color{blue}inclusive value} or {\color{blue}log sum}, given by: -->
<!--    $$ -->
<!--    I_j = \log \left( \sum_{l=1}^{K_j} \exp(\bv{v}_{j,l}'\boldsymbol\beta_j/\rho_j)\right). -->
<!--    $$ -->
<!-- \end{itemize} -->
<!-- \end{scriptsize} -->
<!-- \end{frame} -->
<!-- \begin{frame} -->
<!-- \begin{scriptsize} -->
<!-- \begin{defn}[Generalized Extreme Value (GEV) distribution, \href{http://onlinepubs.trb.org/Onlinepubs/trr/1978/673/673-012.pdf}{McFadden (1978)}]\label{defn:GEVdistri} -->
<!--    The vector of disturbances $\boldsymbol\varepsilon=[\varepsilon_{1,1},\dots,\varepsilon_{1,K_1},\dots,\varepsilon_{J,1},\dots,\varepsilon_{J,K_J}]'$ follows the Generalized Extreme Value (GEV) distribution if its c.d.f. is: -->
<!--    $$ -->
<!--    F(\boldsymbol\varepsilon,\boldsymbol\rho) = \exp(-G(e^{-\varepsilon_{1,1}},\dots,e^{-\varepsilon_{J,K_J}};\boldsymbol\rho)) -->
<!--    $$ -->
<!--    with -->
<!--    \begin{eqnarray*} -->
<!--    G(\bv{Y};\boldsymbol\rho) &\equiv&  G(Y_{1,1},\dots,Y_{1,K_1},\dots,Y_{J,1},\dots,Y_{J,K_J};\boldsymbol\rho) \\ -->
<!--    &=& \sum_{j=1}^J\left(\sum_{k=1}^{K_j} Y_{jk}^{1/\rho_j} -->
<!--    \right)^{\rho_j} -->
<!--    \end{eqnarray*} -->
<!-- \end{defn} -->
<!-- \begin{remark}[]\label{remarks:GEV} -->
<!--    \begin{itemize} -->
<!--    \item[(a)] It can be shown that $\rho_j = \sqrt{1 - \mathbb{C}or(\varepsilon_{j,k},\varepsilon_{j,l})}$, for $k \ne l$. -->
<!--    \item[(b)] $\rho_j=1 \Rightarrow$, $\varepsilon_{j,k}$ and $\varepsilon_{j,l}$ are uncorrelated ($\Rightarrow$ Multinomial logit). -->
<!--    \item[(c)] When $J=1$:  -->
<!--    $$ -->
<!--    F([\varepsilon_1,\dots,\varepsilon_K]',\rho) = \exp\left(-\left(\sum_{k=1}^{K} \exp(-\varepsilon_k/\rho)\right)^{\rho}\right). -->
<!--    $$ -->
<!-- \end{itemize} -->
<!-- \end{remark} -->
<!-- \end{scriptsize} -->
<!-- \end{frame} -->
<!-- \begin{frame} -->
<!-- \begin{scriptsize} -->
<!--        \begin{figure} -->
<!--        \caption{Simulations of bivariate GEV (Def.\,\ref{defn:GEVdistri})} -->
<!--            \includegraphics[width=1\linewidth]{../figures/Figure_GEV.pdf} -->
<!--        \end{figure} -->
<!--        \begin{center} -->
<!--        \begin{tiny} -->
<!--        Note: Gumbel simulation method based on \href{http://www.caee.utexas.edu/prof/bhat/ABSTRACTS/Supp_material.pdf}{Bhat}. -->
<!--        \end{tiny} -->
<!--        \end{center} -->
<!-- \end{scriptsize} -->
<!-- \end{frame} -->
<!-- \begin{frame}{Nested Logits} -->
<!-- \begin{scriptsize} -->
<!-- \begin{itemize} -->
<!--    \item It can be shown that: -->
<!--        \begin{eqnarray*} -->
<!--    I_j = \mathbb{E}(\max_k(U_{j,k})) &=& \mathbb{E}(\max_k(V_{j,k} + \varepsilon_{j,k})), -->
<!--    \end{eqnarray*} -->
<!--    \item[$\Rightarrow$] Inclusive value = measure of the relative attractiveness of a nest.     -->
<!--    \vspace{.4cm} -->
<!--     \item Correlation across $\varepsilon_{j,k}$ (for a given $j$) $\Rightarrow$ existence of an (unobserved) ``common error component'' for the alternatives of a same nest = increased similarity between sets of nested alternatives. -->
<!--     \item[$\Rightarrow$] Leads to a higher sensitivity (cross-elasticity) between alternatives. -->
<!--     \item If the common component is reduced to zero (i.e. $\rho_i=1$), the model reduces to the multinomial logit model with no covariance of error terms among the alternatives. -->
<!-- %  \vspace{.4cm} -->
<!-- %  \item Page R: \href{https://cran.r-project.org/web/packages/mlogit/vignettes/e2nlogit.html}{tuto} -->
<!-- %  \item Applications: TravelMode ou bien Heating systems (voir dans biblio mLogitExercises.pdf). -->
<!-- \end{itemize} -->
<!-- \end{scriptsize} -->
<!-- \end{frame} -->
<!-- \begin{frame} -->
<!-- \begin{scriptsize} -->
<!-- \begin{remark}[Red-Blue Buses (extends Remark\,\ref{remark:redblue})] -->
<!-- \begin{itemize} -->
<!--    \item Nested logits can solve the Red-Blue problem described in Remark\,\ref{remark:redblue}. -->
<!--    \item Assume you have estimated a model specifying $U_{1} = V_{1} + \varepsilon_{1}$ (car choice) and $U_{2} = V_{2} + \varepsilon_{2}$ (red bus choice). -->
<!--    \item You can then assume that the blue-bus utility is of the form $U_{3} = V_{2} + \varepsilon_{3}$ where $\varepsilon_{3}$ is perfectly correlated to $\varepsilon_{2}$. -->
<!--    \item This is done by redefining the set of choices as follows: -->
<!--    \begin{eqnarray*} -->
<!--    j=1 &\Leftrightarrow& (j'=1,k=1) \\ -->
<!--    j=2 &\Leftrightarrow& (j'=2,k=1) \\ -->
<!--    j=3 &\Leftrightarrow& (j'=2,k=2), -->
<!--    \end{eqnarray*} -->
<!--    and by setting $\rho_2 \rightarrow 0$. -->
<!-- \end{itemize} -->
<!-- \end{remark} -->
<!-- \end{scriptsize} -->
<!-- \end{frame} -->
<!-- \begin{frame}{Nested Logits} -->
<!-- \begin{scriptsize} -->
<!-- \begin{itemize} -->
<!--    \item IIA (see Slide\,\ref{slide:limitLogit}) holds within a nest, but not when considering alternatives in different nests. -->
<!--    \item Indeed (using Eq.\,\ref{eq:Nested}): -->
<!--    $$ -->
<!--    \frac{\mathbb{P}[y_1=j,y_2=k_A|\bv{x}] }{\mathbb{P}[y_1=j,y_2=k_B|\bv{x}]} = \frac{\exp(\bv{v}_{j,k_A}'\boldsymbol\beta_j/\rho_j)}{\exp(\bv{v}_{j,k_B}'\boldsymbol\beta_j/\rho_j)}, -->
<!--    $$ -->
<!--    i.e. we have IIA in nest $j$. -->
<!--    By contrast: -->
<!--    \begin{eqnarray*} -->
<!--    \frac{\mathbb{P}[y_1=j_A,y_2=k_A|\bv{x}] }{\mathbb{P}[y_1=j_B,y_2=k_B|\bv{x}]} &=& \frac{\exp(\bv{u}_{j_A}'\boldsymbol\alpha + \rho_{j_A} I_{j_A})\exp(\bv{v}_{{j_A},{k_A}}'\boldsymbol\beta_{j_A}/\rho_{j_A})}{\exp(\bv{u}_{j_B}'\boldsymbol\alpha + \rho_{j_B} I_{j_B})\exp(\bv{v}_{{j_B},{k_B}}'\boldsymbol\beta_{j_B}/\rho_{j_B})}\times\\ -->
<!--    && \frac{\sum_{l=1}^{K_{j_B}} \exp(\bv{v}_{{j_B},l}'\boldsymbol\beta_{j_B}/\rho_{j_B})}{\sum_{l=1}^{K_{j_A}} \exp(\bv{v}_{{j_A},l}'\boldsymbol\beta_{J_A}/\rho_{j_A})}, -->
<!--    \end{eqnarray*} -->
<!--    which depends on the expected utilities of all alternatives in nest $j_A$ and $j_B$. So the IIA does not hold. -->
<!-- \end{itemize} -->
<!-- \end{scriptsize} -->
<!-- \end{frame} -->
<!-- \begin{frame} -->
<!-- \begin{tiny} -->
<!-- % Table created by stargazer v.5.2.2 by Marek Hlavac, Harvard University. E-mail: hlavac at fas.harvard.edu -->
<!-- % Date and time: Sat, Dec 28, 2019 - 07:18:00 -->
<!-- \begin{table}[!htbp] \centering  -->
<!-- % ================================= -->
<!-- % ================================= -->
<!-- % ================================= -->
<!-- \setlength\extrarowheight{-1.8pt}  -->
<!-- % ================================= -->
<!-- % ================================= -->
<!-- % ================================= -->
<!--   \caption{Travel mode (\href{https://www.sciencedirect.com/science/article/pii/S0191261500000357}{Hensher and Greene, 2002})}  -->
<!--   \label{}  -->
<!-- \begin{tabular}{@{\extracolsep{5pt}}lcc}  -->
<!-- \\[-1.8ex]\hline  -->
<!-- \hline \\[-1.8ex]  -->
<!--  & \multicolumn{2}{c}{\textit{Dependent variable:}} \\  -->
<!-- \cline{2-3}  -->
<!-- \\[-1.8ex] & \multicolumn{2}{c}{choice} \\  -->
<!-- \\[-1.8ex] & (1) & (2)\\  -->
<!-- \hline \\[-1.8ex]  -->
<!--  train:(intercept) & $-$0.633 & 0.006 \\  -->
<!--   & (0.494) & (0.636) \\  -->
<!--   & & \\  -->
<!--  bus:(intercept) & $-$1.432$^{**}$ & $-$0.774 \\  -->
<!--   & (0.712) & (0.809) \\  -->
<!--   & & \\  -->
<!--  car:(intercept) & $-$6.507$^{***}$ & $-$6.154$^{***}$ \\  -->
<!--   & (1.148) & (1.178) \\  -->
<!--   & & \\  -->
<!--  gcost & $-$0.014$^{***}$ & $-$0.020$^{***}$ \\  -->
<!--   & (0.005) & (0.006) \\  -->
<!--   & & \\  -->
<!--  wait & $-$0.111$^{***}$ & $-$0.106$^{***}$ \\  -->
<!--   & (0.020) & (0.021) \\  -->
<!--   & & \\  -->
<!--  incomeother & 0.447$^{***}$ & 0.426$^{***}$ \\  -->
<!--   & (0.111) & (0.113) \\  -->
<!--   & & \\  -->
<!--  iv & 1.293$^{***}$ &  \\  -->
<!--   & (0.343) &  \\  -->
<!--   & & \\  -->
<!--  iv:public &  & 0.969$^{***}$ \\  -->
<!--   &  & (0.305) \\  -->
<!--   & & \\  -->
<!--  iv:other &  & 1.724$^{***}$ \\  -->
<!--   &  & (0.519) \\  -->
<!--   & & \\  -->
<!-- \hline \\[-1.8ex]  -->
<!-- Observations & 210 & 210 \\  -->
<!-- R$^{2}$ & 0.330 & 0.336 \\  -->
<!-- Log Likelihood & $-$190.178 & $-$188.433 \\  -->
<!-- LR Test & 187.162$^{***}$ (df = 7) & 190.652$^{***}$ (df = 8) \\  -->
<!-- \hline  -->
<!-- \hline \\[-1.8ex]  -->
<!-- \textit{Note:}  & \multicolumn{2}{l}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\  -->
<!-- & \multicolumn{2}{l}{\href{https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/ModeChoice.html}{Dataset description}.} -->
<!-- \end{tabular}  -->
<!-- \end{table}  -->
<!-- \end{tiny} -->
<!-- \end{frame} -->
<!-- \begin{frame} -->
<!-- \begin{tiny} -->
<!-- % Table created by stargazer v.5.2.2 by Marek Hlavac, Harvard University. E-mail: hlavac at fas.harvard.edu -->
<!-- % Date and time: Sun, Dec 29, 2019 - 07:10:45 -->
<!-- \begin{table}[!htbp] \centering  -->
<!-- % ================================= -->
<!-- % ================================= -->
<!-- % ================================= -->
<!-- \setlength\extrarowheight{-1.8pt}  -->
<!-- % ================================= -->
<!-- % ================================= -->
<!-- % ================================= -->
<!--   \caption{Heating/cooling mode}  -->
<!--   \label{}  -->
<!-- \begin{tabular}{@{\extracolsep{5pt}}lccc}  -->
<!-- \\[-1.8ex]\hline  -->
<!-- \hline \\[-1.8ex]  -->
<!--  & \multicolumn{3}{c}{\textit{Dependent variable:}} \\  -->
<!-- \cline{2-4}  -->
<!-- \\[-1.8ex] & \multicolumn{3}{c}{depvar} \\  -->
<!-- \\[-1.8ex] & (1) & (2) & (3)\\  -->
<!-- \hline \\[-1.8ex]  -->
<!-- % ecc:(intercept) & 0.055 & 2.171 & 2.180 \\  -->
<!-- %  & (3.163) & (3.402) & (3.390) \\  -->
<!-- %  & & & \\  -->
<!-- % er:(intercept) & $-$3.265$^{**}$ & $-$2.455$^{**}$ & $-$2.453$^{**}$ \\  -->
<!-- %  & (1.428) & (1.071) & (1.064) \\  -->
<!-- %  & & & \\  -->
<!-- % erc:(intercept) & $-$1.165 & 1.756 & 1.765 \\  -->
<!-- %  & (3.289) & (3.548) & (3.541) \\  -->
<!-- %  & & & \\  -->
<!-- % gc:(intercept) & 0.068 & $-$0.208 & $-$0.200 \\  -->
<!-- %  & (1.166) & (0.469) & (0.436) \\  -->
<!-- %  & & & \\  -->
<!-- % gcc:(intercept) & 0.705 & 2.234 & 2.240 \\  -->
<!-- %  & (3.176) & (3.384) & (3.367) \\  -->
<!-- %  & & & \\  -->
<!-- % hpc:(intercept) & $-$2.156 & 1.273 & 1.278 \\  -->
<!-- %  & (3.249) & (3.618) & (3.601) \\  -->
<!-- %  & & & \\  -->
<!--  occa & $-$1.159$^{*}$ & $-$0.966 & $-$0.967 \\  -->
<!--   & (0.700) & (0.708) & (0.708) \\  -->
<!--   & & & \\  -->
<!--  icca & $-$0.048 & $-$0.051 & $-$0.051 \\  -->
<!--   & (0.067) & (0.081) & (0.079) \\  -->
<!--   & & & \\  -->
<!--  och & $-$2.096$^{***}$ & $-$0.869$^{*}$ & $-$0.870$^{*}$ \\  -->
<!--   & (0.448) & (0.445) & (0.445) \\  -->
<!--   & & & \\  -->
<!--  ich & $-$0.354$^{***}$ & $-$0.205$^{**}$ & $-$0.205$^{**}$ \\  -->
<!--   & (0.064) & (0.091) & (0.091) \\  -->
<!--   & & & \\  -->
<!--  iv:cooling &  & 0.334$^{*}$ &  \\  -->
<!--   &  & (0.172) &  \\  -->
<!--   & & & \\  -->
<!--  iv:noncool &  & 0.329 &  \\  -->
<!--   &  & (0.212) &  \\  -->
<!--   & & & \\  -->
<!--  iv &  &  & 0.334$^{*}$ \\  -->
<!--   &  &  & (0.171) \\  -->
<!--   & & & \\  -->
<!-- \hline \\[-1.8ex]  -->
<!-- Observations & 250 & 250 & 250 \\  -->
<!-- R$^{2}$ & 0.144 & 0.165 & 0.165 \\  -->
<!-- Log Likelihood & $-$192.877 & $-$188.035 & $-$188.035 \\  -->
<!-- LR Test & 64.669$^{***}$ (df = 10) & 74.354$^{***}$ (df = 12) & 74.353$^{***}$ (df = 11) \\  -->
<!-- \hline  -->
<!-- \hline \\[-1.8ex]  -->
<!-- \textit{Note:}  & \multicolumn{3}{l}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\  -->
<!-- & \multicolumn{3}{l}{\href{https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/HC.html}{Dataset description}.} -->
<!-- \end{tabular}  -->
<!-- \end{table} -->
<!-- \end{tiny} -->
<!-- \end{frame} -->
<!-- %\begin{frame}{Nested Logits} -->
<!-- %\begin{scriptsize} -->
<!-- %\begin{itemize} -->
<!-- %  \item Very good tuto on mLogit \href{http://www2.uaem.mx/r-mirror/web/packages/mlogit/vignettes/mlogit.pdf}{Croissant} -->
<!-- %  \item Page R: \href{https://cran.r-project.org/web/packages/mlogit/vignettes/e2nlogit.html}{tuto} -->
<!-- %  \item \href{http://onlinepubs.trb.org/Onlinepubs/trr/1993/1413/1413-011.pdf}{Pas mal:} The common error component, ee, for the nested alter- natives represents a covariance relationship that describes an increased similarity between pairs of nested alternatives and leads to a higher sensitivity (cross-elasticity) between alter- natives. If this common component, ee, is reduced to zero, the model reduces to the multinomial logit model with no covariance of error terms among the alternatives. -->
<!-- % -->
<!-- %  \item We are back to a standard MNL model when $\rho_i=1$. -->
<!-- %\end{itemize} -->
<!-- %\end{scriptsize} -->
<!-- %\end{frame} -->

</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="intro.html"><span class="header-section-number">2</span> Introduction</a></div>
<div class="next"><a href="appendix.html"><span class="header-section-number">4</span> Appendix</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#microeconometrics"><span class="header-section-number">3</span> Microeconometrics</a></li>
<li>
<a class="nav-link" href="#binary-choice-models"><span class="header-section-number">3.1</span> Binary-choice models</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#interpretation-in-terms-of-latent-variable-and-utility-based-models"><span class="header-section-number">3.1.1</span> Interpretation in terms of latent variable, and utility-based models</a></li>
<li><a class="nav-link" href="#Avregressors"><span class="header-section-number">3.1.2</span> Alternative-Varying Regressors</a></li>
<li><a class="nav-link" href="#estimation"><span class="header-section-number">3.1.3</span> Estimation</a></li>
<li><a class="nav-link" href="#marginal-effectss"><span class="header-section-number">3.1.4</span> Marginal effectss</a></li>
<li><a class="nav-link" href="#goodness-of-fit"><span class="header-section-number">3.1.5</span> Goodness of fit</a></li>
<li><a class="nav-link" href="#example-credit-data"><span class="header-section-number">3.1.6</span> Example: Credit data</a></li>
<li><a class="nav-link" href="#replicating-table-14.2-of-cameron-and-trivedi-2005"><span class="header-section-number">3.1.7</span> Replicating Table 14.2 of Cameron and Trivedi (2005)</a></li>
<li><a class="nav-link" href="#predictions"><span class="header-section-number">3.1.8</span> Predictions</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Advanced Econometrics</strong>" was written by Jean-Paul Renne. It was last built on 2022-08-29.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
