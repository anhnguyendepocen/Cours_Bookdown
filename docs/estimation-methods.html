<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Estimation Methods | Advanced Econometrics</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.27 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Estimation Methods | Advanced Econometrics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Estimation Methods | Advanced Econometrics" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Jean-Paul Renne" />


<meta name="date" content="2022-08-12" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="panel-regressions.html"/>
<link rel="next" href="microeconometrics.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Advanced Econometrics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prerequisites</a></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a></li>
<li class="chapter" data-level="3" data-path="linear-regressions.html"><a href="linear-regressions.html"><i class="fa fa-check"></i><b>3</b> Linear Regressions</a>
<ul>
<li class="chapter" data-level="3.1" data-path="linear-regressions.html"><a href="linear-regressions.html#specification"><i class="fa fa-check"></i><b>3.1</b> Specification</a></li>
<li class="chapter" data-level="3.2" data-path="linear-regressions.html"><a href="linear-regressions.html#least-square-estimation"><i class="fa fa-check"></i><b>3.2</b> Least square estimation</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="linear-regressions.html"><a href="linear-regressions.html#bivariate-case"><i class="fa fa-check"></i><b>3.2.1</b> Bivariate case</a></li>
<li class="chapter" data-level="3.2.2" data-path="linear-regressions.html"><a href="linear-regressions.html#gauss-markow-theorem"><i class="fa fa-check"></i><b>3.2.2</b> Gauss Markow Theorem</a></li>
<li class="chapter" data-level="3.2.3" data-path="linear-regressions.html"><a href="linear-regressions.html#frish-waugh"><i class="fa fa-check"></i><b>3.2.3</b> Frish-Waugh</a></li>
<li class="chapter" data-level="3.2.4" data-path="linear-regressions.html"><a href="linear-regressions.html#goodness-of-fit"><i class="fa fa-check"></i><b>3.2.4</b> Goodness of fit</a></li>
<li class="chapter" data-level="3.2.5" data-path="linear-regressions.html"><a href="linear-regressions.html#inference-and-prediction"><i class="fa fa-check"></i><b>3.2.5</b> Inference and Prediction</a></li>
<li class="chapter" data-level="3.2.6" data-path="linear-regressions.html"><a href="linear-regressions.html#confidence-interval-of-beta_k"><i class="fa fa-check"></i><b>3.2.6</b> Confidence interval of <span class="math inline">\(\beta_k\)</span></a></li>
<li class="chapter" data-level="3.2.7" data-path="linear-regressions.html"><a href="linear-regressions.html#example"><i class="fa fa-check"></i><b>3.2.7</b> Example</a></li>
<li class="chapter" data-level="3.2.8" data-path="linear-regressions.html"><a href="linear-regressions.html#set-of-linear-restrictions"><i class="fa fa-check"></i><b>3.2.8</b> Set of linear restrictions</a></li>
<li class="chapter" data-level="3.2.9" data-path="linear-regressions.html"><a href="linear-regressions.html#common-pitfalls"><i class="fa fa-check"></i><b>3.2.9</b> Common pitfalls</a></li>
<li class="chapter" data-level="3.2.10" data-path="linear-regressions.html"><a href="linear-regressions.html#multicollinearity"><i class="fa fa-check"></i><b>3.2.10</b> Multicollinearity</a></li>
<li class="chapter" data-level="3.2.11" data-path="linear-regressions.html"><a href="linear-regressions.html#omitted-variables"><i class="fa fa-check"></i><b>3.2.11</b> Omitted variables</a></li>
<li class="chapter" data-level="3.2.12" data-path="linear-regressions.html"><a href="linear-regressions.html#irrelevant-variable"><i class="fa fa-check"></i><b>3.2.12</b> Irrelevant variable</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="linear-regressions.html"><a href="linear-regressions.html#large-sample-properties"><i class="fa fa-check"></i><b>3.3</b> Large Sample Properties</a></li>
<li class="chapter" data-level="3.4" data-path="linear-regressions.html"><a href="linear-regressions.html#instrumental-variables"><i class="fa fa-check"></i><b>3.4</b> Instrumental Variables</a></li>
<li class="chapter" data-level="3.5" data-path="linear-regressions.html"><a href="linear-regressions.html#general-regression-model"><i class="fa fa-check"></i><b>3.5</b> General Regression Model</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="linear-regressions.html"><a href="linear-regressions.html#generalized-least-squares"><i class="fa fa-check"></i><b>3.5.1</b> Generalized Least Squares</a></li>
<li class="chapter" data-level="3.5.2" data-path="linear-regressions.html"><a href="linear-regressions.html#heteroskedasticity-and-autocorrelation-hac"><i class="fa fa-check"></i><b>3.5.2</b> Heteroskedasticity and Autocorrelation (HAC)</a></li>
<li class="chapter" data-level="3.5.3" data-path="linear-regressions.html"><a href="linear-regressions.html#how-to-detect-autocorrelation-in-residuals"><i class="fa fa-check"></i><b>3.5.3</b> How to detect autocorrelation in residuals?</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="linear-regressions.html"><a href="linear-regressions.html#summary"><i class="fa fa-check"></i><b>3.6</b> Summary</a></li>
<li class="chapter" data-level="3.7" data-path="linear-regressions.html"><a href="linear-regressions.html#clusters"><i class="fa fa-check"></i><b>3.7</b> Clusters</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="panel-regressions.html"><a href="panel-regressions.html"><i class="fa fa-check"></i><b>4</b> Panel regressions</a>
<ul>
<li class="chapter" data-level="4.0.1" data-path="panel-regressions.html"><a href="panel-regressions.html#three-standard-cases"><i class="fa fa-check"></i><b>4.0.1</b> Three standard cases</a></li>
<li class="chapter" data-level="4.1" data-path="panel-regressions.html"><a href="panel-regressions.html#estimation-of-fixed-effects-models"><i class="fa fa-check"></i><b>4.1</b> Estimation of Fixed Effects Models</a></li>
<li class="chapter" data-level="4.2" data-path="panel-regressions.html"><a href="panel-regressions.html#estimation-of-random-effects-models"><i class="fa fa-check"></i><b>4.2</b> Estimation of random effects models</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="estimation-methods.html"><a href="estimation-methods.html"><i class="fa fa-check"></i><b>5</b> Estimation Methods</a>
<ul>
<li class="chapter" data-level="5.1" data-path="estimation-methods.html"><a href="estimation-methods.html#generalized-method-of-moments-gmm"><i class="fa fa-check"></i><b>5.1</b> Generalized Method of Moments (GMM)</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="estimation-methods.html"><a href="estimation-methods.html#framework"><i class="fa fa-check"></i><b>5.1.1</b> Framework</a></li>
<li class="chapter" data-level="5.1.2" data-path="estimation-methods.html"><a href="estimation-methods.html#example-estimation-of-the-stochastic-discount-factor-s.d.f."><i class="fa fa-check"></i><b>5.1.2</b> Example: Estimation of the Stochastic Discount Factor (s.d.f.)</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="estimation-methods.html"><a href="estimation-methods.html#maximum-likelihood-estimation"><i class="fa fa-check"></i><b>5.2</b> Maximum Likelihood Estimation</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="estimation-methods.html"><a href="estimation-methods.html#notations"><i class="fa fa-check"></i><b>5.2.1</b> Notations</a></li>
<li class="chapter" data-level="5.2.2" data-path="estimation-methods.html"><a href="estimation-methods.html#to-sum-up-mle-in-practice"><i class="fa fa-check"></i><b>5.2.2</b> To sum up – MLE in practice</a></li>
<li class="chapter" data-level="5.2.3" data-path="estimation-methods.html"><a href="estimation-methods.html#example-mle-estimation-of-a-mixture-of-gaussian-distribution"><i class="fa fa-check"></i><b>5.2.3</b> Example: MLE estimation of a mixture of Gaussian distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="microeconometrics.html"><a href="microeconometrics.html"><i class="fa fa-check"></i><b>6</b> Microeconometrics</a></li>
<li class="chapter" data-level="7" data-path="time-series.html"><a href="time-series.html"><i class="fa fa-check"></i><b>7</b> Time Series</a></li>
<li class="chapter" data-level="8" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>8</b> Appendix</a>
<ul>
<li class="chapter" data-level="8.1" data-path="appendix.html"><a href="appendix.html#statitical-tables"><i class="fa fa-check"></i><b>8.1</b> Statitical Tables</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Advanced Econometrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="estimation-methods" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">Chapter 5</span> Estimation Methods<a href="estimation-methods.html#estimation-methods" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Context and Objective:</p>
<ul>
<li>You observe a sample <span class="math inline">\(\bv{y}=\{y_1,\dots,y_n\}\)</span>.</li>
<li>You know that these data have been generated by a model parameterized by <span class="math inline">\(\theta_0 \in \mathbb{R}^K\)</span>.</li>
</ul>
<div id="generalized-method-of-moments-gmm" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Generalized Method of Moments (GMM)<a href="estimation-methods.html#generalized-method-of-moments-gmm" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="framework" class="section level3 hasAnchor" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> Framework<a href="estimation-methods.html#framework" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We denote by <span class="math inline">\(x_t\)</span> a <span class="math inline">\(p \times 1\)</span> vector of (stationary) variables observed at date <span class="math inline">\(t\)</span>; by <span class="math inline">\(\theta\)</span> an <span class="math inline">\(a \times 1\)</span> vector of parameters, and by <span class="math inline">\(h(x_t;\theta)\)</span> a continuous <span class="math inline">\(r \times 1\)</span> vector-valued function.</p>
<p>We denote by <span class="math inline">\(\theta_0\)</span> the true value of <span class="math inline">\(\theta\)</span> and we assume that <span class="math inline">\(\theta_0\)</span> satisfies:
<span class="math display">\[
\mathbb{E}[h(x_t;\theta_0)] = 0.
\]</span></p>
<p>We denote by <span class="math inline">\(\underline{x_t}\)</span> the information contained in the current and past observations of <span class="math inline">\(x_t\)</span>, that is: <span class="math inline">\(\underline{x_t} = \{x_t,x_{t-1},\dots,x_1\}\)</span>. We denote by <span class="math inline">\(g(\underline{x_T};\theta)\)</span> the sample average of <span class="math inline">\(h(x_t;\theta)\)</span>, i.e.:
<span class="math display">\[
g(\underline{x_T};\theta) = \frac{1}{T} \sum_{t=1}^{T} h(x_t;\theta).
\]</span></p>
<p>Intuition behind GMM: Choose <span class="math inline">\(\theta\)</span> so as to make the sample moment as close as possible to 0.</p>
<div class="definition">
<p><span id="def:GMM" class="definition"><strong>Definition 5.1  </strong></span>A GMM estimator of <span class="math inline">\(\theta_0\)</span> is given by:
<span class="math display">\[
\hat{\theta}_T = \mbox{argmin}_{\theta} \quad g(\underline{x_T};\theta)&#39;\, W_T \, g(\underline{x_T};\theta),
\]</span>
where <span class="math inline">\(W_T\)</span> is a positive definite matrix (that may depend on <span class="math inline">\(\underline{x_T}\)</span>).</p>
</div>
<p>If <span class="math inline">\(a = r\)</span> (the dimension of <span class="math inline">\(\theta\)</span> is the same as that of <span class="math inline">\(h(x_t;\theta)\)</span>, or <span class="math inline">\(g(\underline{x_T};\theta)\)</span>), <span class="math inline">\(\hat{\theta}_T\)</span> is such that:
<span class="math display">\[
g(\underline{x_T};\hat{\theta}_T) = 0.
\]</span>
Under regularity and identification conditions:
<span class="math display">\[
\hat{\theta}_{T} \overset{p}{\rightarrow} \theta_0,
\]</span>
i.e. <span class="math inline">\(\forall \varepsilon&gt;0\)</span>, <span class="math inline">\(\lim_{n \rightarrow \infty} \mathbb{P}(|\hat{\theta}_{T} - \theta_0|&gt;\varepsilon) = 0\)</span>.</p>
<p><strong>Optimal weighting matrix</strong>. The GMM estimator achieving the minimum asymptotic variance is obtained when <span class="math inline">\(W_T\)</span> is the inverse of the matrix <span class="math inline">\(S\)</span> defined by:
<span class="math display">\[
S := \sum_{\nu = -\infty}^{\infty} \Gamma_\nu,
\]</span>
where <span class="math inline">\(\Gamma_\nu := \mathbb{E}[h(x_t;\theta_0) h(x_{t-\nu};\theta_0)&#39;]\)</span>.</p>
<p>For <span class="math inline">\(\nu \ge 0\)</span>, let us define <span class="math inline">\(\hat{\Gamma}_{\nu,T}\)</span> by:
<span class="math display">\[
\hat{\Gamma}_{\nu,T} = \frac{1}{T} \sum_{t=\nu + 1}^{T} h(x_t;\hat{\theta}_T)h(x_{t-\nu};\hat{\theta}_T)&#39;,
\]</span>
<span class="math inline">\(S\)</span> can be approximated by:
<span class="math display" id="eq:Shat">\[\begin{eqnarray}
&amp;\hat{\Gamma}_{0,T}&amp; \quad \mbox{if the $h(x_t;\theta_0)$ are serially uncorrelated and} \nonumber \\
&amp;\hat{\Gamma}_{0,T}&amp; + \sum_{\nu=1}^{q}[1-\nu/(q+1)](\hat{\Gamma}_{\nu,T}+\hat{\Gamma}_{\nu,T}&#39;) \quad \mbox{otherwise.}    \tag{5.1}
\end{eqnarray}\]</span></p>
<p><strong>Asymptotic distribution of <span class="math inline">\(\hat\theta_T\)</span></strong></p>
<p>We have:
<span class="math display">\[
\sqrt{T}(\hat\theta_T - \theta_0) \overset{\mathcal{L}}{\rightarrow} \mathcal{N}(0,V),
\]</span>
where <span class="math inline">\(V = (DS^{-1}D&#39;)^{-1}\)</span>.</p>
<p><span class="math inline">\(V\)</span> can be approximated by <span class="math inline">\((\hat{D}_T\hat{S}_T^{-1}\hat{D}_T&#39;)^{-1}\)</span>,
where <span class="math inline">\(\hat{S}_T\)</span> is given by Eq. <a href="estimation-methods.html#eq:Shat">(5.1)</a> and
<span class="math display">\[
\hat{D}&#39;_T := \left.\frac{\partial g(\underline{x_T};\theta)}{\partial \theta&#39;}\right|_{\theta = \hat\theta_T}.
\]</span></p>
</div>
<div id="example-estimation-of-the-stochastic-discount-factor-s.d.f." class="section level3 hasAnchor" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> Example: Estimation of the Stochastic Discount Factor (s.d.f.)<a href="estimation-methods.html#example-estimation-of-the-stochastic-discount-factor-s.d.f." class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Under the no-arbitrage assumption, there exists a random variable <span class="math inline">\(\mathcal{M}_{t,t+1}\)</span> such that
<span class="math display">\[
\mathbb{E}_t(\mathcal{M}_{t,t+1}R_{t+1})=1
\]</span>
for any (gross) asset return <span class="math inline">\(R_t\)</span>. In the following, <span class="math inline">\(R_t\)</span> denotes a <span class="math inline">\(n_r\)</span>-dimensional vector of gross returns.</p>
<p>We consider the following specification of the s.d.f.:
<span class="math display" id="eq:sdf">\[\begin{equation}
\mathcal{M}_{t,t+1} = 1 - \textbf{b}_M&#39;(F_{t+1} - \mathbb{E}_t(F_{t+1})), \tag{5.2}
\end{equation}\]</span>
where <span class="math inline">\(F_t\)</span> is a vector of factors. Eq. <a href="estimation-methods.html#eq:sdf">(5.2)</a> then reads:
<span class="math display">\[
\mathbb{E}_t([1 - \textbf{b}_M&#39;(F_{t+1} - \mathbb{E}_t(F_{t+1}))]R_{t+1})=1.
\]</span></p>
<p>Assume that the date-<span class="math inline">\(t\)</span> information set is <span class="math inline">\(\mathcal{I}_t=\{\textbf{z}_t,\mathcal{I}_{t-1}\}\)</span>, where <span class="math inline">\(\textbf{z}_t\)</span> is a vector of variables observed on date <span class="math inline">\(t\)</span>. (We then have <span class="math inline">\(\mathbb{E}_t(\bullet) \equiv \mathbb{E}(\bullet|\mathcal{I}_t)\)</span>.)</p>
<p>We can use <span class="math inline">\(\textbf{z}_t\)</span> as an instrument. Indeed, we have:
<span class="math display" id="eq:momF">\[\begin{eqnarray}
&amp;&amp;\mathbb{E}(z_{i,t} [\textbf{b}_M&#39;\{F_{t+1} - \mathbb{E}_t(F_{t+1})\}R_{t+1}-R_{t+1}+1]) \nonumber \\
&amp;=&amp;\mathbb{E}(\mathbb{E}_t\{z_{i,t} [\textbf{b}_M&#39;\{F_{t+1} - \mathbb{E}_t(F_{t+1})\}R_{t+1}-R_{t+1}+1]\})\nonumber\\
&amp;=&amp;\mathbb{E}(z_{i,t} \underbrace{\mathbb{E}_t\{\textbf{b}_M&#39;\{F_{t+1} - \mathbb{E}_t(F_{t+1})\}R_{t+1}-R_{t+1}+1\}}_{=0})=0.\tag{5.3}
\end{eqnarray}\]</span>
We have then converted a conditional moment condition into a unconditional one (which we need to implement the theory above). However, at that stage, we cannot still not directly use the GMM formulas because of the conditional expectation <span class="math inline">\(\mathbb{E}_t(F_{t+1})\)</span> that appears in <span class="math inline">\(\mathbb{E}(z_{i,t} [\textbf{b}_M&#39;\{F_{t+1} - \mathbb{E}_t(F_{t+1})\}R_{t+1}-R_{t+1}+1])=0\)</span>.</p>
<p>To go further, let us assume that:
<span class="math display">\[
\mathbb{E}_t(F_{t+1}) = \textbf{b}_F \textbf{z}_t.
\]</span>
We can then easily estimate matrix <span class="math inline">\(\textbf{b}_F\)</span> (of dimension <span class="math inline">\(n_F \times n_z\)</span>) by OLS. Note here that these OLS can be seen as a special GMM case. Indeed, as was done in Eq. <a href="estimation-methods.html#eq:momF">(5.3)</a>, we can show that, for the <span class="math inline">\(j^{th}\)</span> component of <span class="math inline">\(F_t\)</span>, we have:
<span class="math display">\[
\mathbb{E}( [F_{j,t+1} - \textbf{b}_{F,j} \textbf{z}_t]\textbf{z}_{t})=0,
\]</span>
where <span class="math inline">\(\textbf{b}_{F,j}\)</span> denotes the <span class="math inline">\(j^{th}\)</span> row of <span class="math inline">\(\textbf{b}_{F}\)</span>. This yields the OLS formula.</p>
<p>At that stage, we count on the following moment restrictions to estimate <span class="math inline">\(\textbf{b}_M\)</span>:
<span class="math display">\[
\mathbb{E}(z_{i,t} [\textbf{b}_M&#39;\{F_{t+1} - \textbf{b}_F \textbf{z}_t\}R_{t+1}-R_{t+1}+1])=0.
\]</span>
Specifically, the number of restrictions is <span class="math inline">\(n_R \times n_z\)</span>. Let us implement this approach in the U.S. context, using data extracted from the <a href="https://fred.stlouisfed.org">FRED database</a>. In factor <span class="math inline">\(F_t\)</span>, we use the changes in the VIX and in the personal consumption expenditures. The returns (<span class="math inline">\(R_t\)</span>) are based on the Wilshire 5000 Price Index (a stock price index) and on the ICE BofA BBB US Corporate Index Total Return Index (a bond return index).</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="estimation-methods.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(fredr)</span>
<span id="cb1-2"><a href="estimation-methods.html#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">fredr_set_key</span>(<span class="st">&quot;df65e14c054697a52b4511e77fcfa1f3&quot;</span>)</span>
<span id="cb1-3"><a href="estimation-methods.html#cb1-3" aria-hidden="true" tabindex="-1"></a>start_date <span class="ot">&lt;-</span> <span class="fu">as.Date</span>(<span class="st">&quot;1990-01-01&quot;</span>); end_date <span class="ot">&lt;-</span> <span class="fu">as.Date</span>(<span class="st">&quot;2022-01-01&quot;</span>)</span>
<span id="cb1-4"><a href="estimation-methods.html#cb1-4" aria-hidden="true" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="cf">function</span>(ticker){</span>
<span id="cb1-5"><a href="estimation-methods.html#cb1-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fredr</span>(<span class="at">series_id =</span> ticker,</span>
<span id="cb1-6"><a href="estimation-methods.html#cb1-6" aria-hidden="true" tabindex="-1"></a>        <span class="at">observation_start =</span> start_date,<span class="at">observation_end =</span> end_date,</span>
<span id="cb1-7"><a href="estimation-methods.html#cb1-7" aria-hidden="true" tabindex="-1"></a>        <span class="at">frequency =</span> <span class="st">&quot;m&quot;</span>,<span class="at">aggregation_method =</span> <span class="st">&quot;avg&quot;</span>)</span>
<span id="cb1-8"><a href="estimation-methods.html#cb1-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-9"><a href="estimation-methods.html#cb1-9" aria-hidden="true" tabindex="-1"></a>vix <span class="ot">&lt;-</span> <span class="fu">f</span>(<span class="st">&quot;VIXCLS&quot;</span>) <span class="co"># VIX</span></span>
<span id="cb1-10"><a href="estimation-methods.html#cb1-10" aria-hidden="true" tabindex="-1"></a>pce <span class="ot">&lt;-</span> <span class="fu">f</span>(<span class="st">&quot;PCE&quot;</span>) <span class="co"># Personal consumption expenditures</span></span>
<span id="cb1-11"><a href="estimation-methods.html#cb1-11" aria-hidden="true" tabindex="-1"></a>sto <span class="ot">&lt;-</span> <span class="fu">f</span>(<span class="st">&quot;WILL5000PRFC&quot;</span>) <span class="co"># Wilshire 5000 Full Cap Price Index</span></span>
<span id="cb1-12"><a href="estimation-methods.html#cb1-12" aria-hidden="true" tabindex="-1"></a>bdr <span class="ot">&lt;-</span> <span class="fu">f</span>(<span class="st">&quot;BAMLCC0A4BBBTRIV&quot;</span>) <span class="co"># ICE BofA BBB US Corporate Index Total Return Index</span></span>
<span id="cb1-13"><a href="estimation-methods.html#cb1-13" aria-hidden="true" tabindex="-1"></a>T <span class="ot">&lt;-</span> <span class="fu">dim</span>(vix)[<span class="dv">1</span>]</span>
<span id="cb1-14"><a href="estimation-methods.html#cb1-14" aria-hidden="true" tabindex="-1"></a>dvix <span class="ot">&lt;-</span> <span class="fu">c</span>(vix<span class="sc">$</span>value[<span class="dv">3</span><span class="sc">:</span>T]<span class="sc">/</span>vix<span class="sc">$</span>value[<span class="dv">2</span><span class="sc">:</span>(T<span class="dv">-1</span>)]) <span class="co"># change in VIX t+1</span></span>
<span id="cb1-15"><a href="estimation-methods.html#cb1-15" aria-hidden="true" tabindex="-1"></a>dpce <span class="ot">&lt;-</span> <span class="fu">c</span>(pce<span class="sc">$</span>value[<span class="dv">3</span><span class="sc">:</span>T]<span class="sc">/</span>pce<span class="sc">$</span>value[<span class="dv">2</span><span class="sc">:</span>(T<span class="dv">-1</span>)]) <span class="co"># change in PCE t+1</span></span>
<span id="cb1-16"><a href="estimation-methods.html#cb1-16" aria-hidden="true" tabindex="-1"></a>dsto <span class="ot">&lt;-</span> <span class="fu">c</span>(sto<span class="sc">$</span>value[<span class="dv">3</span><span class="sc">:</span>T]<span class="sc">/</span>sto<span class="sc">$</span>value[<span class="dv">2</span><span class="sc">:</span>(T<span class="dv">-1</span>)]) <span class="co"># return t+1</span></span>
<span id="cb1-17"><a href="estimation-methods.html#cb1-17" aria-hidden="true" tabindex="-1"></a>dbdr <span class="ot">&lt;-</span> <span class="fu">c</span>(bdr<span class="sc">$</span>value[<span class="dv">3</span><span class="sc">:</span>T]<span class="sc">/</span>bdr<span class="sc">$</span>value[<span class="dv">2</span><span class="sc">:</span>(T<span class="dv">-1</span>)]) <span class="co"># return t+1</span></span>
<span id="cb1-18"><a href="estimation-methods.html#cb1-18" aria-hidden="true" tabindex="-1"></a>dvix_1 <span class="ot">&lt;-</span> <span class="fu">c</span>(vix<span class="sc">$</span>value[<span class="dv">2</span><span class="sc">:</span>(T<span class="dv">-1</span>)]<span class="sc">/</span>vix<span class="sc">$</span>value[<span class="dv">1</span><span class="sc">:</span>(T<span class="dv">-2</span>)]) <span class="co"># change in VIX t</span></span>
<span id="cb1-19"><a href="estimation-methods.html#cb1-19" aria-hidden="true" tabindex="-1"></a>dpce_1 <span class="ot">&lt;-</span> <span class="fu">c</span>(pce<span class="sc">$</span>value[<span class="dv">2</span><span class="sc">:</span>(T<span class="dv">-1</span>)]<span class="sc">/</span>pce<span class="sc">$</span>value[<span class="dv">1</span><span class="sc">:</span>(T<span class="dv">-2</span>)]) <span class="co"># change in PCE t</span></span>
<span id="cb1-20"><a href="estimation-methods.html#cb1-20" aria-hidden="true" tabindex="-1"></a>dsto_1 <span class="ot">&lt;-</span> <span class="fu">c</span>(sto<span class="sc">$</span>value[<span class="dv">2</span><span class="sc">:</span>(T<span class="dv">-1</span>)]<span class="sc">/</span>sto<span class="sc">$</span>value[<span class="dv">1</span><span class="sc">:</span>(T<span class="dv">-2</span>)]) <span class="co"># return t</span></span>
<span id="cb1-21"><a href="estimation-methods.html#cb1-21" aria-hidden="true" tabindex="-1"></a>dbdr_1 <span class="ot">&lt;-</span> <span class="fu">c</span>(bdr<span class="sc">$</span>value[<span class="dv">2</span><span class="sc">:</span>(T<span class="dv">-1</span>)]<span class="sc">/</span>bdr<span class="sc">$</span>value[<span class="dv">1</span><span class="sc">:</span>(T<span class="dv">-2</span>)]) <span class="co"># return t</span></span></code></pre></div>
<p>Define the matrices containing the <span class="math inline">\(F_{t+1}\)</span>, <span class="math inline">\(\textbf{z}_t\)</span>, and <span class="math inline">\(R_{t+1}\)</span> vectors:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="estimation-methods.html#cb2-1" aria-hidden="true" tabindex="-1"></a>F_tp1 <span class="ot">&lt;-</span> <span class="fu">cbind</span>(dvix,dpce)</span>
<span id="cb2-2"><a href="estimation-methods.html#cb2-2" aria-hidden="true" tabindex="-1"></a>Z     <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>,dvix_1,dpce_1,dsto_1,dbdr_1)</span>
<span id="cb2-3"><a href="estimation-methods.html#cb2-3" aria-hidden="true" tabindex="-1"></a>b_F <span class="ot">&lt;-</span> <span class="fu">t</span>(<span class="fu">solve</span>(<span class="fu">t</span>(Z) <span class="sc">%*%</span> Z) <span class="sc">%*%</span> <span class="fu">t</span>(Z) <span class="sc">%*%</span> F_tp1)</span>
<span id="cb2-4"><a href="estimation-methods.html#cb2-4" aria-hidden="true" tabindex="-1"></a>F_innov <span class="ot">&lt;-</span> F_tp1 <span class="sc">-</span> Z <span class="sc">%*%</span> <span class="fu">t</span>(b_F)</span>
<span id="cb2-5"><a href="estimation-methods.html#cb2-5" aria-hidden="true" tabindex="-1"></a>R_tp1 <span class="ot">&lt;-</span> <span class="fu">cbind</span>(dsto,dbdr)</span>
<span id="cb2-6"><a href="estimation-methods.html#cb2-6" aria-hidden="true" tabindex="-1"></a>n_F <span class="ot">&lt;-</span> <span class="fu">dim</span>(F_tp1)[<span class="dv">2</span>]; n_R <span class="ot">&lt;-</span> <span class="fu">dim</span>(R_tp1)[<span class="dv">2</span>]; n_z <span class="ot">&lt;-</span> <span class="fu">dim</span>(Z)[<span class="dv">2</span>]</span></code></pre></div>
<p>Function <code>f_aux</code> compute the <span class="math inline">\(h(x_t;\theta)\)</span> and the <span class="math inline">\(g(\underline{x_T};\theta)\)</span>; function <code>f2beMin</code> is the function to be minimized.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="estimation-methods.html#cb3-1" aria-hidden="true" tabindex="-1"></a>f_aux <span class="ot">&lt;-</span> <span class="cf">function</span>(theta){</span>
<span id="cb3-2"><a href="estimation-methods.html#cb3-2" aria-hidden="true" tabindex="-1"></a>  b_M <span class="ot">&lt;-</span> <span class="fu">matrix</span>(theta[<span class="dv">1</span><span class="sc">:</span>n_F],<span class="at">ncol=</span><span class="dv">1</span>)</span>
<span id="cb3-3"><a href="estimation-methods.html#cb3-3" aria-hidden="true" tabindex="-1"></a>  R_aux <span class="ot">&lt;-</span> <span class="fu">matrix</span>(F_innov <span class="sc">%*%</span> b_M,T<span class="dv">-2</span>,n_R) <span class="sc">*</span> R_tp1 <span class="sc">-</span> R_tp1 <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb3-4"><a href="estimation-methods.html#cb3-4" aria-hidden="true" tabindex="-1"></a>  H <span class="ot">&lt;-</span> (R_aux <span class="sc">%x%</span> <span class="fu">matrix</span>(<span class="dv">1</span>,<span class="dv">1</span>,n_z)) <span class="sc">*</span> (<span class="fu">matrix</span>(<span class="dv">1</span>,<span class="dv">1</span>,n_R) <span class="sc">%x%</span> Z)</span>
<span id="cb3-5"><a href="estimation-methods.html#cb3-5" aria-hidden="true" tabindex="-1"></a>  g <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">apply</span>(H,<span class="dv">2</span>,mean),<span class="at">ncol=</span><span class="dv">1</span>)</span>
<span id="cb3-6"><a href="estimation-methods.html#cb3-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">g=</span>g,<span class="at">H=</span>H))</span>
<span id="cb3-7"><a href="estimation-methods.html#cb3-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb3-8"><a href="estimation-methods.html#cb3-8" aria-hidden="true" tabindex="-1"></a>f2beMin <span class="ot">&lt;-</span> <span class="cf">function</span>(theta,W){<span class="co"># function to be minimized</span></span>
<span id="cb3-9"><a href="estimation-methods.html#cb3-9" aria-hidden="true" tabindex="-1"></a>  res <span class="ot">&lt;-</span> <span class="fu">f_aux</span>(theta)</span>
<span id="cb3-10"><a href="estimation-methods.html#cb3-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">t</span>(res<span class="sc">$</span>g) <span class="sc">%*%</span> W <span class="sc">%*%</span> res<span class="sc">$</span>g)</span>
<span id="cb3-11"><a href="estimation-methods.html#cb3-11" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Now, let’s minimize this function. We consider 5 iterations (where <span class="math inline">\(W\)</span> is updated).</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="estimation-methods.html#cb4-1" aria-hidden="true" tabindex="-1"></a>theta <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">0</span>,n_F)) <span class="co"># inital value</span></span>
<span id="cb4-2"><a href="estimation-methods.html#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>){<span class="co"># recursion on W</span></span>
<span id="cb4-3"><a href="estimation-methods.html#cb4-3" aria-hidden="true" tabindex="-1"></a>  res <span class="ot">&lt;-</span> <span class="fu">f_aux</span>(theta)</span>
<span id="cb4-4"><a href="estimation-methods.html#cb4-4" aria-hidden="true" tabindex="-1"></a>  W <span class="ot">&lt;-</span> <span class="fu">solve</span>(<span class="dv">1</span><span class="sc">/</span>T <span class="sc">*</span> <span class="fu">t</span>(res<span class="sc">$</span>H) <span class="sc">%*%</span> res<span class="sc">$</span>H)</span>
<span id="cb4-5"><a href="estimation-methods.html#cb4-5" aria-hidden="true" tabindex="-1"></a>  res.optim <span class="ot">&lt;-</span> <span class="fu">optim</span>(theta,f2beMin,<span class="at">W=</span>W,</span>
<span id="cb4-6"><a href="estimation-methods.html#cb4-6" aria-hidden="true" tabindex="-1"></a>                     <span class="at">method=</span><span class="st">&quot;BFGS&quot;</span>, <span class="co"># could be &quot;Nelder-Mead&quot;</span></span>
<span id="cb4-7"><a href="estimation-methods.html#cb4-7" aria-hidden="true" tabindex="-1"></a>                     <span class="at">control=</span><span class="fu">list</span>(<span class="at">trace=</span><span class="cn">FALSE</span>,<span class="at">maxit=</span><span class="dv">200</span>),<span class="at">hessian=</span><span class="cn">TRUE</span>)</span>
<span id="cb4-8"><a href="estimation-methods.html#cb4-8" aria-hidden="true" tabindex="-1"></a>  theta <span class="ot">&lt;-</span> res.optim<span class="sc">$</span>par</span>
<span id="cb4-9"><a href="estimation-methods.html#cb4-9" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Finally, let’s compute the standard deviation of the parameter estimates.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="estimation-methods.html#cb5-1" aria-hidden="true" tabindex="-1"></a>eps <span class="ot">&lt;-</span> .<span class="dv">0001</span></span>
<span id="cb5-2"><a href="estimation-methods.html#cb5-2" aria-hidden="true" tabindex="-1"></a>g0 <span class="ot">&lt;-</span> <span class="fu">f_aux</span>(theta)<span class="sc">$</span>g</span>
<span id="cb5-3"><a href="estimation-methods.html#cb5-3" aria-hidden="true" tabindex="-1"></a>D <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb5-4"><a href="estimation-methods.html#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(theta)){</span>
<span id="cb5-5"><a href="estimation-methods.html#cb5-5" aria-hidden="true" tabindex="-1"></a>  theta.i <span class="ot">&lt;-</span> theta</span>
<span id="cb5-6"><a href="estimation-methods.html#cb5-6" aria-hidden="true" tabindex="-1"></a>  theta.i[i] <span class="ot">&lt;-</span> theta.i[i] <span class="sc">+</span> eps</span>
<span id="cb5-7"><a href="estimation-methods.html#cb5-7" aria-hidden="true" tabindex="-1"></a>  gi <span class="ot">&lt;-</span> <span class="fu">f_aux</span>(theta.i)<span class="sc">$</span>g</span>
<span id="cb5-8"><a href="estimation-methods.html#cb5-8" aria-hidden="true" tabindex="-1"></a>  D <span class="ot">&lt;-</span> <span class="fu">cbind</span>(D,(gi<span class="sc">-</span>g0)<span class="sc">/</span>eps)</span>
<span id="cb5-9"><a href="estimation-methods.html#cb5-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb5-10"><a href="estimation-methods.html#cb5-10" aria-hidden="true" tabindex="-1"></a>V <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span>T <span class="sc">*</span> <span class="fu">solve</span>(<span class="fu">t</span>(D) <span class="sc">%*%</span> W <span class="sc">%*%</span> D)</span>
<span id="cb5-11"><a href="estimation-methods.html#cb5-11" aria-hidden="true" tabindex="-1"></a>std.dev <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">diag</span>(V));t.stud <span class="ot">&lt;-</span> theta<span class="sc">/</span>std.dev</span>
<span id="cb5-12"><a href="estimation-methods.html#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(theta,std.dev,t.stud)</span></code></pre></div>
<pre><code>##           theta    std.dev     t.stud
## [1,] -0.6774355  0.3182614 -2.1285502
## [2,]  4.3612746 13.1163581  0.3325065</code></pre>
<p>The Hansen statistic can be used to test the model. If the model is correct, we have:
<span class="math display">\[
T g(\underline{x_T};\theta)&#39;\, S^{-1} \, g(\underline{x_T};\theta) \sim \,i.i.d.\,\chi^2(J - K),
\]</span>
where <span class="math inline">\(J\)</span> is the number of moment contraints (<span class="math inline">\(n_z \times n_r\)</span> here) and <span class="math inline">\(K\)</span> is the number of estimated parameters (<span class="math inline">\(=n_F\)</span> here).</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="estimation-methods.html#cb7-1" aria-hidden="true" tabindex="-1"></a>g <span class="ot">&lt;-</span> <span class="fu">f_aux</span>(theta)<span class="sc">$</span>g</span>
<span id="cb7-2"><a href="estimation-methods.html#cb7-2" aria-hidden="true" tabindex="-1"></a>Hanse_stat <span class="ot">&lt;-</span> T <span class="sc">*</span> <span class="fu">t</span>(g) <span class="sc">%*%</span> W <span class="sc">%*%</span> g</span>
<span id="cb7-3"><a href="estimation-methods.html#cb7-3" aria-hidden="true" tabindex="-1"></a>pvalue <span class="ot">&lt;-</span> <span class="fu">pchisq</span>(<span class="at">q =</span> Hanse_stat,<span class="at">df =</span> n_R<span class="sc">*</span>n_z <span class="sc">-</span> n_F)</span></code></pre></div>
</div>
</div>
<div id="maximum-likelihood-estimation" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> Maximum Likelihood Estimation<a href="estimation-methods.html#maximum-likelihood-estimation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Intuition behind the Maximum Likelihood Estimation: Estimator = the value of <span class="math inline">\(\theta\)</span> that is such that the probability of having observed <span class="math inline">\(\bv{y}\)</span> is the highest possible.</p>
<p>Assume that the time periods between the arrivals of two customers in a shop, denoted by <span class="math inline">\(y_i\)</span>, are i.i.d. and follow an exponential distribution, i.e. <span class="math inline">\(y_i \sim \mathcal{E}(\lambda)\)</span>.</p>
<p>You have observed these arrivals for some time, thereby constituting a sample <span class="math inline">\(\{y_1,\dots,y_n\}\)</span>. You want to estimate <span class="math inline">\(\lambda\)</span> (i.e. in that case, the vector of parameters is simply <span class="math inline">\(\theta = \lambda\)</span>).</p>
<p>The density of <span class="math inline">\(Y\)</span> is <span class="math inline">\(f(y;\lambda) = \dfrac{1}{\lambda}\exp(-y/\lambda)\)</span>. Fig. <a href="estimation-methods.html#fig:MLE1">5.1</a> represents that density functions for different values of <span class="math inline">\(\lambda\)</span>.</p>
<p>Your 200 observations are reported at the bottom of Fig. <a href="estimation-methods.html#fig:MLE1">5.1</a> (red).
You build the histogram and report it on the same chart.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:MLE1"></span>
<img src="AdvECTS_files/figure-html/MLE1-1.png" alt="The red ticks, at the bottom, indicate observations (there are 200 of them). The historgram is based on these 200 observations" width="90%" />
<p class="caption">
Figure 5.1: The red ticks, at the bottom, indicate observations (there are 200 of them). The historgram is based on these 200 observations
</p>
</div>
<p>What is your estimate of <span class="math inline">\(\lambda\)</span>?</p>
<p>Now, assume that you have only four observations: <span class="math inline">\(y_1=1.1\)</span>, <span class="math inline">\(y_2=2.2\)</span>, <span class="math inline">\(y_3=0.7\)</span> and <span class="math inline">\(y_4=5.0\)</span>.
What was the probability of observing, for a small <span class="math inline">\(\varepsilon\)</span>,</p>
<ul>
<li><span class="math inline">\(1.1-\varepsilon \le Y_1 &lt; 1.1+\varepsilon\)</span>,</li>
<li><span class="math inline">\(2.2-\varepsilon \le Y_2 &lt; 2.2+\varepsilon\)</span>,</li>
<li><span class="math inline">\(0.7-\varepsilon \le Y_3 &lt; 0.7+\varepsilon\)</span> and</li>
<li><span class="math inline">\(5.0-\varepsilon \le Y_4 &lt; 5.0+\varepsilon\)</span>?</li>
</ul>
<p>Because the <span class="math inline">\(y_i\)</span>s are i.i.d., this probability is <span class="math inline">\(\prod_{i=1}^4(2\varepsilon f(y_i,\lambda))\)</span>.
The next plot shows the probability (divided by <span class="math inline">\(16\varepsilon^4\)</span>) as a function of <span class="math inline">\(\lambda\)</span>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:MLE2"></span>
<img src="AdvECTS_files/figure-html/MLE2-1.png" alt="Proba. that $y_i-\varepsilon \le Y_i &lt; y_i+\varepsilon$, $i \in \{1,2,3,4\}$. The vertical red line indicates the maximum of the function." width="90%" />
<p class="caption">
Figure 5.2: Proba. that <span class="math inline">\(y_i-\varepsilon \le Y_i &lt; y_i+\varepsilon\)</span>, <span class="math inline">\(i \in \{1,2,3,4\}\)</span>. The vertical red line indicates the maximum of the function.
</p>
</div>
<p>Back to the example with 200 observations:</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:MLE3"></span>
<img src="AdvECTS_files/figure-html/MLE3-1.png" alt="Log-likelihood function associated with the 200 i.i.d. observations. The vertical red line indicates the maximum of the function." width="90%" />
<p class="caption">
Figure 5.3: Log-likelihood function associated with the 200 i.i.d. observations. The vertical red line indicates the maximum of the function.
</p>
</div>
<div id="notations" class="section level3 hasAnchor" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> Notations<a href="estimation-methods.html#notations" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><span class="math inline">\(f(y;\boldsymbol\theta)\)</span> denotes the probability density function (p.d.f.) of a random variable <span class="math inline">\(Y\)</span> which depends on a set of parameters <span class="math inline">\(\boldsymbol\theta\)</span>.</p>
<p>Density of <span class="math inline">\(n\)</span> independent and identically distributed (i.i.d.) observations of <span class="math inline">\(Y\)</span>:
<span class="math display">\[
f(y_1,\dots,y_n;\boldsymbol\theta) = \prod_{i=1}^n f(y_i;\boldsymbol\theta).
\]</span>
<span class="math inline">\(\bv{y}\)</span> denotes the vector of observations; <span class="math inline">\(\bv{y} = \{y_1,\dots,y_n\}\)</span>.</p>
<hr />
<div class="definition">
<p><span id="def:likelihood" class="definition"><strong>Definition 5.2  (Likelihood function) </strong></span><span class="math inline">\(\mathcal{L}: \boldsymbol\theta \rightarrow \mathcal{L}(\boldsymbol\theta;\bv{y})=f(y_1,\dots,y_n;\boldsymbol\theta)\)</span> is the <strong>likelihood function</strong>.</p>
</div>
<hr />
<p>We often work with <span class="math inline">\(\log \mathcal{L}\)</span>, the <strong>log-likelihood function</strong>.</p>
<div class="example">
<p><span id="exm:normal" class="example"><strong>Example 5.1  (Gaussian distribution) </strong></span>If <span class="math inline">\(y_i \sim \mathcal{N}(\mu,\sigma^2)\)</span>, then
<span class="math display">\[
\log \mathcal{L}(\boldsymbol\theta;\bv{y}) = - \frac{1}{2}\sum_{i=1}^n\left( \log \sigma^2 + \log 2\pi + \frac{(y_i-\mu)^2}{\sigma^2} \right).
\]</span></p>
</div>
<hr />
<div class="definition">
<p><span id="def:score" class="definition"><strong>Definition 5.3  (Score) </strong></span>The score <span class="math inline">\(S(y;\boldsymbol\theta)\)</span> is given by <span class="math inline">\(\frac{\partial \log f(y;\boldsymbol\theta)}{\partial \boldsymbol\theta}\)</span>.</p>
</div>
<hr />
<p>If <span class="math inline">\(y_i \sim \mathcal{N}(\mu,\sigma^2)\)</span> (Example <a href="estimation-methods.html#exm:normal">5.1</a>), then
<span class="math display">\[
\frac{\partial \log f(y;\boldsymbol\theta)}{\partial \boldsymbol\theta} =
\left[\begin{array}{c}
\dfrac{\partial \log f(y;\boldsymbol\theta)}{\partial \mu}\\
\dfrac{\partial \log f(y;\boldsymbol\theta)}{\partial \sigma^2}
\end{array}\right] =
\left[\begin{array}{c}
\dfrac{y-\mu}{\sigma^2}\\
\frac{1}{2\sigma^2}\left(\frac{(y-\mu)^2}{\sigma^2}-1\right)
\end{array}\right].
\]</span></p>
<hr />
<div class="proposition">
<p><span id="prp:score" class="proposition"><strong>Proposition 5.1  (Score expectation) </strong></span>The expectation of the score is zero.</p>
</div>
<hr />
<div class="proof">
<p><span id="unlabeled-div-1" class="proof"><em>Proof</em>. </span>We have:
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}\left(\frac{\partial \log f(Y;\boldsymbol\theta)}{\partial \boldsymbol\theta}\right) &amp;=&amp;
\int \frac{\partial \log f(y;\boldsymbol\theta)}{\partial \boldsymbol\theta} f(y;\boldsymbol\theta) dy \\
&amp;=&amp; \int \frac{\partial f(y;\boldsymbol\theta)/\partial \boldsymbol\theta}{f(y;\boldsymbol\theta)} f(y;\boldsymbol\theta) dy =
\frac{\partial}{\partial \boldsymbol\theta} \int f(y;\boldsymbol\theta) dy =
\partial 1 /\partial \boldsymbol\theta = 0,
\end{eqnarray*}\]</span>
which gives the result.</p>
</div>
<div class="definition">
<p><span id="def:Fisher" class="definition"><strong>Definition 5.4  (Fisher information matrix) </strong></span>The <strong>information matrix</strong> is (minus) the the expectation of the second derivatives of the log-likelihood function:
<span class="math display">\[
\mathcal{I}_Y(\boldsymbol\theta) = - \mathbb{E} \left( \frac{\partial^2 \log f(Y;\boldsymbol\theta)}{\partial \boldsymbol\theta \partial \boldsymbol\theta&#39;} \right).
\]</span></p>
</div>
<hr />
<div class="proposition">
<p><span id="prp:Fisher" class="proposition"><strong>Proposition 5.2  </strong></span>We have <span class="math inline">\(\mathcal{I}_Y(\boldsymbol\theta) = \mathbb{E} \left[ \left( \frac{\partial \log f(Y;\boldsymbol\theta)}{\partial \boldsymbol\theta} \right) \left( \frac{\partial \log f(Y;\boldsymbol\theta)}{\partial \boldsymbol\theta} \right)&#39; \right] = \mathbb{V}ar[S(Y;\boldsymbol\theta)]\)</span>.</p>
</div>
<hr />
<div class="proof">
<p><span id="unlabeled-div-2" class="proof"><em>Proof</em>. </span>We have <span class="math inline">\(\frac{\partial^2 \log f(Y;\boldsymbol\theta)}{\partial \boldsymbol\theta \partial \boldsymbol\theta&#39;} = \frac{\partial^2 f(Y;\boldsymbol\theta)}{\partial \boldsymbol\theta \partial \boldsymbol\theta&#39;}\frac{1}{f(Y;\boldsymbol\theta)} - \frac{\partial \log f(Y;\boldsymbol\theta)}{\partial \boldsymbol\theta}\frac{\partial \log f(Y;\boldsymbol\theta)}{\partial \boldsymbol\theta&#39;}\)</span>. The expectation of the first right-hand side term is <span class="math inline">\(\partial^2 1 /(\partial \boldsymbol\theta \partial \boldsymbol\theta&#39;) = \bv{0}\)</span>, which gives the result.</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-3" class="example"><strong>Example 5.2  </strong></span>If <span class="math inline">\(y_i \sim\,i.i.d.\, \mathcal{N}(\mu,\sigma^2)\)</span>, let <span class="math inline">\(\boldsymbol\theta = [\mu,\sigma^2]&#39;\)</span> then
<span class="math display">\[
\frac{\partial \log f(y;\boldsymbol\theta)}{\partial \boldsymbol\theta} = \left[\frac{y-\mu}{\sigma^2} \quad \frac{1}{2\sigma^2}\left(\frac{(y-\mu)^2}{\sigma^2}-1\right) \right]&#39;
\]</span>
and
<span class="math display">\[
\mathcal{I}_Y(\boldsymbol\theta) = \mathbb{E}\left( \frac{1}{\sigma^4}
\left[
\begin{array}{cc}
\sigma^2&amp;y-\mu\\
y-\mu &amp; \frac{(y-\mu)^2}{\sigma^2}-\frac{1}{2}
\end{array}\right]
\right)=
\left[
\begin{array}{cc}
1/\sigma^2&amp;0\\
0 &amp; 1/(2\sigma^4)
\end{array}\right].
\]</span></p>
</div>
<hr />
<div class="proposition">
<p><span id="prp:additiv" class="proposition"><strong>Proposition 5.3  (Additive property of the Info. mat.) </strong></span>The information matrix resulting from two independent experiments is the sum of the information matrices:
<span class="math display">\[
\mathcal{I}_{X,Y}(\boldsymbol\theta) = \mathcal{I}_X(\boldsymbol\theta) + \mathcal{I}_Y(\boldsymbol\theta).
\]</span></p>
</div>
<hr />
<p>:::{.proof} Immediately obtained from the definition (see Def. @ref{def:Fisher}).
:::</p>
<hr />
<div class="theorem">
<p><span id="thm:FDCR" class="theorem"><strong>Theorem 5.1  (Fr\'echet-Darmois-Cram\'er-Rao bound) </strong></span>Consider an unbiased estimator of <span class="math inline">\(\boldsymbol\theta\)</span> denoted by <span class="math inline">\(\hat{\boldsymbol\theta}(Y)\)</span>.</p>
<p>The variance of the random variable <span class="math inline">\(\boldsymbol\omega&#39;\hat{\boldsymbol\theta}\)</span> (which is a linear combination of the components of <span class="math inline">\(\hat{\boldsymbol\theta}\)</span>) is larger than:
<span class="math display">\[
(\boldsymbol\omega&#39;\boldsymbol\omega)^2/(\boldsymbol\omega&#39; \mathcal{I}_Y(\boldsymbol\theta) \boldsymbol\omega).
\]</span></p>
</div>
<hr />
<div class="proof">
<p><span id="unlabeled-div-4" class="proof"><em>Proof</em>. </span>The Cauchy-Schwarz inequality implies that <span class="math inline">\(\sqrt{\mathbb{V}ar(\boldsymbol\omega&#39;\hat{\boldsymbol\theta}(Y))\mathbb{V}ar(\boldsymbol\omega&#39;S(Y;\boldsymbol\theta))} \ge |\boldsymbol\omega&#39;\mathbb{C}ov[\hat{\boldsymbol\theta}(Y),S(Y;\boldsymbol\theta)]\boldsymbol\omega |\)</span>. Now, <span class="math inline">\(\mathbb{C}ov[\hat{\boldsymbol\theta}(Y),S(Y;\boldsymbol\theta)] = \int_y \hat{\boldsymbol\theta}(y) \frac{\partial \log f(y;\boldsymbol\theta)}{\partial \boldsymbol\theta} f(y;\boldsymbol\theta)dy = \frac{\partial}{\partial \boldsymbol\theta}\int_y \hat{\boldsymbol\theta}(y) f(y;\boldsymbol\theta)dy = \bv{I}\)</span> because <span class="math inline">\(\hat{\boldsymbol\theta}\)</span> is unbiased.</p>
<p>Therefore <span class="math inline">\(\mathbb{V}ar(\boldsymbol\omega&#39;\hat{\boldsymbol\theta}(Y)) \ge \mathbb{V}ar(\boldsymbol\omega&#39;S(Y;\boldsymbol\theta))^{-1} (\boldsymbol\omega&#39;\boldsymbol\omega)^2\)</span>. Prop. <a href="estimation-methods.html#prp:Fisher">5.2</a> leads to the result.</p>
</div>
<div class="definition">
<p><span id="def:identif" class="definition"><strong>Definition 5.5  </strong></span>The vector of parameters <span class="math inline">\(\boldsymbol\theta\)</span> is identifiable if, for any other vector <span class="math inline">\(\boldsymbol\theta^*\)</span>:
<span class="math display">\[
\boldsymbol\theta^* \ne \boldsymbol\theta \Rightarrow \mathcal{L}(\boldsymbol\theta^*;\bv{y}) \ne \mathcal{L}(\boldsymbol\theta;\bv{y}).
\]</span></p>
</div>
<div class="definition">
<p><span id="def:MLEest" class="definition"><strong>Definition 5.6  (Maximum Likelihood Estimator (MLE)) </strong></span>The maximum likelihood estimator (MLE) is the vector <span class="math inline">\(\boldsymbol\theta\)</span> that maximizes the likelihood function. Formally:
<span class="math display" id="eq:MLEestimator">\[\begin{equation}
\boldsymbol\theta_{MLE} = \arg \max_{\boldsymbol\theta} \mathcal{L}(\boldsymbol\theta;\bv{y})  = \arg \max_{\boldsymbol\theta} \log \mathcal{L}(\boldsymbol\theta;\bv{y}).\tag{5.4}
\end{equation}\]</span></p>
</div>
<div class="definition">
<p><span id="def:likFunction" class="definition"><strong>Definition 5.7  (Likelihood equation) </strong></span>Necessary condition for maximizing the likelihood function:
<span class="math display">\[\begin{equation}
\dfrac{\partial \log \mathcal{L}(\boldsymbol\theta;\bv{y})}{\partial \boldsymbol\theta} = \bv{0}.
\end{equation}\]</span></p>
</div>
<div class="hypothesis">
<p><span id="hyp:MLEregularity" class="hypothesis"><strong>Hypothesis 5.1  (Regularity assumptions) </strong></span>We have:</p>
<ol style="list-style-type: lower-roman">
<li><p><span class="math inline">\(\boldsymbol\theta \in \Theta\)</span> where <span class="math inline">\(\Theta\)</span> is compact.</p></li>
<li><p><span class="math inline">\(\boldsymbol\theta_0\)</span> is identified.</p></li>
<li><p>The log-likelihood function is continuous in <span class="math inline">\(\boldsymbol\theta\)</span>.</p></li>
<li><p><span class="math inline">\(\mathbb{E}_{\boldsymbol\theta_0}(\log f(Y;\boldsymbol\theta))\)</span> exists.</p></li>
<li><p>The log-likelihood function is such that <span class="math inline">\((1/n)\log\mathcal{L}(\boldsymbol\theta;\bv{y})\)</span> converges almost surely to <span class="math inline">\(\mathbb{E}_{\boldsymbol\theta_0}(\log f(Y;\boldsymbol\theta))\)</span>, uniformly in <span class="math inline">\(\boldsymbol\theta \in \Theta\)</span>.</p></li>
<li><p>The log-likelihood function is twice continuously differentiable in an open neighborood of <span class="math inline">\(\boldsymbol\theta_0\)</span>.</p></li>
<li><p>The matrix <span class="math inline">\(\bv{I}(\boldsymbol\theta_0) = - \mathbb{E}_0 \left( \frac{\partial^2 \log \mathcal{L}(\theta;\bv{y})}{\partial \boldsymbol\theta \partial \boldsymbol\theta&#39;}\right) \quad \mbox{(Fisher Information matrix)}\)</span> exists and is nonsingular.</p></li>
</ol>
</div>
<hr />
<div class="proposition">
<p><span id="prp:MLEproperties" class="proposition"><strong>Proposition 5.4  (Properties of MLE) </strong></span>Under regularity conditions (Assumptions <a href="estimation-methods.html#hyp:MLEregularity">5.1</a>), the MLE is:</p>
<ol style="list-style-type: lower-alpha">
<li><p><strong>Consistent</strong>: <span class="math inline">\(\mbox{plim}\quad \boldsymbol\theta_{MLE} = \theta_0\)</span> (<span class="math inline">\(\theta_0\)</span> is the true vector of parameters).</p></li>
<li><p><strong>Asymptotically normal</strong>: <span class="math inline">\(\boldsymbol\theta_{MLE} \sim \mathcal{N}(\boldsymbol\theta_0,\bv{I}(\boldsymbol\theta_0)^{-1})\)</span>, where
<span class="math display">\[
\bv{I}(\boldsymbol\theta_0) = - \mathbb{E}_0 \left( \frac{\partial^2 \log \mathcal{L}(\theta;\bv{y})}{\partial \boldsymbol\theta \partial \boldsymbol\theta&#39;}\right) = n \mathcal{I}_Y(\boldsymbol\theta_0). \quad \mbox{(Fisher Info. matrix)}
\]</span></p></li>
<li><p><strong>Asymptotically efficient</strong>: <span class="math inline">\(\boldsymbol\theta_{MLE}\)</span> is asymptotically efficient and achieves the Fr'echet-Darmois-Cram'er-Rao lower bound for consistent estimators.</p></li>
<li><p><strong>Invariant</strong>: The MLE of <span class="math inline">\(g(\boldsymbol\theta_0)\)</span> is <span class="math inline">\(g(\boldsymbol\theta_{MLE})\)</span> if <span class="math inline">\(g\)</span> is a continuous and continuously differentiable function.</p></li>
</ol>
</div>
<hr />
<div class="proof">
<p><span id="unlabeled-div-5" class="proof"><em>Proof</em>. </span>See <a href="https://www.dropbox.com/s/8xelbghtvnd43yh/Proofs_MLE.pdf?dl=0">Online additional material</a>.</p>
</div>
<p>Note that (b) also writes:
<span class="math display" id="eq:normMLE">\[\begin{equation}
\sqrt{n}(\boldsymbol\theta_{MLE} - \boldsymbol\theta_{0}) \overset{d}{\rightarrow} \mathcal{N}(0,\mathcal{I}_Y(\boldsymbol\theta_0)^{-1}). \tag{5.5}
\end{equation}\]</span></p>
<p>The asymptotic covariance matrix of the MLE is:
<span class="math display">\[
[\bv{I}(\boldsymbol\theta_0)]^{-1} = \left[- \mathbb{E}_0 \left( \frac{\partial^2 \log \mathcal{L}(\boldsymbol\theta;\bv{y})}{\partial \boldsymbol\theta \partial \boldsymbol\theta&#39;}\right) \right]^{-1}.
\]</span>
A direct (analytical) evaluation of this expectation is often out of reach.</p>
<p>It can however be estimated by, either:
<span class="math display" id="eq:I2" id="eq:III1">\[\begin{eqnarray}
\hat{\bv{I}}_1^{-1} &amp;=&amp;  \left( - \frac{\partial^2 \log \mathcal{L}({\boldsymbol\theta_{MLE}};\bv{y})}{\partial {\boldsymbol\theta} \partial {\boldsymbol\theta}&#39;}\right)^{-1}, \tag{5.6}\\
\hat{\bv{I}}_2^{-1} &amp;=&amp;  \left( \sum_{i=1}^n \frac{\partial \log \mathcal{L}({\boldsymbol\theta_{MLE}};y_i)}{\partial {\boldsymbol\theta}} \frac{\partial \log \mathcal{L}({\boldsymbol\theta_{MLE}};y_i)}{\partial {\boldsymbol\theta&#39;}} \right)^{-1}.  \tag{5.7}
\end{eqnarray}\]</span></p>
</div>
<div id="to-sum-up-mle-in-practice" class="section level3 hasAnchor" number="5.2.2">
<h3><span class="header-section-number">5.2.2</span> To sum up – MLE in practice<a href="estimation-methods.html#to-sum-up-mle-in-practice" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>A parametric model (depending on the vector of parameters <span class="math inline">\(\boldsymbol\theta\)</span> whose “true” value is <span class="math inline">\(\boldsymbol\theta_0\)</span>) is specified.</p></li>
<li><p>i.i.d. sources of randomness are identified.</p></li>
<li><p>The density associated to one observation <span class="math inline">\(y_i\)</span> is computed analytically (as a function of <span class="math inline">\(\boldsymbol\theta\)</span>): <span class="math inline">\(f(y;\boldsymbol\theta)\)</span>.</p></li>
<li><p>The log-likelihood is <span class="math inline">\(\log \mathcal{L}(\boldsymbol\theta;\bv{y}) = \sum_i \log f(y_i;\boldsymbol\theta)\)</span>.</p></li>
<li><p>The MLE estimator results from the optimization problem (this is Eq. <a href="estimation-methods.html#eq:MLEestimator">(5.4)</a>):
<span class="math display">\[\begin{equation}
\boldsymbol\theta_{MLE} = \arg \max_{\boldsymbol\theta} \log \mathcal{L}(\boldsymbol\theta;\bv{y}).
\end{equation}\]</span></p></li>
<li><p>We have: <span class="math inline">\(\boldsymbol\theta_{MLE} \sim \mathcal{N}(\theta_0,\bv{I}(\boldsymbol\theta_0)^{-1})\)</span>, where <span class="math inline">\(\bv{I}(\boldsymbol\theta_0)^{-1}\)</span> is estimated by means of Eq. <a href="estimation-methods.html#eq:III1">(5.6)</a> or Eq. <a href="estimation-methods.html#eq:I2">(5.7)</a>. Most of the time, this computation is numerical.</p></li>
</ul>
</div>
<div id="example-mle-estimation-of-a-mixture-of-gaussian-distribution" class="section level3 hasAnchor" number="5.2.3">
<h3><span class="header-section-number">5.2.3</span> Example: MLE estimation of a mixture of Gaussian distribution<a href="estimation-methods.html#example-mle-estimation-of-a-mixture-of-gaussian-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider the returns of the SMI index. Let’s assume that these returns are independently drawn from a mixture of Gaussian distributions. The p.d.f. <span class="math inline">\(f(x;\boldsymbol\theta)\)</span>, with <span class="math inline">\(\boldsymbol\theta = [\mu_1,\sigma_1,\mu_2,\sigma_2,p]&#39;\)</span>, is given by:
<span class="math display">\[
p \frac{1}{\sqrt{2\pi\sigma_1^2}}\exp\left(-\frac{(x - \mu_1)^2}{2\sigma_1^2}\right) + (1-p)\frac{1}{\sqrt{2\pi\sigma_2^2}}\exp\left(-\frac{(x - \mu_2)^2}{2\sigma_2^2}\right).
\]</span>
(See <a href="https://jrenne.shinyapps.io/density/">p.d.f. of mixtures of Gaussian dist.</a>)</p>
<p>The maximum likelihood estimate is <span class="math inline">\(\boldsymbol\theta_{MLE}=[0.30,1.40,-1.45,3.61,0.87]&#39;\)</span>.</p>
<p>The first two entries of the diagonal of <span class="math inline">\(\hat{\bv{I}}_1^{-1}\)</span> are <span class="math inline">\(0.00528\)</span> and <span class="math inline">\(0.00526\)</span>. They are the estimates of <span class="math inline">\(\mathbb{V}ar(\mu_{1,MLE})\)</span> and of <span class="math inline">\(\mathbb{V}ar(\sigma_{1,MLE})\)</span>, respectively.</p>
<p>95% confidence intervals for <span class="math inline">\(\mu_1\)</span> and <span class="math inline">\(\sigma_1\)</span> are, respectively:
<span class="math display">\[
0.30 \pm 1.96\underbrace{\sqrt{0.00528}}_{=0.0726} \quad \mbox{ and } \quad 1.40 \pm 1.96\underbrace{\sqrt{0.00526}.}_{=0.0725}
\]</span></p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="estimation-methods.html#cb8-1" aria-hidden="true" tabindex="-1"></a>smi <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;https://raw.githubusercontent.com/jrenne/Data4courses/master/SMI/SMI.csv&quot;</span>,</span>
<span id="cb8-2"><a href="estimation-methods.html#cb8-2" aria-hidden="true" tabindex="-1"></a>                <span class="at">dec =</span> <span class="st">&quot;.&quot;</span>,<span class="at">header =</span> <span class="cn">TRUE</span>, <span class="at">na.strings =</span> <span class="st">&quot;null&quot;</span>)</span>
<span id="cb8-3"><a href="estimation-methods.html#cb8-3" aria-hidden="true" tabindex="-1"></a>smi<span class="sc">$</span>Date <span class="ot">&lt;-</span> <span class="fu">as.Date</span>(smi<span class="sc">$</span>Date,<span class="st">&quot;%m/%d/%y&quot;</span>)</span>
<span id="cb8-4"><a href="estimation-methods.html#cb8-4" aria-hidden="true" tabindex="-1"></a>T <span class="ot">&lt;-</span> <span class="fu">dim</span>(smi)[<span class="dv">1</span>]</span>
<span id="cb8-5"><a href="estimation-methods.html#cb8-5" aria-hidden="true" tabindex="-1"></a>h <span class="ot">&lt;-</span> <span class="dv">5</span> <span class="co"># holding period (one week)</span></span>
<span id="cb8-6"><a href="estimation-methods.html#cb8-6" aria-hidden="true" tabindex="-1"></a>smi<span class="sc">$</span>r <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="cn">NaN</span>,h),</span>
<span id="cb8-7"><a href="estimation-methods.html#cb8-7" aria-hidden="true" tabindex="-1"></a>           <span class="dv">100</span><span class="sc">*</span><span class="fu">c</span>(<span class="fu">log</span>(smi<span class="sc">$</span>Close[(<span class="dv">1</span><span class="sc">+</span>h)<span class="sc">:</span>T]<span class="sc">/</span>smi<span class="sc">$</span>Close[<span class="dv">1</span><span class="sc">:</span>(T<span class="sc">-</span>h)])))</span>
<span id="cb8-8"><a href="estimation-methods.html#cb8-8" aria-hidden="true" tabindex="-1"></a>indic.dates <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">1</span>,T,<span class="at">by=</span><span class="dv">5</span>)  <span class="co"># weekly returns</span></span>
<span id="cb8-9"><a href="estimation-methods.html#cb8-9" aria-hidden="true" tabindex="-1"></a>smi <span class="ot">&lt;-</span> smi[indic.dates,]</span>
<span id="cb8-10"><a href="estimation-methods.html#cb8-10" aria-hidden="true" tabindex="-1"></a>smi <span class="ot">&lt;-</span> smi[<span class="fu">complete.cases</span>(smi),]</span>
<span id="cb8-11"><a href="estimation-methods.html#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb8-12"><a href="estimation-methods.html#cb8-12" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(smi<span class="sc">$</span>Date,smi<span class="sc">$</span>r,<span class="at">type=</span><span class="st">&quot;l&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;in percent&quot;</span>)</span>
<span id="cb8-13"><a href="estimation-methods.html#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span><span class="dv">0</span>,<span class="at">col=</span><span class="st">&quot;blue&quot;</span>)</span>
<span id="cb8-14"><a href="estimation-methods.html#cb8-14" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span><span class="fu">mean</span>(smi<span class="sc">$</span>r,<span class="at">na.rm =</span> <span class="cn">TRUE</span>)<span class="sc">+</span><span class="dv">2</span><span class="sc">*</span><span class="fu">sd</span>(smi<span class="sc">$</span>r,<span class="at">na.rm =</span> <span class="cn">TRUE</span>),<span class="at">lty=</span><span class="dv">3</span>,<span class="at">col=</span><span class="st">&quot;blue&quot;</span>)</span>
<span id="cb8-15"><a href="estimation-methods.html#cb8-15" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span><span class="fu">mean</span>(smi<span class="sc">$</span>r,<span class="at">na.rm =</span> <span class="cn">TRUE</span>)<span class="sc">-</span><span class="dv">2</span><span class="sc">*</span><span class="fu">sd</span>(smi<span class="sc">$</span>r,<span class="at">na.rm =</span> <span class="cn">TRUE</span>),<span class="at">lty=</span><span class="dv">3</span>,<span class="at">col=</span><span class="st">&quot;blue&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:smiData"></span>
<img src="AdvECTS_files/figure-html/smiData-1.png" alt="Time series of SMI weekly returns (source: Yahoo Finance)." width="90%" />
<p class="caption">
Figure 5.4: Time series of SMI weekly returns (source: Yahoo Finance).
</p>
</div>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="estimation-methods.html#cb9-1" aria-hidden="true" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="cf">function</span>(theta,y){ <span class="co"># Likelihood function</span></span>
<span id="cb9-2"><a href="estimation-methods.html#cb9-2" aria-hidden="true" tabindex="-1"></a>  mu<span class="fl">.1</span> <span class="ot">&lt;-</span> theta[<span class="dv">1</span>]; mu<span class="fl">.2</span> <span class="ot">&lt;-</span> theta[<span class="dv">2</span>]</span>
<span id="cb9-3"><a href="estimation-methods.html#cb9-3" aria-hidden="true" tabindex="-1"></a>  sigma<span class="fl">.1</span> <span class="ot">&lt;-</span> theta[<span class="dv">3</span>]; sigma<span class="fl">.2</span> <span class="ot">&lt;-</span> theta[<span class="dv">4</span>]</span>
<span id="cb9-4"><a href="estimation-methods.html#cb9-4" aria-hidden="true" tabindex="-1"></a>  p <span class="ot">&lt;-</span> <span class="fu">exp</span>(theta[<span class="dv">5</span>])<span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(theta[<span class="dv">5</span>]))</span>
<span id="cb9-5"><a href="estimation-methods.html#cb9-5" aria-hidden="true" tabindex="-1"></a>  res <span class="ot">&lt;-</span> p<span class="sc">*</span><span class="dv">1</span><span class="sc">/</span><span class="fu">sqrt</span>(<span class="dv">2</span><span class="sc">*</span>pi<span class="sc">*</span>sigma<span class="fl">.1</span><span class="sc">^</span><span class="dv">2</span>)<span class="sc">*</span><span class="fu">exp</span>(<span class="sc">-</span>(y<span class="sc">-</span>mu<span class="fl">.1</span>)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>(<span class="dv">2</span><span class="sc">*</span>sigma<span class="fl">.1</span><span class="sc">^</span><span class="dv">2</span>)) <span class="sc">+</span> </span>
<span id="cb9-6"><a href="estimation-methods.html#cb9-6" aria-hidden="true" tabindex="-1"></a>    (<span class="dv">1</span><span class="sc">-</span>p)<span class="sc">*</span><span class="dv">1</span><span class="sc">/</span><span class="fu">sqrt</span>(<span class="dv">2</span><span class="sc">*</span>pi<span class="sc">*</span>sigma<span class="fl">.2</span><span class="sc">^</span><span class="dv">2</span>)<span class="sc">*</span><span class="fu">exp</span>(<span class="sc">-</span>(y<span class="sc">-</span>mu<span class="fl">.2</span>)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>(<span class="dv">2</span><span class="sc">*</span>sigma<span class="fl">.2</span><span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb9-7"><a href="estimation-methods.html#cb9-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(res)</span>
<span id="cb9-8"><a href="estimation-methods.html#cb9-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb9-9"><a href="estimation-methods.html#cb9-9" aria-hidden="true" tabindex="-1"></a>log.f <span class="ot">&lt;-</span> <span class="cf">function</span>(theta,y){ <span class="co">#log-Likelihood function</span></span>
<span id="cb9-10"><a href="estimation-methods.html#cb9-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="sc">-</span><span class="fu">sum</span>(<span class="fu">log</span>(<span class="fu">f</span>(theta,y))))</span>
<span id="cb9-11"><a href="estimation-methods.html#cb9-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb9-12"><a href="estimation-methods.html#cb9-12" aria-hidden="true" tabindex="-1"></a>res.optim <span class="ot">&lt;-</span> <span class="fu">optim</span>(<span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="fl">0.5</span>,<span class="fl">1.5</span>,.<span class="dv">5</span>),</span>
<span id="cb9-13"><a href="estimation-methods.html#cb9-13" aria-hidden="true" tabindex="-1"></a>                   log.f,</span>
<span id="cb9-14"><a href="estimation-methods.html#cb9-14" aria-hidden="true" tabindex="-1"></a>                   <span class="at">y=</span>smi<span class="sc">$</span>r,</span>
<span id="cb9-15"><a href="estimation-methods.html#cb9-15" aria-hidden="true" tabindex="-1"></a>                   <span class="at">method=</span><span class="st">&quot;BFGS&quot;</span>, <span class="co"># could be &quot;Nelder-Mead&quot;</span></span>
<span id="cb9-16"><a href="estimation-methods.html#cb9-16" aria-hidden="true" tabindex="-1"></a>                   <span class="at">control=</span><span class="fu">list</span>(<span class="at">trace=</span><span class="cn">FALSE</span>,<span class="at">maxit=</span><span class="dv">100</span>),<span class="at">hessian=</span><span class="cn">TRUE</span>)</span>
<span id="cb9-17"><a href="estimation-methods.html#cb9-17" aria-hidden="true" tabindex="-1"></a>theta <span class="ot">&lt;-</span> res.optim<span class="sc">$</span>par</span>
<span id="cb9-18"><a href="estimation-methods.html#cb9-18" aria-hidden="true" tabindex="-1"></a>theta</span></code></pre></div>
<pre><code>## [1]  0.3012379 -1.3167476  1.7715072  4.8197596  1.9454889</code></pre>
<p>Now, let us compute estimates of the covariance matrix of the MLE:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="estimation-methods.html#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Hessian approach:</span></span>
<span id="cb11-2"><a href="estimation-methods.html#cb11-2" aria-hidden="true" tabindex="-1"></a>J <span class="ot">&lt;-</span> res.optim<span class="sc">$</span>hessian</span>
<span id="cb11-3"><a href="estimation-methods.html#cb11-3" aria-hidden="true" tabindex="-1"></a>I<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">solve</span>(J)</span>
<span id="cb11-4"><a href="estimation-methods.html#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Outer-product of gradient approach:</span></span>
<span id="cb11-5"><a href="estimation-methods.html#cb11-5" aria-hidden="true" tabindex="-1"></a>log.f<span class="fl">.0</span> <span class="ot">&lt;-</span> <span class="fu">log</span>(<span class="fu">f</span>(theta,smi<span class="sc">$</span>r))</span>
<span id="cb11-6"><a href="estimation-methods.html#cb11-6" aria-hidden="true" tabindex="-1"></a>epsilon <span class="ot">&lt;-</span> .<span class="dv">00000001</span></span>
<span id="cb11-7"><a href="estimation-methods.html#cb11-7" aria-hidden="true" tabindex="-1"></a>d.log.f <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb11-8"><a href="estimation-methods.html#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(theta)){</span>
<span id="cb11-9"><a href="estimation-methods.html#cb11-9" aria-hidden="true" tabindex="-1"></a>  theta.i <span class="ot">&lt;-</span> theta</span>
<span id="cb11-10"><a href="estimation-methods.html#cb11-10" aria-hidden="true" tabindex="-1"></a>  theta.i[i] <span class="ot">&lt;-</span> theta.i[i] <span class="sc">+</span> epsilon</span>
<span id="cb11-11"><a href="estimation-methods.html#cb11-11" aria-hidden="true" tabindex="-1"></a>  log.f.i <span class="ot">&lt;-</span> <span class="fu">log</span>(<span class="fu">f</span>(theta.i,smi<span class="sc">$</span>r))</span>
<span id="cb11-12"><a href="estimation-methods.html#cb11-12" aria-hidden="true" tabindex="-1"></a>  d.log.f <span class="ot">&lt;-</span> <span class="fu">cbind</span>(d.log.f,</span>
<span id="cb11-13"><a href="estimation-methods.html#cb11-13" aria-hidden="true" tabindex="-1"></a>                   (log.f.i <span class="sc">-</span> log.f<span class="fl">.0</span>)<span class="sc">/</span>epsilon)</span>
<span id="cb11-14"><a href="estimation-methods.html#cb11-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb11-15"><a href="estimation-methods.html#cb11-15" aria-hidden="true" tabindex="-1"></a>V <span class="ot">&lt;-</span> <span class="fu">t</span>(d.log.f) <span class="sc">%*%</span> d.log.f</span>
<span id="cb11-16"><a href="estimation-methods.html#cb11-16" aria-hidden="true" tabindex="-1"></a>I<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">solve</span>(<span class="fu">t</span>(d.log.f) <span class="sc">%*%</span> d.log.f)</span>
<span id="cb11-17"><a href="estimation-methods.html#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Misspecification-robust approach (sandwich formula):</span></span>
<span id="cb11-18"><a href="estimation-methods.html#cb11-18" aria-hidden="true" tabindex="-1"></a>I<span class="fl">.3</span> <span class="ot">&lt;-</span> <span class="fu">solve</span>(J) <span class="sc">%*%</span> V <span class="sc">%*%</span> <span class="fu">solve</span>(J)</span>
<span id="cb11-19"><a href="estimation-methods.html#cb11-19" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(<span class="fu">diag</span>(I<span class="fl">.1</span>),<span class="fu">diag</span>(I<span class="fl">.2</span>),<span class="fu">diag</span>(I<span class="fl">.3</span>))</span></code></pre></div>
<pre><code>##             [,1]        [,2]       [,3]
## [1,] 0.003683422 0.003199481 0.00586160
## [2,] 0.226892824 0.194283391 0.38653389
## [3,] 0.005764271 0.002769579 0.01712255
## [4,] 0.194081311 0.047466419 0.83130838
## [5,] 0.092114437 0.040366005 0.31347858</code></pre>
<p>According to the first (respectively third) type of estimate for the covariance matrix, a 95% confidence interval for <span class="math inline">\(\mu_1\)</span> is [0.182, 0.42] (resp. [0.151, 0.451]).</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="estimation-methods.html#cb13-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">5</span>,<span class="dv">5</span>,<span class="at">by=</span>.<span class="dv">01</span>)</span>
<span id="cb13-2"><a href="estimation-methods.html#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x,<span class="fu">f</span>(theta,x),<span class="at">type=</span><span class="st">&quot;l&quot;</span>,<span class="at">lwd=</span><span class="dv">2</span>,<span class="at">xlab=</span><span class="st">&quot;returns, in percent&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;&quot;</span>,</span>
<span id="cb13-3"><a href="estimation-methods.html#cb13-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="fl">1.4</span><span class="sc">*</span><span class="fu">max</span>(<span class="fu">f</span>(theta,x))))</span>
<span id="cb13-4"><a href="estimation-methods.html#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">density</span>(smi<span class="sc">$</span>r),<span class="at">type=</span><span class="st">&quot;l&quot;</span>,<span class="at">lwd=</span><span class="dv">2</span>,<span class="at">lty=</span><span class="dv">3</span>)</span>
<span id="cb13-5"><a href="estimation-methods.html#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x,<span class="fu">dnorm</span>(x,<span class="at">mean=</span><span class="fu">mean</span>(smi<span class="sc">$</span>r),<span class="at">sd =</span> <span class="fu">sd</span>(smi<span class="sc">$</span>r)),<span class="at">col=</span><span class="st">&quot;red&quot;</span>,<span class="at">lty=</span><span class="dv">2</span>,<span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb13-6"><a href="estimation-methods.html#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="fu">rug</span>(smi<span class="sc">$</span>r,<span class="at">col=</span><span class="st">&quot;blue&quot;</span>)</span>
<span id="cb13-7"><a href="estimation-methods.html#cb13-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-8"><a href="estimation-methods.html#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topleft&quot;</span>,</span>
<span id="cb13-9"><a href="estimation-methods.html#cb13-9" aria-hidden="true" tabindex="-1"></a>       <span class="fu">c</span>(<span class="st">&quot;Kernel estimate (non-parametric)&quot;</span>,<span class="st">&quot;Estimated mixture of Gaussian distr. (MLE, parametric)&quot;</span>,<span class="st">&quot;Normal distribution&quot;</span>),</span>
<span id="cb13-10"><a href="estimation-methods.html#cb13-10" aria-hidden="true" tabindex="-1"></a>       <span class="at">lty=</span><span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">1</span>,<span class="dv">2</span>), <span class="co"># gives the legend appropriate symbols (lines)</span></span>
<span id="cb13-11"><a href="estimation-methods.html#cb13-11" aria-hidden="true" tabindex="-1"></a>       <span class="at">lwd=</span><span class="fu">c</span>(<span class="dv">2</span>), <span class="co"># line width</span></span>
<span id="cb13-12"><a href="estimation-methods.html#cb13-12" aria-hidden="true" tabindex="-1"></a>       <span class="at">col=</span><span class="fu">c</span>(<span class="st">&quot;black&quot;</span>,<span class="st">&quot;black&quot;</span>,<span class="st">&quot;red&quot;</span>), <span class="co"># gives the legend lines the correct color and width</span></span>
<span id="cb13-13"><a href="estimation-methods.html#cb13-13" aria-hidden="true" tabindex="-1"></a>       <span class="at">pt.bg=</span><span class="fu">c</span>(<span class="dv">1</span>),</span>
<span id="cb13-14"><a href="estimation-methods.html#cb13-14" aria-hidden="true" tabindex="-1"></a>       <span class="at">pt.cex =</span> <span class="fu">c</span>(<span class="dv">1</span>),</span>
<span id="cb13-15"><a href="estimation-methods.html#cb13-15" aria-hidden="true" tabindex="-1"></a>       <span class="at">bg=</span><span class="st">&quot;white&quot;</span>,</span>
<span id="cb13-16"><a href="estimation-methods.html#cb13-16" aria-hidden="true" tabindex="-1"></a>       <span class="at">seg.len =</span> <span class="dv">4</span></span>
<span id="cb13-17"><a href="estimation-methods.html#cb13-17" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:smidistri"></span>
<img src="AdvECTS_files/figure-html/smidistri-1.png" alt="Comparison of different estimates of the distribution of returns." width="90%" />
<p class="caption">
Figure 5.5: Comparison of different estimates of the distribution of returns.
</p>
</div>
<!-- \begin{figure} -->
<!-- \caption{Density of 5-day returns on SMI index} -->
<!-- \includegraphics[width=.9\linewidth]{../../figures/Figure_kernel_smi.pdf} -->
<!-- \label{fig:illuskernel_smi} -->
<!-- \begin{tiny} -->
<!-- Gaussian kernel, $h=0.5$ (in percent). -->
<!-- The data spans the period from 2 June 2006 to 23 February 2016 at the daily frequency. -->
<!-- Left-hand plot: the blue lines indicates $\mu \pm 2 \sigma$, where $\mu$ is the sample mean of the returns and $\sigma$ is their sample standard deviation. Right-hand plot: the red dotted line is the density $\mathcal{N}(\mu,\sigma^2)$ -->
<!-- \end{tiny} -->
<!-- \end{figure} -->
<!-- \end{exmpl} -->
<!-- \end{scriptsize} -->
<!-- \end{frame} -->
<!-- \begin{frame}{} -->
<!-- \begin{scriptsize} -->
<!-- \addtocounter{exmpl}{-1} -->
<!-- \begin{exmpl}[MLE estim. of a mixture of Gaussian distri. (cont'd)] -->
<!-- \begin{figure} -->
<!-- \caption{Estimated density (vs kernel-based estimate)} -->
<!-- \includegraphics[width=1\linewidth]{../../figures/Figure_kernel_smiMLE.pdf} -->
<!-- \label{fig:MLE1} -->
<!-- \end{figure} -->
<!-- \end{exmpl} -->
<!-- \end{scriptsize} -->
<!-- \end{frame} -->

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="panel-regressions.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="microeconometrics.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/04-EstimationMethods.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["AdvECTS.pdf", "AdvECTS.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
